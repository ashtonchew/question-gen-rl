# Hydra config for question generation training
defaults:
  - _self_

data:
  train_data: ["data/processed/train.parquet"]
  val_data: ["data/processed/test.parquet"]

trainer:
  placement:
    colocate_all: true
    colocate_policy_ref: true
    policy_num_nodes: 1
    policy_num_gpus_per_node: 1
    critic_num_nodes: 1
    critic_num_gpus_per_node: 1
    ref_num_nodes: 1
    ref_num_gpus_per_node: 1

  strategy: fsdp2
  sequence_parallel_backend: "ulysses"

  policy:
    model:
      path: "Qwen/Qwen3-4B-Instruct-2507"
      lora:
        rank: 0
        alpha: 16
        dropout: 0
        lora_sync_path: "/tmp/skyrl_lora_sync"
        target_modules: "all-linear"
        exclude_modules: null
    deepspeed_config: null
    optimizer_config:
      lr: 1.0e-6
      adam_betas: [0.9, 0.999]
      weight_decay: 1e-2
      max_grad_norm: 1.0
      offload_after_step: true
      num_warmup_steps: 0
      scheduler: "constant_with_warmup"
    fsdp_config:
      cpu_offload: true
      reshard_after_forward: true
      fsdp_size: -1
    sequence_parallel_size: 1
    use_torch_compile: false
    record_memory: false

  ref:
    model:
      path: ${trainer.policy.model.path}
    sequence_parallel_size: 1
    deepspeed_config: null
    fsdp_config:
      cpu_offload: true
      reshard_after_forward: true
      fsdp_size: -1

  critic:
    model:
      path: null
      lora:
        rank: 0
        alpha: 16
        dropout: 0
        target_modules: "all-linear"
        exclude_modules: null
    deepspeed_config: null
    optimizer_config:
      lr: 5.0e-6
      adam_betas: [0.9, 0.999]
      weight_decay: 1e-2
      max_grad_norm: 1.0
      offload_after_step: true
      num_warmup_steps: 0
      scheduler: "constant_with_warmup"
    fsdp_config:
      cpu_offload: false
      reshard_after_forward: true
      fsdp_size: -1
    sequence_parallel_size: 1

  algorithm:
    advantage_estimator: "grpo"
    kl_ctrl:
      type: "fixed"
      kl_target: 0.1
      horizon: 10000
    kl_estimator_type: "k3"
    use_kl_estimator_k3: false
    use_abs_kl: false
    use_kl_in_reward: false
    use_kl_loss: true
    kl_loss_coef: 0.001
    use_entropy_loss: false
    entropy_loss_coef: 0.01
    advantage_batch_normalize: false
    value_head_prefix: "value_head"
    policy_loss_type: "regular"
    loss_reduction: "token_mean"
    grpo_norm_by_std: true
    lambd: 1.0
    gamma: 1.0
    eps_clip_low: 0.2
    eps_clip_high: 0.2
    clip_ratio_c: 3.0
    tis_imp_ratio_cap: -1.0
    use_tis: false
    value_clip: 0.2
    dynamic_sampling:
      type: null
      max_sample_batches: 30
      min_replace_ratio: 0.3
    clip_cov:
      clip_ratio: 0.0002
      clip_cov_lb: 1.0
      clip_cov_ub: 5.0
    kl_cov:
      kl_cov_frac: 0.2
      ppo_kl_coef: 1.0
    cispo:
      cispo_eps_clip_low: 0
      cispo_eps_clip_high: 5

  fully_async:
    max_staleness_steps: 4
    num_parallel_generation_workers: 64

  gradient_checkpointing: true
  gradient_checkpointing_use_reentrant: false
  seed: 42
  resume_mode: null
  resume_path: null
  ckpt_path: "checkpoints/"
  max_ckpts_to_keep: 3
  ckpt_interval: 10
  hf_save_interval: -1
  export_path: "exports/"
  bf16: true
  epochs: 5
  update_epochs_per_batch: 1
  train_batch_size: 64
  policy_mini_batch_size: 16
  critic_mini_batch_size: 16
  micro_train_batch_size_per_gpu: 2
  micro_forward_batch_size_per_gpu: 2
  update_ref_every_epoch: false
  use_sample_packing: true
  eval_batch_size: 32
  eval_before_train: true
  eval_interval: 2
  max_prompt_length: 512
  flash_attn: true
  disable_fast_tokenizer: false
  target_modules: null
  exclude_modules: null
  project_name: "question-gen-rl"
  run_name: "qwen3-4b-grpo"
  logger: "console"
  dump_data_batch: false
  dump_eval_results: true
  rope_scaling: null
  rope_theta: null
  step_wise_training: false

generator:
  model_name: ${trainer.policy.model.path}
  model_dtype: "bfloat16"
  run_engines_locally: true
  num_inference_engines: 1
  backend: "vllm"
  weight_sync_backend: "nccl"
  weight_transfer_threshold_cuda_ipc_GB: 1.0
  inference_engine_tensor_parallel_size: 1
  inference_engine_pipeline_parallel_size: 1
  inference_engine_expert_parallel_size: 1
  inference_engine_data_parallel_size: 1
  n_samples_per_prompt: 4
  async_engine: true
  batched: false
  max_input_length: ${trainer.max_prompt_length}
  vllm_v1_disable_multiproc: true
  enable_prefix_caching: true
  enable_chunked_prefill: true
  max_num_batched_tokens: 4096
  enforce_eager: true
  fully_sharded_loras: false
  gpu_memory_utilization: 0.5
  max_num_seqs: 128
  max_model_len: 2048
  remote_inference_engine_urls: ["127.0.0.1:8001"]
  enable_http_endpoint: false
  http_endpoint_host: "127.0.0.1"
  http_endpoint_port: 8000
  max_turns: 1
  chat_template:
    source: "name"
    name_or_path: null
  chat_template_kwargs: {}
  engine_init_kwargs:
    max_model_len: 2048
  override_existing_update_group: "auto"
  sampling_params:
    max_generate_length: 256
    repetition_penalty: 1.0
    temperature: 1.0
    top_p: 1.0
    min_p: 0.0
    top_k: -1
    logprobs: null
    stop: null
  use_conversation_multi_turn: true
  append_eos_token_after_stop_str_in_multi_turn: true
  eval_sampling_params:
    max_generate_length: 256
    repetition_penalty: 1.0
    temperature: 0.0
    top_p: 1.0
    min_p: 0.0
    top_k: -1
    logprobs: null
    stop: null
  eval_n_samples_per_prompt: 1
  zero_reward_on_non_stop: false
  apply_overlong_filtering: false
  rope_scaling: ${trainer.rope_scaling}
  rope_theta: ${trainer.rope_theta}

environment:
  env_class: "question-gen"
  skyrl_gym:
    max_env_workers: 8

deepspeed_config:
  train: null
  eval: null
