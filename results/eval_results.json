{
  "rl": {
    "model": "rl",
    "num_samples": 100,
    "avg_relevance": 9.04,
    "avg_clarity": 8.54,
    "avg_discriminative": 8.84,
    "avg_composite": 8.806666666666667,
    "results": [
      {
        "role_id": "be-401",
        "role_title": "Backend Engineer - Training Infrastructure",
        "question": "\"Imagine you're tasked with setting up a Ray cluster for distributed training of a large-scale ML model. You want to ensure that each training job is scheduled efficiently across available GPUs, and that resource utilization is balanced across the cluster. Describe how you would design the Ray cluster configuration (including cluster address, node configuration, and scheduling policies) to achieve this. Include specific details on how you would configure Ray's resource allocation, GPU scheduling, and job monitoring to prevent over-allocation or under-utilization of GPUs. Explain how you would verify that the cluster is working as intended.\"",
        "scores": {
          "relevance": 9,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests Ray (core for distributed ML orchestration, GPU scheduling), minus 1 for not explicitly listed in role but perfectly matches infrastructure needs. Clarity: Well-scoped with specific aspects, but lacks explicit constraints like cluster size/time (-1 red flag: missing constraints, -1 vague jargon context). Discriminative: Probes applied knowledge, trade-offs in config/scheduling/monitoring/verification, strong separation of experts.",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-402",
        "role_title": "Backend Engineer - Model Deployment",
        "question": "\"Explain how you would implement a rollback strategy for a model deployed using KServe in Kubernetes, including how you would detect when a model is no longer performing acceptably and how you would automate the rollback to a previous version.\"",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core role skills (deployment strategies, rollback automation) with KServe/K8s fitting model deployment context; minor ding as KServe not explicitly listed (-1). Clarity: Precise, well-scoped, no ambiguity or missing constraints. Discriminative: Requires deep applied knowledge of monitoring, detection, and automation trade-offs, strongly separating experienced candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-403",
        "role_title": "Backend Engineer - Inference Optimization",
        "question": "\"Describe a scenario where you optimized model inference latency using quantization and batching in a production environment. Walk through the actual steps you took, including how you measured the improvement, and what challenges you faced (e.g., accuracy trade-offs, memory constraints, or model compatibility).\"",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 10,
          "reasoning": "Directly targets core role skills (quantization, batching, latency optimization) in production context; crystal clear with specific guidance on steps, measurement, challenges; elicits deep experiential knowledge with trade-offs, strongly separating candidates with hands-on expertise from those without.",
          "composite": 9.666666666666666
        }
      },
      {
        "role_id": "be-404",
        "role_title": "Senior Backend Engineer - Feature Platform",
        "question": "\"Design a feature computation pipeline using Feast and Spark to compute and store features for a user-based ML model. The pipeline should handle incremental feature updates, support feature discovery, and ensure data consistency. Walk through your design decisions, including how you'd structure the data flow, how you'd handle feature dependencies, and how you'd ensure consistency between online and offline feature stores. Provide a high-level diagram or pseudocode to illustrate your approach.\"",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (feature computation, online/offline stores, discovery) with exact tech (Feast); minor generic penalty avoided (-0). Clarity: Well-scoped design question with specific requirements, no bundling or ambiguity. Discriminative: Probes deep trade-offs in incremental updates, dependencies, consistency, and Feast/Spark integration, distinguishing strong ML platform engineers.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-405",
        "role_title": "Senior Backend Engineer - Model Monitoring",
        "question": "\"Design a drift detection system for a production ML model that monitors input feature distributions over time. Describe how you would implement this using Python, Prometheus, and PostgreSQL, including how you would collect, store, and visualize drift signals. Specifically, the system should detect concept drift in input features and trigger alerts when drift exceeds a configurable threshold. Include at least one example of a drift metric and explain how you would define the threshold for alerting.\"",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core drift detection for production ML monitoring using specified stack; minor ding for not explicitly covering performance tracking/alerting breadth (-1). Clarity: Crystal clear, well-scoped with specific tech, requirements, and example; no bundling or ambiguity. Discriminative: Tests applied system design, trade-offs in metrics/thresholds, and implementation depth, strongly separating strong ML engineers from weak ones.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-406",
        "role_title": "Senior Backend Engineer - LLM Serving",
        "question": "\"Explain how you would optimize a vLLM serving pipeline for low-latency inference with high throughput, focusing on KV cache management and batching strategies. Walk through your approach, including how you'd configure vLLM settings, handle KV cache sharing across requests, and ensure efficient batching for mixed workloads (e.g., long-context queries and short, fast prompts).\"",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core role responsibilities (batching optimization, KV cache management) and exact tech (vLLM) from description; no red flags. Clarity: Crystal clear, well-scoped with specific focus areas, minor deduction for lacking explicit time constraints. Discriminative: Tests deep applied knowledge, trade-offs (e.g., mixed workloads, sharing), and configuration expertise, strongly separating candidates.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-407",
        "role_title": "Staff Backend Engineer - ML Infrastructure",
        "question": "*\u201cYou're tasked with building a scalable training platform for large-scale ML models using Ray and Kubernetes. The platform must support distributed training across multiple GPUs, handle dynamic workloads, and optimize resource utilization. Describe how you would design the job scheduling and resource allocation strategy to ensure efficient use of cluster resources while minimizing job overhead and maximizing throughput. Be specific about how Ray\u2019s cluster mode and Kubernetes integrations would be used, and include considerations for scaling, fault tolerance, and cost optimization.\u201d*",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's core focus on ML training platforms, distributed systems, and cost optimization; uses Ray/K8s directly relevant to scalable ML infra. Clarity: Crystal clear, well-scoped design question with specific tech and considerations; minor deduction for lacking explicit time/format constraints. Discriminative: Tests deep applied knowledge of Ray/K8s integrations, trade-offs in scheduling/scaling/fault tolerance, strongly separates experts from generalists.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-408",
        "role_title": "Junior Backend Developer - Health Endpoints",
        "question": "\"Design and implement a health check endpoint in Go that:\n1. Returns a 200 OK status for liveness and readiness probes\n2. Returns a 503 Service Unavailable when the service is not ready (e.g., during startup)\n3. Exposes metrics via a separate endpoint (e.g. /metrics) that can be scraped by Prometheus\n4. Uses Docker and Kubernetes to run the service and expose the health endpoints\"",
        "scores": {
          "relevance": 9,
          "clarity": 7,
          "discriminative": 8,
          "reasoning": "Relevance: Directly tests core role skills (health checks, liveness/readiness, metrics) and Go; minor ding for Docker/K8s not in role desc (-2 red flag overridden by core match). Clarity: Clear intent but bundles multiple endpoints + infra setup without time/format constraints (-2 for multiple questions). Discriminative: Tests applied design/implementation with trade-offs (startup logic, Prometheus), distinguishes strong implementers from weak ones.",
          "composite": 8.0
        }
      },
      {
        "role_id": "be-409",
        "role_title": "Junior Backend Engineer - File Upload",
        "question": "\"Design a FastAPI endpoint to handle file uploads for a user. The file should be validated for size (max 10MB), MIME type (only allow images), and stored in S3. The endpoint should return a success response with the file's upload ID and a message upon successful upload. Handle errors gracefully and provide meaningful error messages for common issues (e.g., invalid file type, file too large).\"",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (file upload API, multipart implied, validation, S3 storage) with exact tech (FastAPI). No red flags. Clarity: Crystal clear, well-scoped endpoint design with specific constraints; minor deduction as no explicit time/format limit. Discriminative: Requires applied knowledge of FastAPI uploads, validation, S3 integration, error handling, and trade-offs (e.g., async, security), strongly separating capable entry-level candidates.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-410",
        "role_title": "Backend Engineer - Bulk Operations",
        "question": "Imagine you're implementing a bulk import API for a user database where users are imported in batches of 1000 records. Each record has a unique `user_id` and a `name`. The API accepts a JSON array of user records and must:",
        "scores": {
          "relevance": 7,
          "clarity": 4,
          "discriminative": 6,
          "reasoning": "Relevance: Tests bulk API handling relevant to role but lacks explicit role description/tech stack and ignores idempotency/partial success (-3 generic). Clarity: Incomplete/incomplete prompt cuts off requirements, multiple interpretations, missing constraints (-4 for vagueness, bundled/missing scope -2). Discriminative: Scenario-based but superficial without full specs, tests basic knowledge not trade-offs.",
          "composite": 5.666666666666667
        }
      },
      {
        "role_id": "be-411",
        "role_title": "Backend Engineer - Admin APIs",
        "question": "You're building an admin API endpoint to manage user roles in a system. The endpoint needs to:\n- Accept a user ID and a new role (e.g., \"admin\", \"moderator\", \"viewer\")\n- Validate the role is in a predefined list of allowed roles\n- Check that the current user making the request has sufficient privileges (e.g., only users with \"admin\" role can modify roles)\n- Update the user's role in the database\n- Log the action with timestamp, user ID, role before/after, and a descriptive message\n- Return a 200 OK response if successful, or a 400/403/500 error with descriptive messages",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core admin API skills (privileged access, audit logging, workflows) from role description, no red flags. Clarity: Crystal clear requirements, well-scoped; minor deduction for unspecified implementation language/format. Discriminative: Requires applied knowledge of auth, validation, DB ops, logging, and error handling with trade-offs (e.g., privilege checks, audit details), strongly separates candidates.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-412",
        "role_title": "Backend Engineer - Analytics APIs",
        "question": "\"Design a Go-based analytics API endpoint that retrieves user session duration statistics for a given date range. The endpoint must support filtering by user ID, and it should efficiently handle time-series aggregation (e.g., average session duration per day). Use ClickHouse as the primary data store, Redis for caching, and PostgreSQL for metadata (e.g., user IDs). Assume the session data is stored in ClickHouse with a schema like: `user_id, session_start, session_end, session_duration`. The endpoint should return a structured response including daily averages and total counts. Explain your design decisions, including how you'd handle caching, query optimization, and data consistency.\"",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 10,
          "reasoning": "Relevance: Perfectly matches role's focus on analytics APIs, aggregation, time-series, and caching with exact tech stack (Go, ClickHouse, Redis, PostgreSQL). No red flags.\nClarity: Crystal clear with schema, requirements, and scope; minor deduction for lacking explicit time/format constraints.\nDiscriminative: Excellent at testing applied knowledge, trade-offs (caching, optimization, consistency), and deep design skills; strong separation of strong vs weak candidates.",
          "composite": 9.666666666666666
        }
      },
      {
        "role_id": "be-413",
        "role_title": "Senior Backend Engineer - API Gateway Logic",
        "question": "\"Explain how you would design a custom Envoy filter plugin in Go to modify HTTP headers before they are sent to downstream services, and describe how you would ensure it integrates securely and efficiently with Envoy's plugin system, including considerations for performance, memory, and security.\"",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Directly targets Envoy plugin development in Go for HTTP header modification and routing logic, core to API gateway extensions role. Crystal clear with specific scope (custom filter, integration, performance/security trade-offs). Tests deep applied knowledge and design decisions, strongly differentiating strong candidates familiar with Envoy's WASM/Go filter system from others.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-414",
        "role_title": "Senior Backend Engineer - Long-Polling",
        "question": "\"Design a long-polling API endpoint in Go that handles a 30-second timeout and supports a fallback to polling every 5 seconds if the long-polling request times out. Use Redis to store the result of the async operation and PostgreSQL to store the request context. The endpoint must manage client connections properly and ensure that when a client disconnects, the request is marked as failed. Include a method to verify the health of the long-polling service and a method to verify the health of the Redis and PostgreSQL connections.\"",
        "scores": {
          "relevance": 9,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core long-polling, connection management, timeouts, fallbacks, and async ops with role's tech (Go implied, Redis/PostgreSQL specified); minor ding for extra health checks. Clarity: Well-scoped and unambiguous, but bundles multiple elements (design + health checks) and lacks response format/time constraints (-2). Discriminative: Requires deep applied knowledge of trade-offs in connection handling, DB integration, fallbacks, and edge cases like disconnects, strongly separating strong candidates.",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-415",
        "role_title": "Senior Backend Engineer - Multipart APIs",
        "question": "\"Design a resumable upload system using FastAPI and S3 that supports chunked uploads and resume from any point. Explain how you would structure the upload state, manage upload progress, and ensure data integrity when reassembling chunks on the server side. Include how you'd handle edge cases like network failures, partial uploads, and concurrent uploads from the same client.\"",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core role skills (resumable uploads, chunk management, S3 APIs) with specified tech (FastAPI/S3); no red flags. Clarity: Well-scoped design question with specific components and edge cases listed, minor deduction for lacking time/format constraints. Discriminative: Tests deep applied knowledge, trade-offs, and edge cases, strongly separating strong candidates who can reason through state/integrity issues from weak ones.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-416",
        "role_title": "Staff Backend Engineer - External APIs",
        "question": "\"Design a simple Go service that exposes an external API endpoint to validate a partner's API key. The service should:\n1. Accept a POST request with a `key` field in the request body.\n2. Store keys in memory (not persistence) for testing.\n3. Use OpenAPI to define the API spec and serve it via a built-in OpenAPI server.\n4. Validate the key against a predefined list of valid keys (hardcoded).\n5. Return a 200 OK with a JSON response body if valid, 401 Unauthorized if invalid.\n6. Include error handling for malformed requests (e.g., missing key field, invalid JSON).\"",
        "scores": {
          "relevance": 4,
          "clarity": 9,
          "discriminative": 7,
          "reasoning": "Relevance: Generic Go API coding tests superficially mention tech (Go, OpenAPI) but unrelated to core role of API strategy/monetization/enablement; misses role focus (-3 generic, -2 minor tech). Clarity: Crystal clear specs, well-scoped, unambiguous. Discriminative: Tests applied Go/web skills with error handling, differentiates solid coders but not deeply strategic.",
          "composite": 6.666666666666667
        }
      },
      {
        "role_id": "be-417",
        "role_title": "Junior Backend Developer - Event Sourcing",
        "question": "\"Design a simple event handler in Java that listens to a `UserRegisteredEvent` from Kafka, persists the event to PostgreSQL, and then emits a `UserReadyEvent` after a 1-second delay. Use only the provided technologies (Java, Kafka, PostgreSQL, Docker). Do not use Spring Boot or Spring Framework. You can use any Java 17+ library for Kafka and JDBC for PostgreSQL.\"",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core event handling, persistence, and event emission with exact tech stack (Java, Kafka, PostgreSQL); minor Docker mention doesn't detract (-0). Clarity: Crystal clear scope, explicit constraints, no ambiguity. Discriminative: Requires integrating streaming, DB ops, delays, and sequencing\u2014tests applied event sourcing skills and trade-offs (e.g., exactly-once, error handling), strongly separates candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-418",
        "role_title": "Junior Backend Engineer - Service Clients",
        "question": "\"Walk me through how you'd design a gRPC client in Go that automatically retries failed requests with exponential backoff, while also implementing a circuit breaker to prevent overwhelming the server during transient failures.\"",
        "scores": {
          "relevance": 9,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (retries, circuit breakers) in Go for service clients; minor deduction as gRPC not explicitly listed (-1). Clarity: Clear intent and well-scoped for screening, but lacks explicit constraints like max retries or thresholds (-1). Discriminative: Excellent at probing applied knowledge, trade-offs (backoff tuning, circuit states), and integration depth.",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-419",
        "role_title": "Backend Engineer - Retry Logic",
        "question": "*Design a retry mechanism for a distributed system using Go, Redis, and PostgreSQL. The system must handle exponential backoff with jitter, respect a retry budget (e.g., max 3 retries), and avoid infinite loops. Explain how you would store retry state, manage backoff, and ensure the system does't retry indefinitely. Include a brief design for how you\u2019d handle failed operations that exceed the retry budget.*",
        "scores": {
          "relevance": 9,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core retry infrastructure skills (backoff, jitter, budgets) and specifies Go/Redis/PostgreSQL relevant to distributed ops (-1 for assuming specific DBs not in role desc). Clarity: Well-scoped with clear requirements, but 'design' lacks minor constraints like perf or scale (8). Discriminative: Probes applied knowledge, trade-offs (storage, budgeting, indefinite prevention), strong separation of strong vs weak candidates.",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-420",
        "role_title": "Backend Engineer - Graceful Shutdown",
        "question": "How would you implement a graceful shutdown for a Go gRPC server that is running in a Kubernetes environment, ensuring that in-flight requests are completed before terminating the process, and that the server handles termination signals from Kubernetes (like SIGTERM) properly? Include considerations for connection draining and handling of client-side timeouts.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core role requirements (graceful shutdown, connection draining, signals) using Go gRPC and Kubernetes from context (-0 red flags). Clarity: Precise, well-scoped for screening, no ambiguity or bundling. Discriminative: Probes deep applied knowledge of signals, draining, trade-offs (e.g., timeouts), distinguishing strong candidates via reasoning over recall.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-421",
        "role_title": "Senior Backend Engineer - Security Automation",
        "question": "\"Describe how you would implement a Python-based pipeline to automatically detect and rotate secrets in AWS using HashiCorp Vault and Terraform. Include details on how the pipeline would detect outdated secrets, trigger rotation, and ensure compliance with security policies. Specifically, last rotated timestamp and rotation period are critical parameters. Provide a clear explanation of how this would work in practice, including any error handling, logging, or validation steps.\"",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core role skills (security automation, secrets rotation in AWS) with exact tech stack (Python, Vault, Terraform). No red flags. Clarity: Well-scoped with specific parameters and components; minor deduction for lacking explicit time/format constraints. Discriminative: Tests applied knowledge, trade-offs (detection, rotation, compliance), error handling; strong separation without being too broad or recall-based.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-422",
        "role_title": "Junior Backend Engineer - API Testing",
        "question": "Write a pytest test that verifies a FastAPI endpoint returns a 200 OK status and a JSON response with a specific field value (e.g., `{\"message\": \"success\"}`) when accessed with a GET request. Use a fixture to set up a test client and include error handling to catch any unexpected HTTP status codes or JSON parsing errors.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 8,
          "reasoning": "Relevance: Directly tests pytest fixtures, FastAPI testing, and error handling\u2014core to API tests role; minor ding as role emphasizes contract testing/fixtures more explicitly (-1). Clarity: Crystal clear, well-scoped with specific requirements and fixture use. Discriminative: Tests applied pytest/FastAPI knowledge with fixture and error handling, separates those who can write functional tests from trivia knowers.",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-423",
        "role_title": "Staff Engineer - Incident Response Platform",
        "question": "\"Design a system to detect and respond to SLO violations in a Kubernetes environment using Go. Your solution should integrate with PagerDuty for alerts and Slack for notifications. It should monitor a critical service\u2019s SLO (e.g., 99.9% availability), store metrics and alerts in PostgreSQL, and handle alert deduplication and time-based suppression. Explain your architecture, how you'd implement alert deduplication and suppression, and how you'd handle failures gracefully.\"",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core SLO tracking, alerting, and incident response in Kubernetes/Go, matching role; minor ding for specifying PagerDuty/Slack/PostgreSQL not in desc (-1). Clarity: Well-scoped design question with specific integrations, components, and aspects to cover; no bundling or vagueness. Discriminative: Probes architecture, implementation details (dedup/suppression), and trade-offs (failures), separating strong engineers who can apply knowledge from weak ones.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-424",
        "role_title": "Backend Engineer - Message Serialization",
        "question": "\"Design a message serialization pipeline using Avro with schema evolution, where messages are produced to Kafka and consumed by multiple services. The pipeline must support backward and forward compatibility, ensure schema validation at both producer and consumer sides, and handle schema evolution gracefully. Explain how you would structure the schema registry integration, manage schema versioning, and handle schema conflicts during consumption. Provide a concrete example of a message schema evolution from v1 to v2, including how producers and consumers adapt to the change.\"",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 10,
          "reasoning": "Relevance: Perfectly matches role's core focus on message serialization, schema evolution, backward/forward compatibility, and validation; directly tests Avro/Kafka which align with infrastructure needs (no red flags). Clarity: Crystal clear and well-scoped with specific requirements, concrete example requested; minor deduction for no explicit time/format constraints. Discriminative: Excellent at testing deep applied knowledge, trade-offs in versioning/conflicts, and practical adaptation, strongly separating strong candidates.",
          "composite": 9.666666666666666
        }
      },
      {
        "role_id": "be-425",
        "role_title": "Senior Backend Engineer - Graph Analytics",
        "question": "\"Design a graph analytics pipeline to compute user influence scores in a social network using Neo4j and Apache Spark. The pipeline should handle a billion-edge-scale graph, support real-time updates via streaming, and allow for incremental computation of influence scores. Explain how you would structure the pipeline, the key challenges, and how you would balance between query performance and scalability.\"",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 10,
          "reasoning": "Relevance: Directly targets core role skills (graph analytics, billion-edge scale, social networks) with specified tech (Neo4j, Spark); minor ding for assuming Spark/Neo4j in role desc (-1). Clarity: Well-scoped design question with explicit constraints (scale, real-time, incremental); no bundling or vagueness. Discriminative: Excellent at testing trade-offs, deep understanding of challenges in distributed graph processing, streaming, and optimization\u2014strong separation of strong vs weak candidates.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-426",
        "role_title": "Junior Backend Engineer - DevOps Scripting",
        "question": "\"Write a Bash script that will automatically deploy a Python application to a production server using GitHub Actions. The script should:  \n- Clone the latest code from the main branch  \n- Install Python dependencies using pip  \n- Run the application with a specific environment variable  \n- Log all actions to a file called `deploy.log`\"",
        "scores": {
          "relevance": 4,
          "clarity": 8,
          "discriminative": 6,
          "reasoning": "Relevance: Generic Bash scripting with superficial DevOps elements (cloning/pip), but fundamentally mismatches role by asking for Bash script *within* GitHub Actions (a YAML CI workflow), not actual pipeline writing; generic programming (-3), misses core CI pipeline skills. Clarity: Well-formed requirements, unambiguous steps, good scope for screening. Discriminative: Tests basic Bash scripting and applied DevOps tasks (logging, env vars), differentiates weak scripters, but lacks trade-offs/depth; somewhat basic.",
          "composite": 6.0
        }
      },
      {
        "role_id": "be-427",
        "role_title": "Backend Engineer - Feature Store",
        "question": "\"Design a schema for a feature store that supports both batch and real-time feature serving using Feast. The schema should include tables for feature entities, features, and feature views. Include a description of how you would handle feature versioning and how you would ensure data consistency between batch and real-time feature serving.\"",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Directly tests core feature store skills (schema, versioning, batch/real-time serving) using Feast, matching role focus. Crystal clear with specific tables and aspects, well-scoped for screening. Probes applied knowledge of trade-offs in versioning and consistency, distinguishing strong ML infra candidates. Minor ding for lacking explicit time constraint.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-428",
        "role_title": "Senior Backend Engineer - Payment Orchestration",
        "question": "\"Design a system to route payment transactions across multiple providers (e.g., Stripe, Adyen, PayPal) using Go, PostgreSQL, Kafka, and Redis. Your design should include:  \n- How you would store provider configurations and health status in PostgreSQL  \n- How you would handle failover when a provider fails (e.g., due to timeout or error)  \n- How you would use Redis to cache provider latency or success rates  \n- How you would use Kafka to propagate transaction failures and trigger retries or alerts  \n- How you would ensure transaction consistency and avoid duplicate processing in a distributed system\"",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's core needs (routing, failover, cost/success optimization) and exact tech stack. Clarity: Crystal clear with specific components scoped; minor deduction for no time limit. Discriminative: Tests deep applied knowledge, trade-offs (e.g., consistency in distributed systems), and integration; excellent separation of strong vs weak candidates.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-429",
        "role_title": "Backend Engineer - Log Aggregation",
        "question": "Explain how you would design a log aggregation pipeline using Go, Kafka, and ClickHouse to handle 1 million events per second. Include specific details on how you\u2019d handle log parsing, message enrichment, and retention policies in ClickHouse. Be sure to address scalability and data durability.",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core role skills (log pipelines, parsing, enrichment, retention) with exact tech stack implied by high-throughput needs (Go, Kafka, ClickHouse ideal). No red flags. Clarity: Crystal clear, well-scoped with specific components, throughput, and requirements; minor deduction for no explicit time/format constraints. Discriminative: Tests deep applied knowledge, trade-offs in scalability/durability, distinguishes strong architects from weak ones; appropriately scoped for screening.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-430",
        "role_title": "Junior Backend Engineer - Search Indexing",
        "question": "\"Explain how you would design and implement a bulk indexing job for a product catalog in Elasticsearch using Python, and describe how you would handle duplicates, ensure data consistency, and validate the indexing process.\"",
        "scores": {
          "relevance": 9,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core role skills (bulk indexing in Elasticsearch, mapping implied), matches tech stack; minor ding for not explicitly mentioning mapping design (-1). Clarity: Well-formed and unambiguous, but lacks explicit constraints like scale or time (-2). Discriminative: Excellent at testing applied knowledge, trade-offs (e.g., duplicate handling, consistency), and validation\u2014strong separation of candidates.",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-431",
        "role_title": "Staff Engineer - Real-time Collaboration",
        "question": "\"Design a system that synchronizes a shared document between two users in real time using WebSockets and CRDTs. Specifically, highlight how you would handle a conflict when both users insert a character at the same time (e.g., User A inserts 'X' at position 3, and User B inserts 'Y' at position 3). How would you ensure the result is deterministic and consistent across both clients?\"",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 10,
          "reasoning": "Relevance: Directly targets core role skills (real-time collaboration, conflict resolution, operational transforms via CRDTs). Clarity: Crystal clear, well-scoped example with specific conflict scenario; minor deduction only for unspecified time constraints. Discriminative: Forces deep understanding of CRDTs, concurrency, determinism, and trade-offs, strongly separating experts from surface-level knowers.",
          "composite": 9.666666666666666
        }
      },
      {
        "role_id": "be-432",
        "role_title": "Backend Engineer - Data Validation",
        "question": "\"Design a Great Expectations suite for a data pipeline that ingests raw JSON logs from S3 and loads them into a PostgreSQL table. The logs contain user activity events with fields like `user_id`, `action`, and `timestamp`. The pipeline runs daily and must validate that the data is complete, consistent, and conforms to expected patterns. Describe how you would structure your Great Expectations suite, including the key expectations, how you\u2019d handle schema validation, and how you\u2019d integrate with Airflow. Include a specific example of a statistical check you\u2019d include.\"",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests Great Expectations for data validation (core to role), schema/statistical checks, with pipeline context; minor ding for assuming Airflow/S3/PostgreSQL not explicitly listed (-1). Clarity: Well-scoped design question with specific tech/context, no ambiguity. Discriminative: Requires applied knowledge of GE suites, expectations, integration, and trade-offs in statistical checks, strongly separates skilled candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-433",
        "role_title": "Senior Backend Engineer - Platform APIs",
        "question": "\"Design a scalable and robust service catalog API in Go using gRPC that supports service discovery, versioning, and self-service provisioning. The API must support listing available services, retrieving service details, and triggering a provisioning workflow. Include considerations for service discovery, versioning, and error handling in your design.\"",
        "scores": {
          "relevance": 8,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core service catalog and provisioning skills for the role, but specifies Go/gRPC (not explicitly listed) and misses resource provisioning depth (-2). Clarity: Clear intent and scope for screening, but lacks constraints like scale/performance metrics or time limits (-2). Discriminative: Excellent at probing trade-offs in discovery, versioning, workflows, and error handling, strongly separating strong candidates.",
          "composite": 8.333333333333334
        }
      },
      {
        "role_id": "be-434",
        "role_title": "Principal Engineer - Database Strategy",
        "question": "*You are leading a migration from a monolithic PostgreSQL database to a distributed database architecture using CockroachDB across multiple AWS regions. The current system has a 100GB monolithic PostgreSQL instance with 10TB of transactional data and 5TB of analytical data. The migration must preserve data consistency, minimize downtime, and ensure low-latency access for both transactional and analytical workloads. How would you design the data distribution and partitioning strategy to meet these requirements, and what specific steps would you take to ensure data consistency during the migration?*",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 10,
          "reasoning": "Relevance: Directly tests core role skills in multi-region DB strategy, migration planning, and tech selection (CockroachDB fits distributed/multi-region); minor ding as CockroachDB not explicitly listed (-1). Clarity: Crystal clear, well-scoped with specific data sizes, workloads, and constraints. Discriminative: Excellent at testing deep trade-offs in partitioning, data distribution, consistency models, and migration steps, strongly separating strong DB architects from others.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-435",
        "role_title": "Junior Backend Engineer - Queue Consumers",
        "question": "*You're building a consumer for a RabbitMQ queue that processes user registration events. Each event contains a user ID and email. The consumer must:*",
        "scores": {
          "relevance": 4,
          "clarity": 3,
          "discriminative": 2,
          "reasoning": "Relevance: Superficially mentions RabbitMQ (relevant) but incomplete/incomplete question tests nothing specific; misses core skills like ack patterns, dead letters, idempotency (-3 generic/incomplete, -2 ignores main focus). Clarity: Grammatically broken/incomplete (cuts off mid-sentence), multiple interpretations (-2). Discriminative: No actual requirements or task, trivial/impossible (-2).",
          "composite": 3.0
        }
      },
      {
        "role_id": "be-436",
        "role_title": "Backend Engineer - API Documentation",
        "question": "Explain how you would design a system to auto-generate OpenAPI/Swagger specifications from a Node.js/TypeScript backend, including versioning, example generation, and SDK generation. Walk through the steps, key considerations, and trade-offs you\u2019d make.",
        "scores": {
          "relevance": 8,
          "clarity": 7,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (auto-gen specs, versioning, examples, SDKs) and Node.js/TS stack, but generic phrasing subtracts 2. Clarity: Clear intent matching role, but 'design a system' lacks explicit scoping/constraints (-2). Discriminative: Excellent at probing applied knowledge, trade-offs, and depth for strong separation among candidates.",
          "composite": 8.0
        }
      },
      {
        "role_id": "be-437",
        "role_title": "Senior Backend Engineer - Secrets Management",
        "question": "\"Design a secure secrets rotation mechanism for a Kubernetes cluster using HashiCorp Vault and AWS KMS. The secrets must be encrypted at rest, rotated automatically every 90 days, and accessible only to service pods with minimal required permissions. Include details on how you would configure Vault, AWS KMS, and Kubernetes to enforce encryption-at-rest, handle rotation, and ensure audit logging for all access. Explain how you would verify the mechanism is working correctly.\"",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's core needs (secrets rotation, encryption-at-rest, access policies, audit logging) with exact tech (Vault, KMS, K8s). Clarity: Well-scoped design question with specific requirements, minor deduction for lacking time/format constraints. Discriminative: Tests deep applied knowledge, trade-offs in integration/security, verification\u2014strong separation of experts from juniors.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-438",
        "role_title": "Staff Engineer - ML Serving Infrastructure",
        "question": "How would you design a high-throughput, low-latency ML serving system using Triton, and what specific strategies would you implement to optimize batching and model versioning for a real-time inference workload with variable request sizes and arrival patterns?",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Directly targets core role skills (ML serving infra, batching, model versioning, latency opt) with Triton (common for inference serving). Crystal clear scope for screening, tests applied trade-offs in batching/versioning for variable workloads. Minor ding for assuming Triton expertise without role mention, but highly relevant overall.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-439",
        "role_title": "Backend Engineer - Billing Integration",
        "question": "\"Design a system to handle proration for a subscription upgrade. A user upgrades from a $10/month plan to a $20/month plan on the 15th of the month. The original plan ran from the 1st to the 15th, and the new plan starts on the 15th. The user should only be charged for the difference in cost (i.e., $10) for the period from the 15th to the end of the month. How would you design the billing calculation to ensure this proration is accurate and handled correctly in a real-world system?\"",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core proration for subscription upgrades, matching role's billing focus (-0 red flags). Clarity: Precise scenario with clear dates, expected charge, and real-world system scope. Discriminative: Requires deep understanding of proration math, edge cases, and system design trade-offs, strongly separating candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-440",
        "role_title": "Junior Backend Engineer - Metrics Collection",
        "question": "\"Describe how you would instrument a Go service to collect CPU usage as a gauge metric and the number of incoming HTTP requests as a counter metric. Include how you would expose these metrics via Prometheus and visualize them in Grafana.\"",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Directly tests core instrumentation skills (gauge/counter) with Go, Prometheus, and Grafana visualization\u2014perfectly matches entry-level role focus. Crystal clear with specific metrics and full stack. Strong separation via applied knowledge requiring trade-offs in implementation/exposure.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-441",
        "role_title": "Senior Backend Engineer - Autocomplete Systems",
        "question": "Imagine you're building a global autocomplete system that must support 100K QPS with sub-50ms latency. How would you design the caching layer for autocomplete queries using Redis and Elasticsearch, and what specific strategies would you employ to handle sudden spikes in traffic and prevent cache thrashing? Please include how you'd balance personalization (e.g., user-specific suggestions) with performance, and how you'd validate performance under load.",
        "scores": {
          "relevance": 9,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core autocomplete caching, latency/QPS from role, Redis/ES implied as standard; minor ding for not explicitly listing them (-1). Clarity: Well-scoped with specifics, but open-ended design lacks strict constraints (-1). Discriminative: Probes trade-offs (personalization vs perf, spikes/thrashing), deep applied knowledge separates strong candidates.",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-442",
        "role_title": "Backend Engineer - Event Streaming",
        "question": "Design a system that routes real-time user activity events (e.g., \"user clicked a button\") to multiple downstream consumers (e.g., analytics, notifications, audit logs) using NATS and Rust. The system must support fan-out, filtering (e.g., only events from users with `role: admin`), and replay capabilities. Describe the architecture, data flows, and how you would implement the fan-out and filtering. Be specific about how you\u2019d use NATS features, and how you\u2019d ensure replay is accurate and consistent.",
        "scores": {
          "relevance": 8,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (event streaming, fan-out, filtering, replay) but specifies unmentioned tech (NATS/Rust; -2). Clarity: Well-scoped with specific requirements and NATS focus, though minor lack of constraints like scale (-1 from 9). Discriminative: Excellent at probing applied knowledge, trade-offs in NATS features, Rust integration, and consistency challenges for strong separation.",
          "composite": 8.333333333333334
        }
      },
      {
        "role_id": "be-443",
        "role_title": "Senior Backend Engineer - Data Lake Architecture",
        "question": "Explain how to configure a Spark job to read from an Iceberg table in S3 with dynamic partition pruning enabled, and describe the steps to validate that partition pruning is actually occurring (not just inferred). Include how you would verify that schema evolution is properly supported and that time travel queries are working correctly.",
        "scores": {
          "relevance": 9,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (Iceberg tables, partition pruning, schema evolution, time travel) with Spark/S3 stack (-1 for no explicit Spark mention in role, but highly aligned). Clarity: Well-formed and unambiguous, but minor deduction for lacking explicit constraints on response format/depth. Discriminative: Excellent at separating candidates via applied knowledge, configuration steps, and validation (trade-offs in verification methods), not mere recall.",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-444",
        "role_title": "Backend Engineer - Service Templates",
        "question": "\"Walk me through how you'd create a new Go service template using Cookiecutter and GitHub Actions. Include how you'd structure the project, what defaults you'd include for observability and security, and how you'd set up CI/DR for the service using ArgoCD. Explain your reasoning for each decision.\"",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (service templates, CI/CD, observability, security) with Go/Cookiecutter/ArgoCD; minor ding for GitHub Actions specificity not in desc (-1). Clarity: Well-scoped, unambiguous, single focused walkthrough with clear components. Discriminative: Requires applied knowledge, trade-offs, and reasoning, strongly separating candidates with role-specific expertise.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-445",
        "role_title": "Junior Backend Engineer - Database Migrations",
        "question": "\"Imagine you're working on a service that uses PostgreSQL and SQLAlchemy with Alembic for schema migrations. A recent migration failed due to a constraint violation during a `CREATE TABLE` statement. The migration script includes a `downgrade()` function, but it's not being called when the migration fails. How would you ensure that the database remains in a consistent state if a migration fails during the `up()` phase, and what steps would you take to recover from this scenario?\"",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core role skills (database migrations, PostgreSQL/Alembic implied, rollback/consistency) without red flags (-0). Clarity: Well-scoped scenario with specific context, unambiguous intent and depth. Discriminative: Probes applied knowledge of Alembic failure handling, downgrade invocation, recovery steps, and trade-offs like zero-downtime/rollback strategies, strongly separating candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-446",
        "role_title": "Staff Engineer - Distributed Tracing",
        "question": "\"Design a sampling strategy for distributed traces in a microservices environment with 500+ services, where you need to balance cost, data volume, and observability depth. Explain your approach, including key metrics, thresholds, and how you would validate it in production.\"",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core role responsibility of designing sampling strategies for distributed tracing at scale, matches 500+ services scenario perfectly, no red flags. Clarity: Crystal clear with specific context (microservices, 500+ services, balance factors), well-scoped for screening, minor deduction for lacking explicit time/format constraints. Discriminative: Tests applied design thinking, trade-offs (cost vs. observability), metrics, and validation\u2014strong separation of strong vs. weak candidates, not mere recall.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-447",
        "role_title": "Backend Engineer - Load Shedding",
        "question": "\"Design a load shedding mechanism using Go and Envoy that detects backpressure and triggers a graceful degradation strategy. Explain how you would implement adaptive throttling based on real-time metrics from Prometheus, and how you would ensure the system remains resilient during high-load scenarios. Use specific examples of backpressure signals and how they would be translated into throttling policies.\"",
        "scores": {
          "relevance": 9,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (load shedding, backpressure, adaptive throttling) with priority on Go/Prometheus; minor deduction for unmentioned Envoy (-1). Clarity: Well-scoped with specifics but assumes Envoy/Go familiarity without role context. Discriminative: Requires deep applied knowledge of trade-offs, integration, and resilience, strongly separating candidates.",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-448",
        "role_title": "Senior Backend Engineer - Webhook Infrastructure",
        "question": "Design a webhook delivery system in Go that ensures guaranteed delivery using Kafka and PostgreSQL. The system must handle retry logic with exponential backoff, signature verification, and delivery analytics. Implement the core components: webhook receiver, message processor, and delivery tracker. Include error handling, idempotency, and metrics collection. Provide a high-level architecture diagram in text and describe how you would implement the consumer group, idempotency, and retry logic.",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role requirements (guaranteed delivery, retry, signatures, analytics) with exact tech (Go, Kafka, PostgreSQL). Clarity: Precise scope with components listed, minor deduction for lacking strict time/format constraints. Discriminative: Tests deep applied knowledge of distributed systems, trade-offs in retries/idempotency/consumer groups, distinguishes strong candidates.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-449",
        "role_title": "Junior Backend Engineer - Auth Integration",
        "question": "\"Implement a function that handles the OAuth2 authorization code flow with a provider (e.g., Google). The function should:\n1. Receive an authorization code from the client\n2. Exchange it for an access token and refresh token using the provider's token endpoint\n3. Store the tokens securely in a PostgreSQL database (with expiration timestamps)\n4. Return a JWT token for the client to use in subsequent API requests\n5. Include proper error handling for network issues, invalid responses, and expired tokens",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's OAuth focus, token handling, and refresh flows; uses PostgreSQL (common for entry-level backend) without straying. Clarity: Crystal clear steps and scope, minor vagueness on exact DB schema but well-formed for screening. Discriminative: Tests applied OAuth knowledge, security (storage/JWT), DB integration, and error handling\u2014distinguishes those who understand flows from rote memorizers. Minor broadness (-1) but scoped well.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-450",
        "role_title": "Principal Engineer - ML Platform Strategy",
        "question": "\"Describe a recent ML platform decision you made or influenced that had a measurable impact on team productivity or model quality. Walk through the context, your role, the technical approach, and the outcome\u2014specifically how it improved model quality or engineering velocity.\"",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core ML platform strategy, tooling decisions, and impact measurement\u2014perfect match for role. No red flags. Clarity: Crystal clear structure with specific components requested; minor vagueness on 'recent' depth but well-scoped. Discriminative: Forces demonstration of real-world applied experience, trade-offs, and outcomes, strongly separating strategic thinkers from weak candidates. No red flags.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-451",
        "role_title": "Backend Engineer - Subscription Billing",
        "question": "\"Design a system to handle proration for subscription plan changes. Explain how you would calculate the remaining balance after a customer changes plans mid-month, considering usage metering and variable pricing. Include how you would handle edge cases like partial billing cycles, overlapping usage, and plan changes on the last day of the month.\"",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core subscription billing skills (proration, plan changes, usage metering) from role description; no red flags. Clarity: Crystal clear and well-scoped for screening, minor deduction for no explicit time/format constraints. Discriminative: Requires deep applied knowledge of trade-offs and edge cases, strongly separates strong candidates.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-452",
        "role_title": "Senior Backend Engineer - Faceted Search",
        "question": "\"Design a solution to handle faceted search with dynamic filtering in Elasticsearch, ensuring accurate facet counts even when filters are applied. Explain how you'd structure the query, handle edge cases (e.g., overlapping filters, missing data), and optimize performance for large datasets (e.g., 10M+ documents). Address how you'd ensure facet count accuracy and prevent overcounting when multiple filters are applied.\"",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core role skills (faceted search, dynamic filtering, aggregation optimization, scale) using Elasticsearch, no red flags. Clarity: Crystal clear and well-scoped for screening, minor deduction for no explicit time constraint. Discriminative: Tests deep applied knowledge, trade-offs, edge cases, and optimization, strongly separates candidates; appropriately scoped.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-453",
        "role_title": "Backend Engineer - Notification Delivery",
        "question": "\"Design a system to deliver push notifications to mobile devices using FCM and APNS. Your system must handle device registration, batching, and delivery tracking. How would you structure the data model in PostgreSQL to store device registrations and delivery status? Include considerations for scalability, data consistency, and handling device tokens expiration. Provide a brief explanation of how you'd ensure delivery tracking and batching efficiency.\"",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's core requirements (device registration, batching, delivery tracking) with specified protocols (FCM/APNS implied in role context). No red flags.\nClarity: Crystal clear, well-scoped to data model + key considerations; minor deduction as it bundles data model design with explanations but remains focused.\nDiscriminative: Tests deep applied knowledge of modeling for scalability/consistency, trade-offs (e.g., token expiration), and efficiency\u2014strong separation between good and weak candidates.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-454",
        "role_title": "Junior Backend Engineer - ETL Scripts",
        "question": "\"Write a Python script using pandas and PostgreSQL that reads a CSV file, transforms the data (e.g., clean missing values, standardize column names), and loads it into a PostgreSQL table. Include error handling for common issues like missing files or database connection failures. Test your script with a sample CSV and a sample database.\"",
        "scores": {
          "relevance": 9,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core ETL skills (read/transform/load) with pandas (data transformation) and PostgreSQL, perfect for entry-level ETL role; minor ding as scheduling not included (-1). Clarity: Clear and well-scoped but lacks specific constraints like CSV structure or table schema. Discriminative: Requires applied ETL pipeline with error handling and testing, distinguishes practical skills from theory.",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-455",
        "role_title": "Staff Engineer - Developer Portal",
        "question": "\"Design a plugin architecture for a developer portal that allows plugins to dynamically register services and documentation, and explain how you would ensure that these plugins are safely loaded and validated before being used in production.\"",
        "scores": {
          "relevance": 9,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core plugin architecture skill from role (-1 for no explicit tech stack mention). Clarity: Clear intent and well-formed, but lacks minor constraints like scale or time (-2). Discriminative: Excellent at probing trade-offs in dynamic registration, safety, and validation, distinguishing strong architects.",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-456",
        "role_title": "Backend Engineer - Query Optimization",
        "question": "\"Explain how you would use PostgreSQL's `EXPLAIN (ANALYZE)` to identify a query that has a poor execution plan, and walk through a step-by-step process to diagnose and fix the issue using index recommendations based on query patterns and data distribution.\"",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core PostgreSQL query optimization, slow query detection, plan analysis, and index recommendations (-1 for assuming PG as main stack, though fits perfectly). Clarity: Crystal clear, well-scoped step-by-step process with no ambiguity or missing constraints. Discriminative: Requires applied knowledge of EXPLAIN ANALYZE, diagnosis, patterns, and data distribution trade-offs, strongly separates skilled optimizers from basics.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-457",
        "role_title": "Senior Backend Engineer - SLO Automation",
        "question": "\"Design a system to track error budgets and generate burn rate alerts for a set of SLOs. Your solution should use Go and Prometheus to monitor application errors and detect when an SLO is approaching its error budget. Explain how you would structure the data model in Prometheus, how you\u2019d implement the burn rate calculation, and how you\u2019d trigger alerts when the burn rate exceeds a threshold. Include a brief explanation of how you\u2019d handle incident escalation if the burn rate exceeds the threshold.\"",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Directly tests core SLO/error budget tracking, burn rate alerting, and incident escalation from role desc. Specifies Go/Prometheus (relevant stack). Crystal clear with specific components asked. Strong differentiation via design, data modeling, calculations, and trade-offs; minor deduction for no explicit time constraint.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-458",
        "role_title": "Backend Engineer - API Gateway Plugins",
        "question": "You're tasked with creating a Kong plugin that validates JWT tokens using a custom Redis-based token blacklist. The plugin should:\n1. Extract the JWT token from the request header (`Authorization: Bearer <token>`)\n2. Verify the token's signature using a public RSA key stored in Kong's configuration\n3. Check if the token's `jti` (JWT ID) is present in a Redis set of blacklisted tokens\n4. If the token is blacklisted, return a 401 Unauthorized response with a custom error message",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests Kong plugin development, JWT handling, Redis integration, and request/response modification\u2014core to API gateway plugin role (-1 minor for no explicit blacklist Redis details in desc). Clarity: Precise steps, clear requirements, well-scoped for screening. Discriminative: Requires integration of auth, config, Redis, and error handling; tests applied Kong/JWT knowledge with trade-offs (e.g., Redis perf, error cases).",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-459",
        "role_title": "Junior Backend Engineer - Container Security",
        "question": "\"Describe how you would configure Trivy to scan a Docker image for vulnerabilities and ensure that only images with critical and high severity vulnerabilities are allowed to be deployed to production. Include steps for setting up a scan policy, defining severity thresholds, and integrating with a CI/CD pipeline (e.g., GitHub Actions) to enforce this policy before deployment.\"",
        "scores": {
          "relevance": 7,
          "clarity": 9,
          "discriminative": 8,
          "reasoning": "Relevance: Tests core vulnerability scanning skills with Trivy (highly relevant to container scanning role), but deduct -2 for focusing only on one minor tool (Trivy) while ignoring role's main areas like base image management/policy enforcement, and -1 for generic CI/CD without role-specific tech. Clarity: Crystal clear, well-scoped steps with specific expectations, no ambiguity or bundling issues. Discriminative: Requires applied knowledge of configuration, policy setup, thresholds, and integration, testing practical understanding and trade-offs effectively.",
          "composite": 8.0
        }
      },
      {
        "role_id": "be-460",
        "role_title": "Backend Engineer - Experiment Tracking",
        "question": "\"Imagine you're setting up a new experiment tracking system using MLflow and PostgreSQL for storing experiment metadata and metrics. You want to log a model's performance across different hyperparameters, including accuracy, precision, recall, and F1-score. In addition, you want to store model artifacts (e.g., a saved model file) in S3.",
        "scores": {
          "relevance": 9,
          "clarity": 8,
          "discriminative": 8,
          "reasoning": "Relevance: Directly tests core skills (experiment tracking, metric logging, artifact storage) with exact tech stack (MLflow, PostgreSQL, S3) from role; minor deduction for no -1 generic feel. Clarity: Clear scenario and requirements, but lacks explicit constraints on implementation details or scope (-1 for minor vagueness). Discriminative: Requires applied MLflow knowledge, integration trade-offs (DB vs S3), distinguishes candidates with hands-on experience from theorists.",
          "composite": 8.333333333333334
        }
      },
      {
        "role_id": "be-461",
        "role_title": "Senior Backend Engineer - Fraud Detection",
        "question": "\"Design a system to detect fraudulent transactions in real-time using a combination of rule-based triggers and machine learning models. Your response should include:  \n- A high-level architecture overview of the data flow from transaction arrival to fraud score generation  \n- How you would integrate a rule engine (e.g., Drools or a custom one) with the ML model scoring  \n- A description of how you would handle model drift and retraining in a production environment  \n- How you would manage the trade-off between false positives and false negatives in a high-stakes financial system\"",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 10,
          "reasoning": "Directly targets core role skills (real-time fraud pipelines, rule engines, ML integration, drift handling). Crystal clear with specific subpoints scoping response perfectly. Tests deep trade-offs and production concerns, strongly separating strong candidates; no red flags.",
          "composite": 9.666666666666666
        }
      },
      {
        "role_id": "be-462",
        "role_title": "Backend Engineer - Alert Routing",
        "question": "\"Design a smart routing strategy for alerts in a distributed system using Alertmanager. Consider a scenario where alerts from different services (e.g., API gateway, database, cache) are routed based on business impact levels (e.g., high, medium, low). Describe how you would implement alert routing with escalation policies, silence management, and deduplication. Include how you would handle alerts from the same service but with different error types (e.g., 500 vs 404), and how you would ensure alerts are not duplicated during high-volume events (e.g., a database crash affecting multiple endpoints).\"",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's core needs (routing, grouping, escalation, silence, deduplication) and directly uses Alertmanager for alert infrastructure. Clarity: Crystal clear scenario and requirements, well-scoped; minor deduction for no explicit time/format constraints. Discriminative: Tests deep applied knowledge, trade-offs in routing/escalation/dedup across scenarios, strongly separates candidates able to design vs recite basics.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-463",
        "role_title": "Junior Backend Engineer - Full-text Search",
        "question": "How would you implement a full-text search query in PostgreSQL to find all products with a description containing \"wireless\" and a price less than $100, using a ranking function to prioritize results based on relevance? Include a brief explanation of how the ranking works.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Directly tests PostgreSQL full-text search (tsvector/ranking) core to role; clear, scoped query with explanation; distinguishes via applied knowledge of implementation and ranking trade-offs. Minor relevance ding as price filter is tangential but relevant.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-464",
        "role_title": "Staff Engineer - Presence Systems",
        "question": "Design a presence system that tracks user connections in real time using Go, WebSocket, and Redis. How would you ensure that presence state is updated reliably and consistently across clients, especially during network interruptions or client disconnects?",
        "scores": {
          "relevance": 9,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core role skills (presence, connections, state sync) with exact tech stack (Go, WebSocket, Redis); minor deduction for not mentioning heartbeats explicitly. Clarity: Well-scoped design question with clear focus on reliability/edge cases, but lacks explicit constraints like scale or time. Discriminative: Probes deep trade-offs in protocols, consistency, and failure handling, strongly separating strong architects from juniors.",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-465",
        "role_title": "Backend Engineer - CDC Pipelines",
        "question": "\"Design a CDC pipeline using Debezium and Kafka to replicate data from a PostgreSQL database to Snowflake. Explain how you would handle schema changes, initial data snapshot, and ensure exactly-once delivery. Include a specific example of a schema change scenario and how you'd adapt your pipeline.\"",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Directly targets core role skills (CDC, schema changes, snapshots, exactly-once) with exact tech stack. Crystal clear and well-scoped for screening; minor deduction for no explicit time constraint. Strong trade-off testing via design + specific example distinguishes deep applied knowledge.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-466",
        "role_title": "Senior Backend Engineer - GitOps Tooling",
        "question": "\"Design a reconciliation loop for a Kubernetes cluster using ArgoCD with Helm charts, ensuring that the cluster state is kept in sync with the Git repository. Include considerations for handling drift, partial updates, and rollbacks in your design.\"",
        "scores": {
          "relevance": 9,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core GitOps skills (reconciliation, drift, rollbacks) with exact tech (ArgoCD, Helm, K8s); minor ding for not explicitly mentioning tooling design (-1). Clarity: Clear and well-scoped for screening, but lacks explicit constraints like time or detail level (-2). Discriminative: Excellent at testing applied design, trade-offs (drift/partial/rollbacks), separates strong GitOps experts from juniors.",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-467",
        "role_title": "Backend Engineer - Connection Pooling",
        "question": "\"Design a Go service that uses PgBouncer to manage connection pooling for a PostgreSQL database in a Kubernetes environment. The service must support dynamic pool sizing based on workload metrics and handle failover to a standby database when the primary fails. Describe how you would implement the pool sizing logic, the failover mechanism, and how you would ensure the service remains stable during high-load traffic spikes.\"",
        "scores": {
          "relevance": 9,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (pool sizing, failover) with relevant tech (Go, PgBouncer, PostgreSQL, Kubernetes); minor ding as PgBouncer/K8s not explicitly listed (-1). Clarity: Clear and well-scoped, but lacks explicit constraints like time or metrics sources (-1, -1). Discriminative: Excellent at probing trade-offs in dynamic sizing, failover, and stability under load, separating strong candidates.",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-468",
        "role_title": "Junior Backend Engineer - CI Pipelines",
        "question": "\u201cWrite a GitHub Actions workflow that builds and tests a Python package using Docker. Include caching of pip dependencies and parallel job execution for faster testing.\u201d",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests GitHub Actions workflows, Docker builds, pip caching, and parallel testing\u2014core to role's CI pipeline focus (-1 minor for no explicit time constraint). Clarity: Precise scope, unambiguous requirements, well-formed for screening. Discriminative: Requires applied knowledge of syntax, caching strategies, and parallelization trade-offs, separating capable entry-level candidates effectively.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-469",
        "role_title": "Senior Backend Engineer - Chaos Engineering",
        "question": "\"How would you design a failure injection test to simulate a node failure in a Kubernetes cluster using Chaos Mesh, ensuring that the application remains operational and recovers automatically within a defined time window? Include specific configuration details for the Chaos Mesh experiment, such as the target pod, failure duration, recovery validation, and any necessary monitoring integration.\"",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core chaos engineering skills (failure injection, recovery validation) with Kubernetes and Chaos Mesh, matching role focus; minor ding as Chaos Mesh not explicitly listed (-1). Clarity: Crystal clear, well-scoped with specific config details requested, no ambiguity. Discriminative: Requires applied knowledge of Chaos Mesh configs, trade-offs in blast radius/recovery, and integration\u2014strong separation of experts from novices.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-470",
        "role_title": "Backend Engineer - GraphQL Federation",
        "question": "\"Design and implement a GraphQL query plan for a federated subgraph that resolves a query involving a nested object with multiple fields. Specifically, create a schema definition for a `User` type that includes a `posts` field (a list of `Post` objects), and a `Post` type with a `comments` field (a list of `Comment` objects). Each subgraph must return only its own data, and the gateway must resolve references to the nested objects. Explain how the query planning works during execution, including how Apollo Federation determines which subgraphs to query, how it resolves field values, and how it handles potential schema conflicts or missing fields.\"",
        "scores": {
          "relevance": 9,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core federated GraphQL skills (query planning, schema, entity resolution) from role; minor ding for not explicitly mentioning stitching (-1). Clarity: Clear and well-scoped example, but lacks explicit constraints on response format/depth (-1) and bundles schema+planning+explanation (-1). Discriminative: Excellent at testing applied deep understanding of federation mechanics, trade-offs in resolution, and execution\u2014strong separation of experts from juniors.",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-471",
        "role_title": "Staff Engineer - Zero Trust Architecture",
        "question": "\"Describe how you would implement mutual TLS (mTLS) for service-to-service communication in a Kubernetes cluster using SPIFFE and SPIRE, and how you would ensure that mTLS is enforced at both the Envoy proxy and the Kubernetes API server level. Include at only one practical detail about how you would handle certificate lifetime and renewal.\"",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core mTLS automation in Kubernetes microservices (-0 red flags). Clarity: Unambiguous, well-scoped with specific tech (SPIFFE/SPIRE, Envoy, K8s API) and single detail constraint. Discriminative: Requires applied knowledge of integration, enforcement, and trade-offs like cert renewal, distinguishing strong architects.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-472",
        "role_title": "Backend Engineer - Vector Search",
        "question": "What are the key differences between using Pinecone's built-in vector indexing and implementing a custom indexing pipeline with Redis + PostgreSQL for a high-throughput semantic search application? Evaluate each approach in terms of performance, scalability, cost, and accuracy, and explain which you'd choose for a production environment and why.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core vector search/indexing skills with role-relevant tech (Pinecone, Redis+Postgres for hybrid search); minor ding as Pinecone not explicitly listed but fits perfectly (-1). Clarity: Crystal clear, well-scoped evaluation criteria, no ambiguity. Discriminative: Forces trade-off analysis across key dimensions, distinguishes deep production knowledge from superficial recall.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-473",
        "role_title": "Senior Backend Engineer - Refund Processing",
        "question": "Explain how you would design a system to process partial refunds in a payments platform, ensuring data consistency and auditability across distributed components like Kafka, PostgreSQL, and Redis, while handling ledger reconciliation during reconciliation windows. Consider edge cases like provider callbacks, duplicate refunds, and system failures.",
        "scores": {
          "relevance": 9,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core refund processing, ledger reconciliation, audit trails, and provider callbacks from role; uses specified tech (Kafka, PostgreSQL, Redis) - minor deduction for no explicit 'partial refund support' emphasis. Clarity: Clear intent and scope, but 'design a system' lacks explicit time/format constraints. Discriminative: Excellent at probing trade-offs, edge cases, and deep distributed systems understanding for strong candidate separation.",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-474",
        "role_title": "Backend Engineer - Dashboards API",
        "question": "Design a Go endpoint that allows a user to create or update a Grafana dashboard template with variable substitutions. The endpoint should accept a JSON payload containing a dashboard JSON structure and a list of variables (e.g., `{ \"name\": \"env\", \"options\": [\"prod\", \"staging\"] }`). The template should support variable substitution using the format `{{env}}` in the dashboard JSON. The endpoint must validate that:\n1. All variable names in the template are defined in the input.\n2. Variable values are properly substituted into the final dashboard JSON.\n3. The input dashboard JSON is valid (e.g., correct structure, no syntax errors).\n4. The output dashboard JSON has no remaining `{{variable}}` placeholders.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests Go API development, JSON handling, and variable substitution core to dashboard template role (-1 for no explicit role tech stack like DB/storage). Clarity: Well-scoped design question with precise requirements and validation rules. Discriminative: Requires applied Go skills, validation logic, substitution implementation, and edge-case handling to separate strong candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-475",
        "role_title": "Junior Backend Engineer - Search Analytics",
        "question": "Explain how you would design a system to log and analyze search queries for a web application, including how you'd collect query data, store it, and visualize it using Elasticsearch and Kibana. Focus on the key components and trade-offs.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Directly targets core role skills (query logging, analytics) with exact tech stack (Elasticsearch/Kibana). Crystal clear with focused scope on components/trade-offs; strong separation via design reasoning and trade-offs, not recall. Minor ding for entry-level breadth but well-scoped for screening.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-476",
        "role_title": "Backend Engineer - Live Updates",
        "question": "\"Imagine you're building a live dashboard where users can join rooms to view real-time data updates. Each room can have multiple users, and only users in the same room should receive updates. When a user joins a room, they must be able to reconnect later with their state preserved\u2014this includes their current room assignment and any pending updates from previous sessions. Design a solution using Socket.io and Redis to handle room management, selective broadcasting, and reconnection preservation. Explain how you'd structure your code to manage the state of users and rooms, and how you'd ensure that when a user reconnects, they get their previous room and any pending updates.\"",
        "scores": {
          "relevance": 9,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (room mgmt, selective broadcast, reconnection) with exact tech stack (Socket.io, Redis); minor generic feel -1. Clarity: Well-scoped design question with clear requirements, but lacks explicit constraints like scale or time (-1 from red flag). Discriminative: Probes deep applied knowledge, trade-offs in state mgmt/pub-sub/reconnection, excellent separation of strong vs weak candidates.",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-477",
        "role_title": "Senior Backend Engineer - Data Catalog",
        "question": "\"Describe how you would design a system to automatically extract and store lineage information from a data pipeline using Apache Atlas, Kafka, and Airflow. Include details on how you would capture the source and target of data movements, how you would handle schema changes, and how you would ensure data lineage is updated in real-time as the pipeline runs.\"",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly targets core role skills (lineage tracking, automated metadata) using relevant tools; no red flags. Clarity: Crystal clear, well-scoped with specific aspects to cover; minor deduction for lacking explicit time/format constraints. Discriminative: Tests applied design knowledge, trade-offs (schema changes, real-time), distinguishes strong big data engineers.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-478",
        "role_title": "Backend Engineer - Cost Attribution",
        "question": "What are the key challenges in building a cost attribution system that accurately assigns cloud costs to teams or projects, and how would you design a solution using Go, Kubernetes, and Prometheus to track and report on cost allocation?",
        "scores": {
          "relevance": 9,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core role skills (cost attribution, team allocation) and matches tech stack (Go, K8s, Prometheus for cloud resource tracking); minor ding for not explicitly mentioning tagging/chargebacks. Clarity: Clear intent and well-scoped for screening, but lacks specific constraints like scale or time. Discriminative: Excellent at probing challenges (accuracy, tagging issues) and design trade-offs (e.g., Prometheus metrics for costs, K8s integration), separating strong systems thinkers from weak ones.",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-479",
        "role_title": "Principal Engineer - Data Architecture",
        "question": "\"Design a data architecture for a company that processes 10 million transactions per day and runs daily analytics on 50 million rows of data. The system must support low-latency transactional operations (sub-second response time) and real-time dashboards with a 10-second latency requirement. The solution must be scalable, resilient, and maintain data consistency across all workloads. Suggest the component structure, data flow, and technologies for each component. Explain how you would ensure data consistency between transactional and analytical workloads, and how you would handle data freshness and latency requirements. Be specific about how you would balance OLTP and OLAP workloads. Also, describe how you would monitor and validate data quality across the system.\"",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core data architecture strategy for mixed OLTP/OLAP workloads, scalability, tech selection, and team guidance as per role; no red flags. Clarity: Well-scoped with specific volumes, latencies, and requirements; minor deduction for lacking explicit time/format constraints. Discriminative: Probes deep trade-offs in consistency, freshness, balancing workloads, monitoring\u2014strong separation of strong vs weak candidates; not trivial recall or overly broad.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-480",
        "role_title": "Junior Backend Engineer - Deployment Automation",
        "question": "*You're deploying a Python application to AWS using Docker and Ansible. The app has a config file `app.conf` that must be copied to the server with the correct ownership and permissions. How would you ensure the config file is correctly copied, set with 644 permissions, and owned by the `appuser` user? Provide a relevant Ansible task and explain how it ensures correctness.*",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests Ansible for config management and deployment scripting, core to role (-0 red flags). Clarity: Precise scope, unambiguous task with exact requirements. Discriminative: Requires applied Ansible knowledge (module usage, params), explanation tests understanding of idempotency/permissions, strong separation without being trivial or broad.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-481",
        "role_title": "Backend Engineer - Canary Deployments",
        "question": "\"Design a canary deployment strategy using Istio and ArgoCD to promote a new version of a Go service with automated rollback based on traffic and metrics. Explain how you would ensure reliability during the rollout, including traffic shifting, monitoring, and rollback triggers.\"",
        "scores": {
          "relevance": 9,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core role skills (canary deployments, traffic shifting, metrics, rollback) with Istio/ArgoCD fitting infra focus; minor deduct for assuming specific tools not explicitly listed (-1). Clarity: Well-scoped design question but lacks explicit constraints like time or metrics thresholds (-1, -1 red flag). Discriminative: Excellent at testing applied knowledge, trade-offs in reliability, monitoring, and triggers; strong separation of strong vs weak candidates.",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-482",
        "role_title": "Senior Backend Engineer - API Monetization",
        "question": "\"Design a system to track API usage and enforce quotas for a multi-tenant SaaS platform using Go, PostgreSQL, and Redis. Your solution must support:\n- Per-tenant, per-API endpoint usage tracking\n- Real-time quota enforcement (e.g., 1000 requests per day, 100 requests per minute)\n- Rate limiting at both the endpoint and tenant level\n- Cost calculation based on usage (e.g., tiered pricing: free tier 10,000 requests/day, paid tier 100,000 requests/day)",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (usage tracking, quotas, pricing tiers) with exact tech stack (Go, PostgreSQL, Redis). No red flags. Clarity: Crystal clear with specific requirements, but lacks minor constraints like time limit (-1). Discriminative: Tests applied system design, trade-offs (real-time enforcement, multi-level limiting), and deep understanding; strong separation without being too broad.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-483",
        "role_title": "Backend Engineer - WAF Integration",
        "question": "How would you implement a custom ModSecurity rule in Go to detect and block a specific attack pattern (e.g., SQL injection) in an Nginx-based web application, including the handling of rate limiting and logging to Redis?",
        "scores": {
          "relevance": 7,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Tests core WAF rule management, attack pattern detection (SQLi), rate limiting, and logging\u2014directly matches role focus, but Go/Nginx/ModSecurity not explicitly listed (-2 for unlisted tech, -1 generic elements). Clarity: Well-scoped with specific example and components, minor ambiguity on Nginx-Go integration. Discriminative: Requires applied knowledge of rules, integration, rate limiting trade-offs, and Redis\u2014strong separation of strong vs weak candidates.",
          "composite": 8.0
        }
      },
      {
        "role_id": "be-484",
        "role_title": "Staff Engineer - Model Registry",
        "question": "\"Design a model registry system using MLflow and S3 for storing model versions, with automatic versioning and metadata tracking. How would you implement a solution that ensures each model version is uniquely identifiable, tracks metadata (e.g., model parameters, training date, environment), and handles version conflicts when multiple teams are developing and deploying models concurrently?\"",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Directly targets core role skills (model registry, versioning, governance) using specified tech (MLflow, S3). Crystal clear with precise scope, tests applied design knowledge, trade-offs (e.g., conflicts), and multi-team concurrency. Minor ding for no explicit time constraint, but well-scoped overall.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-485",
        "role_title": "Junior Backend Engineer - Payment Webhooks",
        "question": "How would you design a Python FastAPI endpoint to safely process a Stripe payment webhook? Include considerations for signature verification, idempotency, and logging.",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Directly tests core role skills (signature verification, idempotency, event processing) with exact tech stack (Python FastAPI, Stripe). Crystal clear and well-scoped for screening, though minor deduction for no explicit time constraint. Strong trade-off testing (safety considerations) differentiates strong entry-level candidates.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-486",
        "role_title": "Backend Engineer - Span Processing",
        "question": "\"Design a tail sampling strategy for a distributed tracing pipeline using OpenTelemetry and Kafka. The pipeline ingests spans from distributed services, and you need to ensure that only a small fraction (e.g., 0.1%) of the total spans are stored in ClickHouse for long-term analysis. Your design must account for high-volume, high-velocity span data and must minimize data drift and ensure observability of low-frequency events. Consider how to implement this in Go using OpenTelemetry SDK, how to configure sampling decisions at the span level, and how to handle the tail sampling logic in a scalable, fault-tolerant way across a distributed system. Explain your approach to sampling decisions, the trade-offs, and how you would ensure data completeness for rare events.\"",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 10,
          "reasoning": "Relevance: Directly targets core role skill (tail sampling in span pipeline) with exact tech (OpenTelemetry, Kafka, ClickHouse, Go); minor ding as ClickHouse storage not explicitly core but fits optimization. Clarity: Precise scope, constraints (0.1%, high-volume), unambiguous despite length. Discriminative: Excellent at probing deep trade-offs, scalability, fault-tolerance, and rare event handling, strongly separating experts.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-487",
        "role_title": "Senior Backend Engineer - Search Ranking",
        "question": "\"Design a feature pipeline for a learning-to-rank model that ranks search results by relevance. The pipeline should extract features from raw search queries and documents, compute relevance scores, and store them in Elasticsearch for ranking. Describe how you would structure the pipeline, including data sources, feature extraction methods, how you would handle scalability, and how you would ensure feature consistency and quality.\"",
        "scores": {
          "relevance": 9,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core role skills (feature engineering, LTR pipelines) with minor ding for specifying Elasticsearch (-1, not in role desc). Clarity: Well-formed and scoped but lacks explicit constraints like time/depth (-1, 8 range) or A/B testing mention. Discriminative: Excellent at probing applied ML engineering, trade-offs (scalability, quality), distinguishes deep thinkers from superficial ones.",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-488",
        "role_title": "Backend Engineer - Gaming Backend",
        "question": "\"Design a state synchronization mechanism for a multiplayer game where players are in different rooms (e.g., room A has 2 players, room B has 3 players). When a player performs an action (e.g., move or shoot), that action must be immediately reflected in the client's view, but only for players in the same room. How would you implement this using Go, WebSocket, and Redis? Include a consideration for handling network latency and disconnections.\"",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core state synchronization for multiplayer game backend with exact tech stack (Go, WebSocket, Redis); minor deduction as role also emphasizes matchmaking/anti-cheat. Clarity: Crystal clear scope (room-based, immediate client reflection, specific tech), well-constrained for screening. Discriminative: Requires applied knowledge of real-time systems, trade-offs in latency/disconnections, strong separation of strong vs weak candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-489",
        "role_title": "Backend Engineer - Data Quality",
        "question": "\"Describe how you would implement a data freshness check for a critical table in a Snowflake warehouse using dbt and Great Expectations. Include how you would define the freshness expectation, set up a scheduled check, and ensure it triggers a warning if the table is not updated within a specified time window.\"",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core data quality monitoring (freshness checks) in Snowflake warehouse with exact tools (dbt, Great Expectations) from role. No red flags. Clarity: Precise, well-scoped steps; minor vagueness on scheduling details but excellent overall. Discriminative: Requires applied knowledge of tool integration, configuration, and alerting logic for strong candidate separation; tests trade-offs implicitly (e.g., time windows).",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-490",
        "role_title": "Senior Backend Engineer - Environment Management",
        "question": "\"Design a system to manage preview environments for a Kubernetes cluster using ArgoCD and Terraform. The system must ensure namespace isolation, enforce resource quotas, and automatically clean up environments that are no longer in use after a TTL. Describe how you would implement this using Go, Kubernetes, ArgoCD, and Terraform. Include a high-level design of your solution, and explain how each component contributes to achieving the isolation, quota enforcement, and cleanup requirements.\"",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's core requirements (namespace isolation, quotas, TTL cleanup) and specifies exact tech stack (Kubernetes, ArgoCD, Terraform, Go). No red flags.\nClarity: Crystal clear, well-scoped high-level design with specific requirements and components; minor deduction for lacking explicit time/format constraints.\nDiscriminative: Tests deep applied knowledge, trade-offs in system design, and integration of multiple tools, strongly separating strong candidates.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-491",
        "role_title": "Junior Backend Engineer - Read Replicas",
        "question": "*You're building a read replica router that routes read queries to the appropriate replica based on a query's \"readiness\" score. The readiness score is calculated as:*",
        "scores": {
          "relevance": 2,
          "clarity": 3,
          "discriminative": 4,
          "reasoning": "Relevance: Directly mentions read replica routing (core to role) but no role description provided to confirm tech stack; feels generic/incomplete (-3 generic). Clarity: Incomplete question cuts off mid-sentence, leaving formula undefined and no actual ask (multiple interpretations, broken). Discriminative: Partial setup hints at lag/trade-offs but no task specified, so trivial or impossible to answer properly.",
          "composite": 3.0
        }
      },
      {
        "role_id": "be-492",
        "role_title": "Backend Engineer - CD Pipelines",
        "question": "\"Design a GitOps-based CI/CD pipeline using ArgoCD and GitHub Actions that deploys a Go application to staging and production environments. Include how you would implement multi-environment promotion, approval gates, and rollback automation. Explain your architecture, decision points, and how you\u2019d ensure security and reliability.\"",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's core focus on GitOps pipelines, multi-env promotion, approvals, rollbacks; directly tests required skills with relevant tools (ArgoCD aligns with GitOps, GitHub Actions common for CI/CD). No red flags. Clarity: Well-scoped design question with specific components listed; minor deduction as no explicit time/format constraints but excellent for screening. Discriminative: Requires architecture, trade-offs (security/reliability decisions), applied GitOps knowledge; strong separation of strong vs weak candidates. Minor deduction for potential breadth exceeding 10min if overly verbose.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-493",
        "role_title": "Staff Engineer - Reliability Standards",
        "question": "\"Imagine you're leading a production readiness review (PRR) for a new Kubernetes cluster being deployed to production. The team has proposed a 99.99% uptime SLA for a critical microservice. How would you define the reliability standards for this service, including measurable metrics, failure modes, and incident response requirements? Provide a concrete example of how you would evaluate a candidate's proposed PRR checklist, including at least one metric you'd validate and one failure mode you'd investigate.\"",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role responsibilities (reliability standards, PRR, SRE practices) with Kubernetes context fitting production deployment; no red flags. Clarity: Well-scoped scenario with specific asks (metrics, failure modes, response), minor deduction for lacking explicit time/format constraints. Discriminative: Requires applied SRE knowledge, trade-offs in SLAs/metrics, and evaluation skills, strongly separating experienced SREs from juniors; not mere recall.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-494",
        "role_title": "Backend Engineer - API Mocking",
        "question": "Explain how you would design a WireMock setup to mock a user authentication API that returns different responses based on the request headers, including:\n- A 200 OK response with a valid JWT token for authenticated users (header: `X-User-Id: 123`)\n- A 401 Unauthorized response for unauthenticated users (no `X-User-Id` header)\n- A 403 Forbidden response for users with invalid IDs (header: `X-User-Id: 999`)\n- Support dynamic response templating using a JSON template that includes the user ID in the response body",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests WireMock (core for API mocking), request matching via headers, response templating, and conditional responses - matches role's focus perfectly (-0 red flags). Clarity: Precise scenarios, specific headers/responses, well-scoped for screening, unambiguous. Discriminative: Requires applied WireMock knowledge (matchers, transformers, templating), trade-offs in setup, distinguishes practical expertise from theory.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-495",
        "role_title": "Senior Backend Engineer - Audit Logging",
        "question": "How would you design a tamper-proof audit logging system using Go, Kafka, and ClickHouse, ensuring that log entries are immutable, securely stored, and can be queried efficiently for compliance purposes?",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (tamper-proof storage, immutability, querying for compliance) using exact tech stack (Go, Kafka, ClickHouse). Clarity: Crystal clear intent and scope for screening, minor deduction for lacking explicit time/format constraints. Discriminative: Requires deep trade-offs in immutability, distributed systems, and tech integration, strongly separating strong candidates.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-496",
        "role_title": "Junior Backend Engineer - Model Serving",
        "question": "*You are deploying a simple ML model via FastAPI. The model is loaded from a `.pkl` file and served via a `/predict` endpoint. Describe how you would structure the FastAPI app to handle model loading, request batching, and basic monitoring (e.g., request count and latency). Include a brief explanation of how batching improves performance and why you might use Redis for request queuing in a production environment.*",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Directly tests core role skills (model loading from .pkl, FastAPI deployment, batching, monitoring) for entry-level ML API engineer. Crystal clear with specific components and scope; asks for applied structure + explanations of trade-offs (batching benefits, Redis use), distinguishing strong candidates. Minor ding for assuming Redis familiarity, but fits production context well.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-497",
        "role_title": "Backend Engineer - Payout Systems",
        "question": "\"Design a system to process daily payout batches for a marketplace with 10,000+ merchants. Each merchant has a daily payout amount, and payouts are sent to different banks via a secure, auditable channel. The system must handle failures, ensure data consistency, and provide reconciliation logs. Describe your approach, including data flow, error handling, and how you'd ensure auditability and consistency.\"",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's core focus on payout systems, batch processing, bank handling, validation, and reconciliation; no red flags. Clarity: Crystal clear with specific scale (10k+ merchants), requirements, and scoped to approach/data flow/error handling; minor deduction for lacking exact time/format constraints. Discriminative: Tests applied system design, trade-offs in failures/consistency/auditability, strongly separates candidates with real-world understanding from superficial ones; not trivial or overly broad.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-498",
        "role_title": "Senior Backend Engineer - Profiling Infrastructure",
        "question": "\"Describe how you would design a continuous profiling system using Pyroscope for Go applications running in Kubernetes, including how you'd collect, store, and analyze flame graphs. Specifically, profile a Go service that runs in a Kubernetes pod, and explain how you'd handle baseline comparisons to detect performance regressions over time.\"",
        "scores": {
          "relevance": 9,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core skills (continuous profiling, flame graphs, baseline comparison) and matches role focus; minor ding for specifying Pyroscope (not in role desc, -1) but it's profiling infra. Clarity: Well-scoped with specifics but lacks minor constraints like scale (-1 from 9). Discriminative: Requires applied design knowledge, trade-offs in K8s/Pyroscope/Go, strong separation of strong vs weak candidates.",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-499",
        "role_title": "Principal Engineer - Search Platform",
        "question": "*You have a search platform running on Elasticsearch, which is heavily used across an enterprise. Recently, a new team started using the platform, and their queries are causing a significant increase in latency and resource consumption. After reviewing the logs and metrics, you find that the new team uses a large number of wildcard queries (e.g., `*field*`, `*value*`) and complex boolean combinations. These queries are not being cached and are hitting the cluster frequently. How would you diagnose and resolve this issue to improve performance without compromising the platform\u2019s reliability or stability?*",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core Elasticsearch/search platform optimization skills critical for defining enterprise strategy and operational excellence (-0 red flags). Clarity: Crystal clear scenario with specific issues, well-scoped for screening (no red flags). Discriminative: Requires deep applied knowledge of ES query pitfalls, caching, diagnosis (logs/metrics), and trade-offs (e.g., ngrams vs wildcards, query rewriting), strongly separating experts from juniors.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-500",
        "role_title": "Staff Engineer - Streaming Architecture",
        "question": "\"Design a real-time event streaming pipeline that delivers user activity events to multiple downstream services with exactly-once semantics and low latency. The system must handle up to 100k events per second. Describe your architecture, the tools you\u2019d use, and how you\u2019d ensure exactly-once delivery. Be specific about how you\u2019d handle fan-out and message ordering. Also, exactly-once delivery must be achieved at the system level, not just via a single component.\"",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's focus on streaming infrastructure, event schemas (implied), delivery guarantees (exactly-once), and fan-out patterns; no red flags. Clarity: Crystal clear and well-scoped with throughput and specifics, minor deduction for no explicit time constraint. Discriminative: Tests deep applied knowledge, trade-offs in tools/architecture, fan-out, and system-level guarantees, strongly separates candidates; not trivial or recall-based.",
          "composite": 9.333333333333334
        }
      }
    ]
  },
  "grok-4-1": {
    "model": "grok-4-1",
    "num_samples": 100,
    "avg_relevance": 9.16,
    "avg_clarity": 9.06,
    "avg_discriminative": 9.02,
    "avg_composite": 9.080000000000002,
    "results": [
      {
        "role_id": "be-406",
        "role_title": "Senior Backend Engineer - LLM Serving",
        "question": "**Question:**  \nIn vLLM, explain how continuous batching works for LLM inference and describe one optimization you've implemented (or would implement) for KV cache management in a production serving setup using Python and vLLM. (2-3 sentences)",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Directly tests core role skills (batching optimization, KV cache management) using vLLM, which aligns perfectly with LLM serving infrastructure; clear scoping (2-3 sentences, explain + one optimization) avoids ambiguity; strong separation via applied knowledge requiring trade-offs/experience, not just recall, while personal implementation tests depth.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-403",
        "role_title": "Backend Engineer - Inference Optimization",
        "question": "**Question:**  \nYou're optimizing a latency-sensitive transformer model for inference using TensorRT on a single GPU. The model experiences high tail latency due to variable input sizes. Describe a step-by-step approach (including code snippets if relevant) to implement dynamic batching and INT8 quantization in TensorRT to reduce p99 latency by at least 50%, while ensuring GPU memory usage stays under 80%. What trade-offs would you monitor?",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 10,
          "reasoning": "Relevance: Directly targets core role skills (quantization, batching, GPU memory) with TensorRT for transformer inference; minor ding as TensorRT not explicitly listed but fits optimization focus (-1). Clarity: Precise scope, constraints, and expectations; no bundling or vagueness. Discriminative: Requires deep applied knowledge, trade-offs, and practical steps, strongly separating experts from pretenders.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-404",
        "role_title": "Senior Backend Engineer - Feature Platform",
        "question": "**Question:**  \nImagine you're building a feature platform using Feast and need to compute a user's average transaction amount over the last 7 days (with a 1-day lookback window) for real-time ML serving via Redis. Walk me through how you'd define the feature view in Feast, including the entities, aggregation, and online serving setup in Python. What key considerations would you have for latency and data freshness?",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests Feast (core to feature platforms), feature computation, online serving (Redis), and discovery\u2014perfect match for role (-0 red flags). Clarity: Precise scope, unambiguous, well-formed with specific params, no bundling or vagueness. Discriminative: Requires applied Feast knowledge (feature view definition, entities, agg, serving), plus trade-offs (latency/freshness), distinguishing strong ML platform engineers from weak ones.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-408",
        "role_title": "Junior Backend Developer - Health Endpoints",
        "question": "**Question:**  \nIn Go, implement a simple HTTP handler for a `/healthz` liveness probe endpoint that returns a 200 OK status if the application is healthy (e.g., a database connection is available) or a 500 status if not. Assume a global `dbHealthy` bool variable tracks the DB status (set it to `true` initially). Use the `net/http` package and keep it under 20 lines.\n\n*(Follow-up: How would you expose this endpoint's response time as a Prometheus metric?)*",
        "scores": {
          "relevance": 9,
          "clarity": 10,
          "discriminative": 9,
          "reasoning": "Directly tests core role skills (health checks/liveness probes in Go) with exact endpoint and assumptions. Crystal clear with line limit and stdlib constraint. Applied coding + follow-up on metrics tests trade-offs (strong separation). Minor ding on relevance for assuming global var (not idiomatic), but spot-on for entry-level role focus.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-401",
        "role_title": "Backend Engineer - Training Infrastructure",
        "question": "**Question:**  \nIn a Kubernetes cluster with multiple GPU nodes, you're using Ray to launch a distributed PyTorch training job for a large language model. The job needs 4 GPUs across 2 nodes but fails with a scheduling error. Walk me through 3 practical steps you'd take to debug and resolve GPU allocation issues in this setup (using Python/Ray/K8s commands or configs). \n\n*(Expected: Quick mentions like `ray status`, `kubectl describe pod`, checking RayCluster CRD GPU requests/limits, node taints/labels, or `nvidia-smi` via debug pod.)*",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core skills in distributed ML infra (K8s, Ray, PyTorch, GPU allocation/scheduling) matching role; no red flags (-1 for minor tech like nvidia-smi but central to GPU issues). Clarity: Precise scenario, specific ask for 3 steps with command examples, well-scoped; expected answer clarifies without ambiguity. Discriminative: Requires applied debugging knowledge and trade-offs in real Ray/K8s GPU setup, distinguishes practitioners from theorists; not recall or trivial.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-402",
        "role_title": "Backend Engineer - Model Deployment",
        "question": "**Question:**  \nYou're deploying a new version of a machine learning model to production using KServe on Kubernetes. Describe a step-by-step Python-based approach (using KServe SDK or kubectl) to perform a canary deployment with 10% traffic initially, monitor for errors, and automate a full rollout or rollback if latency exceeds 200ms or error rate >5%. Include key code snippets or commands.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core model deployment, Kubernetes, canary strategies, monitoring, and automation (-1 for no explicit KServe mention in role, but perfect fit otherwise). Clarity: Crystal clear, well-scoped steps with specific metrics, no bundling or ambiguity. Discriminative: Requires applied knowledge of KServe/K8s, Python automation, monitoring integration, and trade-offs in rollout/rollback, strongly separates skilled candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-410",
        "role_title": "Backend Engineer - Bulk Operations",
        "question": "**Question:**  \nYou're building a Go API endpoint that accepts a bulk request to update up to 1,000 user records in PostgreSQL (e.g., via a JSON array of user IDs and updates). The operation must be idempotent, support partial success (e.g., some updates succeed, others fail due to constraints), and use Kafka for async processing of successes/failures.\n\nDescribe your high-level approach in Go, including:  \n1. How you'd ensure idempotency.  \n2. How you'd handle batching/partial failures in PostgreSQL.  \n3. The Kafka integration flow.  \n\nSketch a simple code outline or pseudocode for the handler if it helps explain. (Answer in 2-5 minutes.)",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core role needs (bulk ops, idempotency, partial success) with exact tech stack (Go, PostgreSQL, Kafka, JSON arrays); minor -1 for assuming Kafka scale not explicit. Clarity: Precise scope (up to 1k, specific subpoints, 2-5 min limit, pseudocode optional). Discriminative: Requires applied trade-offs (idempotency patterns, batch SQL strategies, Kafka flows), separates strong candidates via reasoning depth vs rote answers.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-409",
        "role_title": "Junior Backend Engineer - File Upload",
        "question": "**Question:**\n\nIn a FastAPI endpoint for file uploads, how would you implement basic validation to ensure only image files (under 5MB) are accepted? Provide a short code snippet showing the endpoint, including file reading, size/content-type checks, and a clear error response if invalid.\n\n*(Expected: Use `UploadFile`, check `content_type` starts with 'image/', read bytes to verify size < 5*1024*1024, return 400 error if invalid. Tests practical FastAPI file handling at junior level.)*",
        "scores": {
          "relevance": 9,
          "clarity": 10,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core file upload validation and FastAPI (matches role's multipart uploads, validation focus); minor deduction as role doesn't explicitly list FastAPI (-1). Clarity: Crystal clear with specific requirements, expected checks, and scoped for short snippet. Discriminative: Requires practical applied knowledge of UploadFile, content_type/size checks, error handling\u2014distinguishes juniors who can code it from those who can't; not mere recall.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-411",
        "role_title": "Backend Engineer - Admin APIs",
        "question": "**Question:**  \nYou're building a FastAPI endpoint for an admin to delete a user account, which requires privileged access and must log the action for audit purposes. The endpoint uses PostgreSQL for user data and Redis for session caching.  \n\nOutline the key steps and code structure (in Python/FastAPI) to:  \n1. Authenticate and authorize the admin (e.g., via JWT or API key).  \n2. Perform the deletion atomically.  \n3. Log the audit trail to PostgreSQL.  \n4. Invalidate any related Redis cache.  \n\nProvide a high-level code snippet focusing on dependencies, security checks, and error handling. (No need for full implementation.)",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (admin APIs, privileged access, audit logging) with exact tech stack (FastAPI, PostgreSQL, Redis); minor ding for assuming JWT/API key. Clarity: Crystal clear, well-scoped with numbered steps, high-level snippet request, no ambiguity. Discriminative: Requires applied knowledge of auth, transactions, auditing, caching invalidation, and error handling trade-offs, strongly separates strong candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-414",
        "role_title": "Senior Backend Engineer - Long-Polling",
        "question": "**Question:**  \nIn a Go-based long-polling API for async operations (using Redis for state storage and PostgreSQL for persistence), describe how you'd implement connection management and timeout handling for a `/poll/{operationId}` endpoint. Include key Go code snippets for the handler, a timeout mechanism (e.g., context with deadline), and a fallback strategy if the connection hangs. What Redis operations would you use to check operation status?",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's core focus on long-polling APIs, connection management, timeout handling, fallback strategies, with exact tech stack (Go, Redis, PostgreSQL). No red flags. Clarity: Crystal clear, well-scoped for screening with specific endpoint and examples; minor deduction for lacking explicit time/format constraints. Discriminative: Tests applied deep knowledge, trade-offs (timeouts, fallbacks), code snippets, and Redis ops, strongly separating strong candidates; not trivial recall or too broad.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-405",
        "role_title": "Senior Backend Engineer - Model Monitoring",
        "question": "**Question:**  \nIn a production ML system, you've detected data drift in one of your models using a statistical test like Kolmogorov-Smirnov. Walk me through how you'd implement an automated alerting pipeline for this using Python, Prometheus, and Grafana. What key metrics would you expose, and how would you configure the alert to avoid false positives? (Feel free to sketch pseudocode or a high-level architecture.)",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly targets core role responsibilities (drift detection, alerting automation) with exact tech stack implied for production ML monitoring. Clarity: Crystal clear, well-scoped with specific tools and asks for architecture/pseudocode; minor deduction for no strict time constraint. Discriminative: Requires applied knowledge of drift handling, metrics, alerting config, and false positive mitigation\u2014tests trade-offs and integration deeply, strong separation.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-416",
        "role_title": "Staff Backend Engineer - External APIs",
        "question": "**Question:**  \nAs a Staff Backend Engineer leading our external API strategy, imagine we're designing a monetized API for partners using Go, OpenAPI specs, and Kong as the gateway on Kubernetes. Walk me through your approach to implementing rate limiting that supports multiple partner tiers (e.g., free, pro, enterprise) while ensuring fair usage and scalability. What key OpenAPI annotations, Kong plugins, and Go middleware patterns would you use, and why?",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core role responsibilities (API strategy, partner enablement, monetization) with exact tech stack (Go, OpenAPI, Kong, Kubernetes); no red flags. Clarity: Crystal clear scenario, well-scoped to rate limiting with specific tech; minor deduction for lacking explicit time constraint. Discriminative: Tests applied knowledge, trade-offs (fairness, scalability, tiers), and integration of multiple tools, strongly separating strong candidates who can reason through patterns from weak ones.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-415",
        "role_title": "Senior Backend Engineer - Multipart APIs",
        "question": "**Question:**  \nIn FastAPI, describe how you would implement a resumable multipart upload endpoint for large files to S3, including how to handle chunked requests, track upload progress/state (e.g., via a database or Redis), and resume interrupted uploads. Provide a high-level code structure with key dependencies like `boto3` and mention any relevant S3 multipart upload APIs you'd use (e.g., `create_multipart_upload`). What challenges might arise with concurrent chunk uploads, and how would you address them?",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's core focus on multipart APIs, resumable uploads, chunk management, and S3 integration with exact tech stack (FastAPI, boto3). No red flags. Clarity: Crystal clear, well-scoped for screening with specific components requested; minor deduction for no explicit time constraint. Discriminative: Tests deep applied knowledge, trade-offs (concurrency challenges), and architecture decisions, strongly separating strong candidates.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-413",
        "role_title": "Senior Backend Engineer - API Gateway Logic",
        "question": "**Question:**  \nIn Envoy, you're building a custom Lua filter for an API gateway to transform incoming requests by adding a custom `x-user-id` header based on a JWT token in the `Authorization` header. The JWT is signed with RS256 and contains a `sub` claim.\n\nProvide a concise Lua script snippet (10-20 lines) for the `onRequest` phase that:  \n1. Extracts and validates the JWT (basic signature check not required, just decode).  \n2. Pulls the `sub` claim.  \n3. Adds it as `x-user-id` header if valid, or returns a 401 response if invalid/missing.  \n\nWhat headers would you inspect or set, and how do you handle errors? (Answer in code + 1-2 sentences explanation.)",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests Envoy Lua filters, JWT handling, and request transformation\u2014core to API gateway extensions (-1 minor for not explicitly listing Envoy/Lua/JWT but perfectly matches role). Clarity: Crystal clear scope, line limit, specific requirements, and format. Discriminative: Requires applied Lua/Envoy/JWT knowledge with error handling and trade-offs, distinguishing strong candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-407",
        "role_title": "Staff Backend Engineer - ML Infrastructure",
        "question": "**Question:**  \nYou're leading the migration of our distributed ML training jobs from Kubernetes-native setups to Ray on Kubernetes for better scalability. Walk me through your 3-step plan to ensure a smooth rollout, including how you'd handle cost optimization and one key failure mode you'd monitor for.\n\n*(Expected answer outline: 1) Pilot with shadow traffic/canary deploys; 2) Tune Ray cluster autoscaling + spot instances for cost; 3) Monitor for node failures via Ray dashboard/ Prometheus. Probes leadership in ML infra platforms.)*",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core ML infra leadership skills (Ray/K8s migration, scaling, cost opt), matches role perfectly (-0 red flags). Clarity: Unambiguous 3-step structure with specific inclusions, well-scoped for screening. Discriminative: Requires applied trade-offs (pilot strategy, cost tuning, failure monitoring), separates leaders with Ray/ML infra depth from generalists.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-417",
        "role_title": "Junior Backend Developer - Event Sourcing",
        "question": "**Question:**\n\nIn an event-sourced system using Kafka and Java, you have an `Order` aggregate. An `OrderCreated` event is published to a Kafka topic. \n\nWrite a short Java code snippet (5-10 lines) for a simple **event handler** that loads the current aggregate state from a repository, applies the `OrderCreated` event to build the initial state (e.g., set order ID and status to \"PENDING\"), and saves the updated state back to PostgreSQL.\n\n*(No need for full Kafka consumer setup or DB connection details\u2014just focus on the handler logic.)*\n\n**Expected Answer Outline (for recruiter reference):**  \n```java\npublic class OrderEventHandler {\n    private OrderRepository repo;\n\n    public void handle(OrderCreated event) {\n        Order order = repo.load(event.getOrderId()).orElse(new Order()); // Load or init\n        order.apply(event); // e.g., order.setId(event.getOrderId()); order.setStatus(\"PENDING\");\n        repo.save(order);\n    }\n}\n```\n*(Tests: event application to aggregate, basic repo interaction, event sourcing flow\u2014junior level, no complex projections/distribution needed.)*",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly targets event sourcing core (event handlers, aggregate state, repo interaction) for entry-level role; uses listed tech (Java, Kafka, PostgreSQL) without straying. Clarity: Crystal clear scope (5-10 lines, handler logic only), unambiguous instructions. Discriminative: Requires applied understanding of event sourcing flow and basic Java patterns, distinguishes juniors who grasp aggregates from those stuck on CRUD; not trivial recall. Minor subtract avoided as single focused task.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-412",
        "role_title": "Backend Engineer - Analytics APIs",
        "question": "**Question:**  \nYou're building a Go-based analytics API endpoint that aggregates daily active users (DAU) from a ClickHouse table over the past 30 days, grouped by date. The query is expensive and runs frequently for dashboard refreshes.  \n\n1. Sketch a simple Go handler function outline (using Gin or net/http) that executes this aggregation query.  \n2. Describe **two caching strategies** you'd implement with Redis to optimize it (e.g., cache keys, TTLs, invalidation), and when you'd use each.  \n\n*(Expect 2-5 min: pseudocode + brief explanation)*",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests Go API development, ClickHouse aggregation queries, time-series DAU, and caching\u2014core to role (-1 minor for not explicitly listing Gin/Redis, but highly aligned). Clarity: Precise scope, parts clearly separated, time-constrained, unambiguous. Discriminative: Requires applied Go pseudocode + trade-off reasoning on caching strategies (keys/TTL/invalidation), separates strong candidates via depth and practicality.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-420",
        "role_title": "Backend Engineer - Graceful Shutdown",
        "question": "**Question:**  \nIn a Go gRPC server running on Kubernetes, explain how you would implement graceful shutdown to handle SIGTERM signals, drain existing connections, and complete in-flight requests without dropping them. Outline the key code changes (e.g., context management, HTTP server shutdown) and any relevant Kubernetes config (e.g., terminationGracePeriodSeconds).",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's core focus on graceful shutdown, connection draining, in-flight requests, and signals in exact tech stack (Go, gRPC, Kubernetes). No red flags. Clarity: Crystal clear, well-scoped with specific elements (SIGTERM, code changes, K8s config), minor deduction for lacking explicit time constraint. Discriminative: Tests deep applied knowledge, trade-offs in context/signal handling, and cross-domain integration, strongly separates strong candidates.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-418",
        "role_title": "Junior Backend Engineer - Service Clients",
        "question": "**Question:**  \nIn Go, when implementing a gRPC service client, how would you add a simple retry mechanism for transient errors (e.g., network timeouts)? Provide a short code snippet showing the key parts using the standard gRPC retry options or a basic loop, and explain why you'd choose transient errors only.\n\n*(Expected answer: Use gRPC's built-in `grpc.WithBackoff` and `grpc.RetryPolicy` with `grpc.RetryPolicy{RetryableStatusCodes: []codes.Code{codes.ResourceExhausted, codes.Unavailable}}`, or a simple loop with `time.Sleep` backoff. Focus on not retrying idempotency-sensitive errors like `AlreadyExists`. Tests practical error handling knowledge for juniors.)*",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 8,
          "reasoning": "Relevance: Directly tests core error handling/retry skills for service clients in Go/gRPC per role (-1 minor for entry-level specificity). Clarity: Precise scope, expected depth clear, unambiguous. Discriminative: Requires applied knowledge of gRPC APIs, transient error reasoning, and trade-offs (idempotency), separates juniors with practical skills from trivia recall.",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-419",
        "role_title": "Backend Engineer - Retry Logic",
        "question": "**Question:**\n\nYou're implementing retry logic in Go for a Kafka producer that sends critical events to a topic, backed by Redis for tracking retry budgets (max 5 retries per event ID) and PostgreSQL for final failure logging. Describe how you'd structure the retry function, including exponential backoff with jitter. Provide a concise Go code snippet (~20 lines) showing the key logic (e.g., budget check, backoff calc, sleep). What Go libraries would you use, and why?\n\n*(Expected: full jitter impl like `time.Duration(rand.Intn(max-jitter))`, redis.Get/Set for budget, time.Sleep; stdlib `math/rand` or `retry-go`; mid-level shows error classification, budget decrement.)*",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's retry infrastructure focus (backoff, jitter, budgets) with exact tech stack (Go, Kafka, Redis, PostgreSQL). No red flags. Clarity: Crystal clear, well-scoped with line limit, expected depth, and example hints; minor jargon but contextualized. Discriminative: Requires applied knowledge of backoff/jitter math, budget logic, error handling, and Go/Redis patterns; distinguishes mid/junior via code quality and trade-offs without being too broad.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-424",
        "role_title": "Backend Engineer - Message Serialization",
        "question": "**Question:**  \nYou're using Avro with Kafka and Schema Registry to serialize messages for a distributed system. A new version of your Avro schema adds an optional string field `userRole` (default: null) after an existing required field `userId`. Explain whether this change is backward and/or forward compatible, and why. If not fully compatible, what minimal adjustment would make it so?",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core schema evolution, backward/forward compatibility, and validation using Avro (implied in role's serialization infra). No red flags. Clarity: Crystal clear, well-scoped scenario with specific schema change; minor deduction as Avro/Kafka not explicitly in role desc but perfectly aligned. Discriminative: Requires deep understanding of compatibility rules, trade-offs (e.g., reader vs writer schemas), and practical fixes, strongly separating experts from juniors.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-422",
        "role_title": "Junior Backend Engineer - API Testing",
        "question": "**Question:**\n\nYou're writing pytest tests for a FastAPI endpoint that retrieves user data from a PostgreSQL database. The endpoint is defined as:\n\n```python\n@app.get(\"/users/{user_id}\")\ndef get_user(user_id: int, db: Session = Depends(get_db)):\n    return db.query(User).filter(User.id == user_id).first()\n```\n\nWrite a simple pytest test function to verify that the endpoint returns a 404 status code when the user ID doesn't exist in the database. Assume a test client and a test database fixture (`test_db`) are available.\n\n(Expect a concise response showing `TestClient`, a mock non-existent user, `assert response.status_code == 404`, and basic setup.)",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 8,
          "reasoning": "Relevance: Directly tests pytest + FastAPI + PostgreSQL (core stack for API tests role), with fixture usage; minor ding as contract testing not explicit (-1). Clarity: Crystal clear with code example, explicit assumptions, expected response format. Discriminative: Tests applied testing skills (setup, client usage, assertions) distinguishing entry-level competence; not trivial recall.",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-423",
        "role_title": "Staff Engineer - Incident Response Platform",
        "question": "**Question:**  \nYou're building an incident response platform in Go that integrates with PagerDuty and Slack. Describe how you would design and implement a reliable retry mechanism for sending Slack notifications triggered by PagerDuty escalations, including handling duplicates, rate limits, and failures. What Go libraries or patterns would you use, and how would you ensure it doesn't exacerbate an ongoing incident?",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core incident response tooling skills with Go, PagerDuty, Slack integration, and reliability\u2014matches role focus perfectly (-0 red flags). Clarity: Well-scoped design question with specific constraints (duplicates, rate limits, failures, non-exacerbation); unambiguous for screening. Discriminative: Probes applied knowledge of retries, Go patterns (e.g., idempotency, backoff), trade-offs in failure handling\u2014strong separation of strong vs weak candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-421",
        "role_title": "Senior Backend Engineer - Security Automation",
        "question": "**Question:**  \nYou're automating secrets rotation for a Kubernetes cluster using HashiCorp Vault and Python. Walk me through how you'd implement a Python script to rotate a database password stored in Vault, update the corresponding Kubernetes Secret, and roll out the change to a Deployment without downtime. What key Vault APIs or auth methods would you use, and how would you handle errors like lease expiration?",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 10,
          "reasoning": "Relevance: Directly tests core secrets rotation in K8s/Vault/Python (-1 minor for not mentioning scanning/compliance). Clarity: Precise, well-scoped steps with specific tech. Discriminative: Requires deep applied knowledge of APIs, auth, K8s rolling updates, error handling, and trade-offs like zero-downtime.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-426",
        "role_title": "Junior Backend Engineer - DevOps Scripting",
        "question": "**Question:**\n\nYou're setting up a simple CI/CD pipeline in GitHub Actions to build and test a Python application. The workflow should:\n\n1. Trigger on push to `main`.\n2. Run on `ubuntu-latest`.\n3. Install Python 3.11 and dependencies from `requirements.txt`.\n4. Run `pytest` tests.\n\nWrite the YAML for `.github/workflows/ci.yml`. (No Docker needed.)\n\n*Expected time: 3-5 minutes. Look for correct structure, `uses:`, `run:`, and basic steps.*",
        "scores": {
          "relevance": 9,
          "clarity": 10,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests GitHub Actions YAML for CI/CD pipelines, core to DevOps automation role (-1 for not mentioning deployments despite role scope). Clarity: Crystal clear with precise requirements, triggers, runner, steps, and time estimate. Discriminative: Requires applied YAML knowledge of structure, 'uses', 'run', and Python setup, distinguishing those who can write working workflows from those who can't; 3-5 min scope perfect.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-427",
        "role_title": "Backend Engineer - Feature Store",
        "question": "**Question:**  \nIn Feast, describe the key steps to define a simple feature view for real-time serving of a user activity count feature (e.g., computed from Kafka events and stored in Redis). Include the main configuration elements you'd specify in the feature view YAML, and explain how you'd retrieve it online for inference in a Python service.\n\n*(Expected answer outline: FeatureView with entities (e.g., user_id), stream source (Kafka), online store (Redis), TTL, and features with value_type. Retrieval via feature_store.get_online_features() with entity rows.)*",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests Feast for feature store infrastructure, core to ML pipelines with versioning, real-time serving, Kafka, and Redis\u2014no red flags. Clarity: Precise, well-scoped with YAML elements and retrieval; minor vagueness on exact YAML syntax prevents 10. Discriminative: Requires applied Feast knowledge, configuration details, and API usage with trade-offs (e.g., TTL, stores), distinguishing strong candidates from weak ones.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-425",
        "role_title": "Senior Backend Engineer - Graph Analytics",
        "question": "**Question:**  \nYou're optimizing a Neo4j graph traversal query for a recommendation engine on a social network with 1 billion edges (users \u2192 follows \u2192 interests). The current Cypher query for \"find top-10 interest recommendations for a user\" is taking 30+ seconds due to high cardinality.  \n\n```\nMATCH (u:User {id: 123})-[:FOLLOWS*1..3]->(other:User)-[:LIKES]->(i:Interest)\nWITH i, count(DISTINCT other) as score\nRETURN i.name, score\nORDER BY score DESC\nLIMIT 10\n```\n\nWhat are 2-3 specific optimizations you'd apply (e.g., indexes, query rewrites, or config changes), and why would they improve performance at this scale?",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests Neo4j/Cypher optimization for graph traversal at billion-edge scale, core to role (-1 minor for assuming Neo4j not explicitly listed). Clarity: Crystal clear with specific query, scenario, and scoped ask for 2-3 optimizations. Discriminative: Requires applied knowledge of graph query tuning, indexes, cardinality issues, and scale trade-offs, separating strong candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-430",
        "role_title": "Junior Backend Engineer - Search Indexing",
        "question": "**Question:**  \nYou're building a Python script to bulk index 10,000 user profiles from PostgreSQL into Elasticsearch. The profiles have fields like `name`, `email`, and `bio`.  \n\n1. Write a simple Elasticsearch mapping for these fields (JSON).  \n2. Provide a Python code snippet using the `elasticsearch` library to connect, prepare a bulk action for 3 sample docs, and execute the indexing.  \n\n(Expect ~100-200 words of code/response; focus on correctness over optimization.)",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 8,
          "reasoning": "Relevance: Directly tests core role skills (bulk indexing, mapping design) with exact tech stack (Python, PostgreSQL, Elasticsearch); minor ding for not covering relevance tuning (-1). Clarity: Crystal clear with specific fields, sample size, library, and scoped expectations. Discriminative: Requires applied knowledge of mappings and bulk API, distinguishes those who can code correctly from theorists; not elite trade-offs but strong for entry-level.",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-429",
        "role_title": "Backend Engineer - Log Aggregation",
        "question": "**Question:**  \nYou're building a log aggregation pipeline in Go using Vector for collection and ClickHouse for storage, processing millions of events per second on Kubernetes. Describe a practical approach to implement dynamic retention policies (e.g., delete logs older than 7 days for high-volume sources but 30 days for critical ones). Include key Go code snippets for the retention logic and any ClickHouse/Vector configurations you'd use. (2-5 min)",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core role skills (log pipelines, retention policies at scale) with exact tech stack (Go, Vector, ClickHouse, K8s); minor generic penalty avoided (-0). Clarity: Well-scoped (2-5 min, practical approach, specific elements), unambiguous with clear expectations. Discriminative: Requires applied knowledge of integration, trade-offs (dynamic policies at scale), and code/config, strongly separating experienced candidates; not mere recall.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-428",
        "role_title": "Senior Backend Engineer - Payment Orchestration",
        "question": "**Question:**  \nIn our payment orchestration system built with Go, Kafka, and PostgreSQL, we route transactions to multiple providers based on success rates, costs, and failover rules. Describe how you would implement a failover mechanism in Go that switches providers mid-transaction if the primary provider times out or fails (e.g., after 2 seconds), while ensuring the transaction state is reliably tracked across retries. Include key code snippets for the routing logic and any relevant Kafka/PostgreSQL interactions.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core payment orchestration skills (failover, routing, success tracking) with exact tech stack (Go, Kafka, PostgreSQL); minor deduction as role doesn't explicitly specify 'mid-transaction' switch. Clarity: Well-scoped with specific timeout example, clear expectations for code snippets and DB/Kafka interactions. Discriminative: Requires applied knowledge of Go concurrency, distributed state, retries, and trade-offs (idempotency, at-least-once), strongly separates strong candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-435",
        "role_title": "Junior Backend Engineer - Queue Consumers",
        "question": "**Question:**  \nYou're building a Python RabbitMQ consumer that processes order updates from a queue and saves them to PostgreSQL. The consumer might crash mid-processing, causing duplicates if restarted.  \n\nExplain in 2-3 sentences how you'd make it **idempotent** (safe to retry). What code pattern or DB technique would you use, and why?  \n\n*(Follow-up if time: Sketch a simple code snippet.)*",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests idempotency for message queue consumers (core role skill) with Python/RabbitMQ/PostgreSQL stack; minor deduction as role is entry-level but question fits learning focus (-1). Clarity: Crystal clear, scoped to 2-3 sentences with specific ask for pattern/technique/why; follow-up is optional. Discriminative: Requires applied understanding of trade-offs (e.g., DB unique constraints vs. app logic), distinguishes those grasping retry safety from rote memorizers.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-433",
        "role_title": "Senior Backend Engineer - Platform APIs",
        "question": "**Question:**  \nYou're designing a gRPC-based internal platform API in Go for a service catalog that allows developers to query and provision resources (e.g., databases or caches). The API needs to support pagination for large result sets and integrate with PostgreSQL for storage and Redis for caching.\n\nWalk us through how you'd structure the protobuf schema for the `ListServices` RPC, including pagination and caching strategy. What key gRPC and Go features would you use, and why? (e.g., streaming vs. unary, context handling).",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (API design, service catalog, provisioning) with exact tech stack (gRPC, Go, PostgreSQL, Redis); minor deduction as role doesn't explicitly list gRPC but fits internal platform APIs (-1). Clarity: Crystal clear, well-scoped to one RPC with specific constraints, no ambiguity. Discriminative: Probes deep applied knowledge of protobuf design, gRPC features (streaming vs unary), Go specifics, caching trade-offs, and context handling for strong candidate separation.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-434",
        "role_title": "Principal Engineer - Database Strategy",
        "question": "**Question:**  \nYou're leading the database strategy for a new multi-region application deployment using PostgreSQL as the primary database, with CockroachDB as a potential option for future scalability, Redis for caching, and Kafka for event streaming, all orchestrated on Kubernetes.  \n\nWalk me through your high-level approach to selecting between PostgreSQL (with replication) and CockroachDB for strong consistency across 3 regions, including 2-3 key trade-offs you'd evaluate and how you'd ensure operational resilience (e.g., failover, monitoring).  \n\n*(Expected response: 2-5 min verbal explanation demonstrating strategic trade-offs like latency vs. availability, cost, ops complexity, and practical Kubernetes integration.)*",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core database strategy, multi-region deployment, and tech selection (PostgreSQL, CockroachDB) from role; minor ding for unmentioned Redis/Kafka/K8s (-1). Clarity: Crystal clear, well-scoped with explicit trade-offs, resilience focus, and time expectation. Discriminative: Forces trade-off analysis (latency/availability/cost/ops) and applied Kubernetes knowledge, separating strategic thinkers from rote learners.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-432",
        "role_title": "Backend Engineer - Data Validation",
        "question": "**Question:**\n\nIn a Python-based data pipeline using Great Expectations and Airflow, you've set up an expectation suite that includes schema validation and a statistical check for row count drift (e.g., expecting row counts to stay within 10% of a baseline). During an Airflow DAG run, the task fails due to a Great Expectations validation error on the row count check.\n\nWalk me through **3 practical steps** you'd take to debug and resolve this issue, including specific Great Expectations or Airflow commands/tools you'd use, and explain why each step helps ensure pipeline quality.\n\n*(Expected response time: 2-4 minutes; follow-up: Ask for code snippet if they mention CLI commands.)*",
        "scores": {
          "relevance": 9,
          "clarity": 10,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (schema validation, statistical checks) with exact tech stack (Python, Great Expectations, Airflow); minor deduction as role mentions data lineage not covered (-1). Clarity: Crystal clear, well-scoped with 3 steps, specific tools, expected time, and follow-up. Discriminative: Requires applied debugging knowledge, trade-offs in pipeline quality, and specific commands; strong separation beyond recall.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-431",
        "role_title": "Staff Engineer - Real-time Collaboration",
        "question": "**Question:**  \nYou're designing a real-time collaborative text editor using WebSockets and CRDTs. A user applies a large text insertion (e.g., 10KB) while another user deletes a nearby character simultaneously. Walk me through how you'd ensure both operations are correctly merged without conflicts or data loss, including any trade-offs in your CRDT choice (e.g., Logoot vs. Yjs).",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 10,
          "reasoning": "Relevance: Directly tests core role skills (real-time collab, conflict resolution, operational transforms via CRDTs); minor ding as role mentions OT too but question focuses perfectly on CRDTs (-1). Clarity: Crystal clear scenario, well-scoped, specific examples, no ambiguity. Discriminative: Forces deep understanding of CRDT mechanics, concurrency, and trade-offs (Logoot vs Yjs), excellent separation of strong vs weak candidates.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-438",
        "role_title": "Staff Engineer - ML Serving Infrastructure",
        "question": "**Question:**  \nYou're designing a Triton Inference Server deployment on Kubernetes to serve a high-throughput computer vision model with sub-100ms p99 latency targets. The model uses dynamic batching. Walk me through your approach to configuring batching parameters (e.g., max_batch_size, preferred_batch_size) and any Kubernetes autoscaling integrations you'd use to handle traffic spikes, including one key Prometheus metric you'd monitor for optimization.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Directly targets core role skills (ML serving, batching, latency optimization) with Triton/K8s specifics highly relevant to infrastructure design; crystal clear with precise parameters, integrations, and metric scope; tests applied trade-offs in config and monitoring, distinguishing deep expertise from superficial knowledge. Minor ding for assuming Triton without role mention, but fits ML serving context perfectly.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-442",
        "role_title": "Backend Engineer - Event Streaming",
        "question": "**Question:**  \nIn our event streaming system built with Rust and NATS, we need to support fan-out of real-time updates to thousands of connected clients (e.g., via WebSocket). Describe a practical approach you'd take to efficiently fan-out a single high-volume event topic across NATS subjects, including how you'd handle filtering for client-specific subscriptions (e.g., by user ID or event type). What Rust crates or NATS features would you leverage, and how would you ensure scalability without overwhelming Redis or PostgreSQL?",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core role skills (event streaming, fan-out, filtering) with exact tech stack (Rust, NATS); minor ding for mentioning Redis/PostgreSQL not in role desc (-1). Clarity: Well-scoped, unambiguous, specific constraints provided. Discriminative: Requires applied knowledge of trade-offs, scalability, and specific tools, strongly separates strong candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-437",
        "role_title": "Senior Backend Engineer - Secrets Management",
        "question": "**Question:**  \nYou're implementing automated secret rotation for a service account used by a Go application running in Kubernetes, storing its credentials in HashiCorp Vault. The secret needs to be rotated every 24 hours, with the app fetching the latest version via Vault's API, and old versions revoked after successful update. Walk me through your approach in Go, including key code snippets for the rotation logic, handling Vault authentication, and ensuring zero-downtime during the update. What Vault features (e.g., policies, dynamic secrets) would you leverage, and how would you test this in a Kubernetes environment?",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's secrets management, rotation, Vault, with Go/K8s specifics (no red flags). Clarity: Crystal clear, well-scoped for screening, minor deduction for lacking explicit time/format constraints. Discriminative: Tests deep applied knowledge, trade-offs (zero-downtime), Vault features, and testing\u2014strong separation of strong vs weak candidates.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-440",
        "role_title": "Junior Backend Engineer - Metrics Collection",
        "question": "**Question:**  \nIn Go, using the Prometheus client library, write a short code snippet (5-10 lines) to create and increment a counter metric named `http_requests_total` that tracks the number of incoming HTTP requests, labeled by HTTP method (e.g., \"GET\", \"POST\"). Explain briefly (1-2 sentences) how you'd register and expose this metric for Prometheus scraping.\n\n*(Expected answer: Import `prometheus/client_golang/prometheus` and `prometheus/client_golang/prometheus/promhttp`; define var `httpRequests = prometheus.NewCounterVec(prometheus.CounterOpts{Name: \"http_requests_total\"}, []string{\"method\"});` register it with `prometheus.MustRegister(httpRequests);` then `httpRequests.WithLabelValues(\"GET\").Inc();` in handler; expose via `/metrics` handler with `promhttp.Handler().` Tests basic metric patterns, Go syntax, and observability setup.)*",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's focus on counter metrics/patterns in Go with Prometheus, core to entry-level observability; no red flags. Clarity: Crystal clear with line limit, specific labels, and scoped explanation; minor deduction for not specifying handler context explicitly. Discriminative: Requires applied knowledge of Prometheus client (not just recall), Go syntax, registration, and exposure, distinguishing candidates familiar with observability setup from novices.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-444",
        "role_title": "Backend Engineer - Service Templates",
        "question": "**Question:**  \nYou're setting up a Cookiecutter template for a new Go microservice that will deploy to Kubernetes via ArgoCD. Walk me through 3-5 key best practices you'd include in the template for security defaults and observability, and briefly explain how you'd implement one of them using Go or GitHub Actions.\n\n*(Expected response: Covers basics like non-root containers, network policies, structured logging with zap/zerolog, Prometheus metrics, GitHub Actions for scanning dependencies/secrets. Implementation example: Embedding OTEL exporter in Go main() or Actions lint/test workflow.)*",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (templates, security defaults, observability) with exact tech (Cookiecutter, Go, K8s/ArgoCD); minor ding for not mentioning CI/CD explicitly (-1). Clarity: Precise scope (3-5 practices, one implementation), no ambiguity or bundling. Discriminative: Requires applied knowledge of best practices + implementation, tests trade-offs/explanations to separate strong candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-443",
        "role_title": "Senior Backend Engineer - Data Lake Architecture",
        "question": "**Question:**  \nIn a data lake using Apache Iceberg on S3 with Spark for writes and Trino for queries, describe a practical approach to handle schema evolution (e.g., adding a new column) while ensuring safe partition pruning and time travel queries remain functional. What Iceberg-specific features would you leverage, and why? (Briefly outline 2-3 steps with trade-offs.)\n\n*(Expected answer time: 2-4 minutes. Tests senior-level practical experience with Iceberg schema evolution, integration across Spark/Trino/S3, and awareness of features like schema evolution modes, metadata tables, and branching for time travel.)*",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's core skills (Iceberg table formats, schema evolution, partition pruning, time travel) with exact tech stack (S3, Spark, Trino). Clarity: Crystal clear, well-scoped with steps/trade-offs, expected time, and no bundling/ambiguity. Discriminative: Requires applied senior-level knowledge of Iceberg features/modes, trade-offs, and integrations, strongly separating experienced candidates; minor deduction as not ultra-deep edge-case probing.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-439",
        "role_title": "Backend Engineer - Billing Integration",
        "question": "**Question:**  \nIn a Python-based billing system using Stripe and PostgreSQL, describe how you would implement a customer upgrade from a $20/month plan to a $50/month plan mid-cycle (e.g., on day 10 of a 30-day month), ensuring proper proration of the unused portion of the old plan while immediately applying the new plan. Include key Stripe API calls and any relevant database considerations. (Answer in 3-5 sentences or bullet points.)\n\n*(Expected answer outline: Use `stripe.Subscription.modify()` with `proration_behavior='create_prorations'` and `items` to update the price ID; credit the unused $10 days of the old plan ($20 * 20/30 \u2248 $13.33) and charge the prorated new plan ($50 * 20/30 \u2248 $33.33); store subscription metadata and sync status/events in PostgreSQL via a Celery task triggered by Stripe webhooks for idempotency and audit trail.)*",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's core focus on billing integrations, proration, Stripe, with Python/PostgreSQL directly from description (no red flags). Clarity: Crystal clear scenario, well-scoped with format/depth guidance; minor deduction for lacking exact proration formula. Discriminative: Tests deep applied knowledge of Stripe API, proration math, DB sync, and idempotency\u2014distinguishes strong candidates via trade-offs and integration thinking.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-441",
        "role_title": "Senior Backend Engineer - Autocomplete Systems",
        "question": "**Question:**  \nYou're building an autocomplete system using Elasticsearch that needs to support prefix matching with user personalization (e.g., boosting recent searches for the user) while targeting sub-50ms latency at 100K QPS. Traffic is sharded across 10 ES nodes.\n\nDescribe your approach to indexing and querying for prefix matches with personalization. What key ES features would you use (e.g., specific query types, mappings), and how would you optimize for latency at this scale? (Focus on 2-3 most critical optimizations.)",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core autocomplete skills, prefix matching, personalization, and latency/QPS from role desc using ES (relevant tech); minor ding as ES not explicitly listed (-1). Clarity: Well-scoped with specific constraints, focus on 2-3 opts, no ambiguity. Discriminative: Requires applied ES knowledge, trade-offs in indexing/querying/optimizations at scale, separates strong candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-445",
        "role_title": "Junior Backend Engineer - Database Migrations",
        "question": "**Question:**\n\nYou're using Alembic to manage database migrations for a PostgreSQL database with SQLAlchemy. A recent migration added a non-nullable `email` column to the `users` table without a default value, but some existing rows now fail validation because they lack email data.\n\nExplain in 2-3 steps how you would create a follow-up Alembic migration to fix this (backfill missing emails with a placeholder like `'missing@example.com'`, make the column nullable temporarily, then add a NOT NULL constraint). Include the key Alembic commands and any relevant SQLAlchemy/Alembic revision code snippets.\n\n*(Expected answer time: 2-4 minutes)*",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly targets Alembic migrations, PostgreSQL, SQLAlchemy, and zero-downtime/rollback patterns for entry-level role; no red flags. Clarity: Crystal clear with specific steps, expected output, and time scope; minor deduction for not specifying exact code format. Discriminative: Requires applied knowledge of Alembic revision creation, upgrade/downgrade logic, and safe schema changes, distinguishing those with hands-on experience from theorists.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-447",
        "role_title": "Backend Engineer - Load Shedding",
        "question": "**Question:**\n\nYou're implementing load shedding in a Go service running on Kubernetes with Envoy as the ingress proxy. Under high load, you need to gracefully degrade by dropping low-priority requests while preserving critical ones. Describe a practical approach using Go code snippets, including:\n\n1. How you'd integrate with Envoy's external authorization or backpressure signals (e.g., via headers or metrics).\n2. A simple adaptive throttling mechanism (e.g., using Redis for a priority queue or rate limiter).\n3. How you'd signal backpressure to upstream callers without crashing.\n\nKeep it concise\u2014focus on the key logic and trade-offs. (Answer in 2-5 minutes.)",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core load shedding, priority queues, throttling, and backpressure from role; mentions Go/K8s/Envoy (relevant stack), minor ding for Redis not in desc (-1). Clarity: Crystal clear, well-scoped with numbered parts, time limit, and focus on logic/trade-offs. Discriminative: Requires applied knowledge, integration, code snippets, and trade-offs; distinguishes deep understanding from superficial knowledge.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-450",
        "role_title": "Principal Engineer - ML Platform Strategy",
        "question": "**Question:**  \nYou're leading the ML platform strategy for our organization and need to recommend a tooling stack for productionizing ML workflows across 50+ teams. Our current setup includes Kubernetes for orchestration, and we're evaluating Kubeflow, MLflow, and Ray.  \n\nWalk me through your high-level architecture design: How would you integrate 1-2 of these tools with Kubernetes to support end-to-end ML lifecycles (experimentation, training, serving, monitoring)? What key governance considerations (e.g., access control, cost management) would you prioritize, and why?",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core ML platform strategy, tooling selection (Kubeflow/MLflow/Ray), governance, and Kubernetes integration from role (-1 for not specifying all role elements like team enablement). Clarity: Crystal clear, well-scoped with specific tools, lifecycle stages, and governance examples; no bundling or vagueness. Discriminative: Requires applied architecture design, integration trade-offs, and prioritized reasoning, strongly separating strategic thinkers from rote responders.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-448",
        "role_title": "Senior Backend Engineer - Webhook Infrastructure",
        "question": "**Question:**  \nIn Go, design a simple retry mechanism for delivering a webhook payload to an endpoint that might fail transiently (e.g., 5xx errors). Outline the key components (code structure, not full implementation), including exponential backoff, deduplication, and a max retry limit. How would you persist retry state across restarts using Redis or PostgreSQL? (Answer in 300 words or less.)\n\n*(Expected answer: Struct with payload ID, exponential backoff like `time.Sleep(base * 2^attempt)`, Redis/PostgreSQL for state like `SETEX payload_id {attempts,deadline}`, dead letter queue on max retries; tests delivery guarantees at senior level.)*",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (retry logic, guaranteed delivery) in Go, with persistence; minor deduction as role doesn't explicitly specify Go or Redis/PostgreSQL (-1). Clarity: Crystal clear, well-scoped with word limit, specific components listed, no ambiguity. Discriminative: Requires applied knowledge of backoff, deduplication, persistence trade-offs, distinguishes seniors via design choices and guarantees; not mere recall.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-452",
        "role_title": "Senior Backend Engineer - Faceted Search",
        "question": "**Question:**\n\nIn Elasticsearch, you're building a faceted search for an e-commerce product catalog with millions of items. Users want to filter by category, price range, and brand, while seeing accurate facet counts (e.g., \"10 laptops in stock under $1000\"). \n\nExplain how you'd structure the search query using `bool` filters and `composite` or `terms` aggregations to ensure facet counts exclude the applied filters and handle high cardinality efficiently. Include a brief code snippet in Python (using elasticsearch-py) and mention one key optimization for scale.\n\n*(Expected answer: Use `post_filter` for client-side filters or filtered aggs; `composite` agg for pagination/high-cardinality; optimizations like sampler agg or keyword subfields.)*",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's faceted search, dynamic filtering, aggregation queries, facet accuracy at scale with Elasticsearch; no red flags. Clarity: Crystal clear, well-scoped with specific requirements and example; minor deduction for not specifying exact response format/length. Discriminative: Tests deep applied knowledge of ES query structure, aggs trade-offs (composite vs terms), optimizations; expected answer shows strong separation; not pure recall.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-449",
        "role_title": "Junior Backend Engineer - Auth Integration",
        "question": "**Question:**  \nIn a Node.js/Express app using TypeScript and PostgreSQL, you're implementing an OAuth2 authorization code flow for Google login. After receiving the authorization code from Google and exchanging it for an access token and refresh token via their token endpoint, walk us through the key steps you'd take to securely store and manage these tokens for the user. Mention any relevant database schema considerations and security best practices (e.g., for refresh tokens). \n\n*(Expected answer outline: Validate code, exchange for tokens securely (HTTPS), hash refresh token before storing in DB with user ID/expiry, store access token in HTTP-only secure cookie or short-lived session, implement refresh logic with validation/rotation, use libraries like `passport-oauth2` or `oauth4webapi`.)*",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's OAuth focus, token handling, refresh flows, and exact tech stack (Node.js/Express/TS/PostgreSQL); no red flags. Clarity: Crystal clear, well-scoped steps with specific context, minor deduction only for implicit time constraint. Discriminative: Requires applied knowledge of secure token practices, trade-offs (hashing vs cookies, rotation), and DB design, strongly separates candidates familiar with OAuth security from those with superficial knowledge; not mere recall.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-436",
        "role_title": "Backend Engineer - API Documentation",
        "question": "**Question:**  \nYou're building an OpenAPI spec for a Node.js/Express API endpoint that retrieves user data from PostgreSQL. The endpoint is `GET /api/v1/users/{userId}` and returns a JSON object like `{ id: number, name: string, email: string }`.  \n\nWrite a minimal OpenAPI 3.0 YAML snippet for this endpoint, including:  \n- Path parameters  \n- A 200 response schema  \n- One example response  \n- Basic security (e.g., API key)  \n\n(Provide just the `paths` and `components` sections; no need for full spec.)  \n\n**Expected Time:** 3-5 minutes  \n**What it tests:** Practical OpenAPI authoring, TypeScript-aligned schema design, API versioning awareness.",
        "scores": {
          "relevance": 9,
          "clarity": 10,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core OpenAPI spec generation and API versioning (v1 in path), central to role's auto-generated specs and documentation tooling; minor ding as Node.js/PostgreSQL are illustrative not required (-1). Clarity: Crystal clear with precise scope (minimal YAML, specific sections, constraints), expected time, no ambiguity. Discriminative: Requires practical applied knowledge of OpenAPI 3.0 YAML syntax, schemas, examples, and security; distinguishes those who can author specs from theorists (strong separation, not recall).",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-451",
        "role_title": "Backend Engineer - Subscription Billing",
        "question": "**Question:**  \nIn a subscription billing system using PostgreSQL and Java/Spring Boot, how would you implement usage-based metering for a feature like API calls, including storing the usage data and checking limits during billing cycles? Briefly describe the schema design and a key method or query you'd use to compute billable usage (e.g., for proration across mid-cycle plan changes).",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Directly tests core role skills (usage metering, proration, billing cycles) with exact tech stack (PostgreSQL, Java/Spring Boot). Crystal clear, well-scoped with specific schema and method/query asks. Requires applied knowledge of design trade-offs, distinguishes strong candidates via practical implementation details. Minor ding for not specifying exact constraints, but excellent overall.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-446",
        "role_title": "Staff Engineer - Distributed Tracing",
        "question": "**Question:**  \nYou're designing a distributed tracing system for a high-scale service using OpenTelemetry and Jaeger as the backend. Traffic is at 10,000 requests/second, and storing 100% of traces is infeasible due to storage costs in ClickHouse.  \n\nWalk me through how you'd architect a sampling strategy: What type(s) of sampling would you use (e.g., head/tail, rate-limiting, probabilistic), how would you configure it in OpenTelemetry, and how would you tune it dynamically based on errors or SLOs? What trade-offs are you considering for trace completeness vs. cost?",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 10,
          "reasoning": "Relevance: Directly targets core role responsibilities (distributed tracing, sampling strategies, SLO correlation) with exact tech stack (OpenTelemetry, Jaeger, ClickHouse); minor ding for assuming specific backend not explicitly listed (-1). Clarity: Crystal clear, well-scoped scenario with concrete numbers, specific asks, no ambiguity. Discriminative: Forces deep applied knowledge of sampling types, config, dynamic tuning, and trade-offs, perfectly separating strong architects from weak ones.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-454",
        "role_title": "Junior Backend Engineer - ETL Scripts",
        "question": "**Question:**\n\nYou're writing a Python ETL script using pandas to load sales data from a CSV file into a PostgreSQL table. The CSV has 100k rows with a 'sale_date' column in string format ('2023-12-01'). \n\nWrite a short code snippet (5-10 lines) that:\n- Reads the CSV into a pandas DataFrame\n- Converts 'sale_date' to a proper datetime type\n- Handles any invalid dates by setting them to NaT (not a time)\n- Inserts the cleaned data into a PostgreSQL table named 'sales' (assume connection string is provided)\n\nInclude necessary imports and explain one potential error you might encounter during the insert.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core ETL skills (pandas data loading/transformation) and PostgreSQL for entry-level role; minor ding for assuming connection string (-1). Clarity: Precise scope (5-10 lines), clear steps, well-constrained. Discriminative: Requires applied pandas/datetime handling, error management, SQL integration, and trade-off explanation (e.g., connection errors), separating competent from weak candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-456",
        "role_title": "Backend Engineer - Query Optimization",
        "question": "**Question:**  \nYou're analyzing a slow PostgreSQL query using `EXPLAIN ANALYZE` that shows a sequential scan on a large table (`users`) with 10M rows, filtering on `email` (varchar(255)). The query is `SELECT * FROM users WHERE email = 'user@example.com';`.  \n\n1. What index would you recommend adding, and why?  \n2. How would you verify if it improves performance?  \n\n*(Expected answer: B-tree index on `email` since it's selective and equality-based; re-run `EXPLAIN ANALYZE` to check for index scan, compare planning/execution time.)*",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Directly tests core role skills (slow query detection, index recommendations, plan analysis) with PostgreSQL example matching query optimization focus; no red flags. Crystal clear with specific scenario, two focused sub-questions (minor bundle deduct not applied as well-scoped). Strong separation via trade-offs (why B-tree/selective), verification method testing applied knowledge beyond recall.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-455",
        "role_title": "Staff Engineer - Developer Portal",
        "question": "**Question:**  \nIn Backstage, imagine you're designing a plugin architecture for a developer portal where teams need to onboard new services to the service catalog with minimal friction. Walk us through how you would structure a custom Backstage plugin (using TypeScript and React) to automate service entity creation from a GitHub PR webhook, including key code snippets for the backend handler and frontend scaffolder UI. What Backstage APIs or patterns would you leverage to ensure it integrates seamlessly with the existing catalog and supports extensibility for future teams?",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 10,
          "reasoning": "Relevance: Directly tests Backstage plugin architecture, service catalog onboarding, and extensibility\u2014core to the role (-1 for not explicitly mentioning team flows). Clarity: Well-scoped with specific tech (TypeScript/React), clear deliverables (structure, snippets, APIs), no bundling or vagueness. Discriminative: Requires deep applied knowledge of Backstage APIs/patterns, trade-offs in integration/extensibility, and code-level implementation\u2014strong separation of strong vs weak candidates.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-453",
        "role_title": "Backend Engineer - Notification Delivery",
        "question": "**Question:**  \nYou're implementing a Go service for delivering push notifications using FCM and APNS. Devices register their tokens in Redis (with TTL for expiration) and PostgreSQL (for persistence). Describe a simple batching strategy to efficiently send notifications to 10,000 registered devices in real-time, including how you'd handle token expiration checks and delivery tracking. What Go data structures and Redis operations would you use?\n\n*(Expected answer outline: Use Redis SCAN or Lua script for batched token fetching with TTL checks; Go channels/slices for concurrent goroutine batches; PostgreSQL for idempotent delivery status updates via UPSERT. Limit batch size e.g., 100-500 per goroutine to respect FCM/APNS rate limits.)*",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's core requirements (push notifications, device registration, batching, delivery tracking) with exact tech stack (Go, Redis, PostgreSQL, FCM/APNS). Clarity: Crystal clear, well-scoped for screening, specific tech details provided. Discriminative: Tests applied knowledge of batching, concurrency (Go channels/goroutines), Redis ops, rate limits, and trade-offs like batch size; expected outline shows deep understanding needed. Minor clarity ding for no explicit time constraint, but excellent overall.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-458",
        "role_title": "Backend Engineer - API Gateway Plugins",
        "question": "**Question:**  \nIn Kong, you're developing a custom Lua plugin to implement JWT authentication. The plugin needs to verify the JWT token from the `Authorization` header, decode it using the `lua-resty-jwt` library, validate the `exp` claim against the current time, and either allow the request or return a 401 Unauthorized response.  \n\nWrite a concise code snippet for the `access` phase of the plugin that accomplishes this (assume `kong.request.get_header(\"Authorization\")` provides the header value starting with \"Bearer \"). Include error handling for missing/invalid tokens.  \n\n*(Expected: ~10-15 lines of Lua code demonstrating practical Kong plugin structure, header parsing, JWT library usage, and phase logic.)*",
        "scores": {
          "relevance": 10,
          "clarity": 10,
          "discriminative": 9,
          "reasoning": "Directly tests core Kong Lua plugin development for API gateway authentication (matches role's custom auth focus). Crystal clear with precise scope, assumptions, expected output, and error handling requirements. Strong separation via applied coding with library integration, validation logic, and Kong phase structure; minor deduction as top candidates might discuss edge cases beyond snippet.",
          "composite": 9.666666666666666
        }
      },
      {
        "role_id": "be-457",
        "role_title": "Senior Backend Engineer - SLO Automation",
        "question": "**Question:**  \nIn Go, implement a simple function to calculate the current SLO burn rate for a service, given a time window (e.g., 28 days), the total error budget (e.g., 1000 \"credits\"), the good request count, and the total request count over that window. The burn rate should be the rate at which error budget is consumed per request (e.g., 0.01 credits per bad request). Explain your assumptions and edge cases briefly.\n\n*(Expected answer: Something like `func BurnRate(window int64, budget, good, total uint64) float64 { errorBudgetConsumed := float64(total - good) / float64(budget); return errorBudgetConsumed / float64(window) }` \u2013 tests Go proficiency, SLO math, and senior-level reasoning on reliability concepts like error budgets.)*",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests Go (core for role), SLO burn rate/error budget math central to SLO infrastructure/burn rate alerting; minor deduct for not specifying exact role tech stack but fits perfectly (-1). Clarity: Crystal clear inputs/outputs, well-scoped function impl with explanation request. Discriminative: Requires Go syntax, correct SLO math trade-offs (per-request vs per-time), edge cases (zero requests, full budget); distinguishes seniors who catch bad expected formula from juniors.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-459",
        "role_title": "Junior Backend Engineer - Container Security",
        "question": "**Question:**  \nYou're setting up Trivy to scan a Docker image for vulnerabilities in a CI/CD pipeline. The scan reveals a high-severity vulnerability in a dependency. Walk me through 3 practical steps you'd take next to address it, including one command you'd run with Trivy to help investigate. (Keep your answer to 3-5 sentences.)",
        "scores": {
          "relevance": 9,
          "clarity": 10,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core container scanning skills with Trivy (key for vulnerability detection), perfectly matching entry-level role focus (-0 red flags). Clarity: Crystal clear, well-scoped with exact step count, sentence limit, and specific command request. Discriminative: Requires practical application and trade-offs (e.g., investigate vs. fix), distinguishing those with hands-on CI/CD scanning experience from theorists.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-463",
        "role_title": "Junior Backend Engineer - Full-text Search",
        "question": "**Question:**  \nYou're implementing a full-text search feature in PostgreSQL for a blog application using Python and FastAPI. You have a `posts` table with a `content` column (text). Write a SQL query to create a GIN-indexed `tsvector` column for full-text search, then show a basic `SELECT` query that searches for posts matching the query \"machine learning\" and ranks results by relevance (using `ts_rank`).  \n\n*Bonus (optional): How would you pass this search query from a FastAPI endpoint to execute it?*",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests PostgreSQL full-text search core skills (tsvector, GIN index, ts_rank) from role description, with relevant FastAPI context (-1 for minor Python mention not core to entry-level Postgres focus). Clarity: Crystal clear, well-scoped tasks with specific elements, bonus properly separated. Discriminative: Requires applied SQL knowledge and trade-offs (indexing, ranking), distinguishes candidates who understand FTS implementation from those with superficial knowledge.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-465",
        "role_title": "Backend Engineer - CDC Pipelines",
        "question": "**Question:**  \nIn a Debezium CDC pipeline streaming PostgreSQL changes to Kafka (with Snowflake as the downstream sink), describe how you would handle an unexpected schema change, such as a new required column being added to a table mid-stream. Walk through your step-by-step approach to ensure exactly-once delivery and minimal downtime (2-3 sentences max).",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Directly tests core CDC pipeline skills (schema changes, exactly-once delivery) matching role focus on PostgreSQL/Debezium/Kafka/Snowflake; crystal clear with specific scenario, constraints (2-3 sentences), and step-by-step scope; probes applied trade-offs for minimal downtime, strongly separating experienced engineers from juniors. Minor ding for assuming exact tech stack familiarity without role confirmation (-1 relevance).",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-464",
        "role_title": "Staff Engineer - Presence Systems",
        "question": "**Question:**  \nYou're designing a real-time presence system in Go using WebSockets to track user online status across 1M+ concurrent connections. Describe how you'd implement a heartbeat protocol for connection health checks, including client-side and server-side logic, handling missed heartbeats, and ensuring low-latency state updates (e.g., via Redis). What trade-offs would you consider for scalability in Kubernetes?",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (presence, heartbeats, connection management, state sync) with exact tech (Go, WebSockets, Redis) and scale (1M+), minor ding for Kubernetes not explicit in role (-1). Clarity: Well-scoped, unambiguous, specifies components without bundling multiples. Discriminative: Probes applied knowledge, trade-offs, and deep scalability understanding, strongly separates candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-462",
        "role_title": "Backend Engineer - Alert Routing",
        "question": "**Question:**  \nIn Alertmanager, you've received a batch of 10 alerts from a service outage (e.g., high CPU, high latency, error rate spikes across 5 pods). Describe your Go-based approach to implement smart grouping and deduplication before routing to PagerDuty. Include key grouping labels and a brief code snippet for the matching logic (no full implementation needed). How would you handle escalation if no one acknowledges within 5 minutes?",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (alert grouping, deduplication, escalation) with Alertmanager and Go, matching role focus; minor ding as PagerDuty is implied not explicit (-1). Clarity: Well-scoped, specific scenario, clear asks (approach, labels, snippet, escalation) without ambiguity. Discriminative: Requires applied knowledge of Alertmanager concepts, Go implementation trade-offs, and system design, distinguishing strong candidates via reasoning and code insight.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-460",
        "role_title": "Backend Engineer - Experiment Tracking",
        "question": "**Question:**  \nIn MLflow, you've just logged a run with parameters, metrics, and a model artifact to an S3-backed artifact store. Describe the exact Python code (or key MLflow API calls) you'd use to query and compare the average validation accuracy across the top 3 runs from that experiment, sorted by a custom metric like 'f1_score'. Assume you're using a PostgreSQL tracking backend.\n\n*(Expected answer: Use `mlflow.search_runs()` with `order_by=[\"metrics.f1_score DESC\"]`, `max_results=3`, filter by experiment ID if needed, then aggregate `metrics.val_accuracy` via pandas or list comprehension. Tests practical MLflow querying, metric handling, and Python fluency.)*",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests MLflow (core for experiment tracking), metric handling, artifact storage (S3), and comparison - matches role perfectly; minor ding as not all role aspects explicit (-1). Clarity: Precise, well-scoped API-focused question with clear assumptions; no bundling or ambiguity. Discriminative: Requires applied MLflow knowledge (search_runs params, filtering, aggregation), trade-offs in querying; distinguishes practical users from theorists.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-461",
        "role_title": "Senior Backend Engineer - Fraud Detection",
        "question": "**Question:**  \nYou're building a real-time fraud detection pipeline using Kafka for event streaming, Redis for caching, and scikit-learn models for scoring. Describe how you'd architect the system to score a payment transaction in under 100ms, including how you'd handle feature lookups from PostgreSQL, rule engine evaluation (e.g., velocity checks), and ML inference. What trade-offs would you make for latency vs. accuracy, and how would you use Redis here?\n\n*(Expected answer outline: Kafka consumer \u2192 Redis for hot features/low-latency lookups \u2192 simple rule engine in Python \u2192 lightweight scikit-learn inference (e.g., cached/ONNX) \u2192 score + queue to Postgres/manual review. Trade-offs: approximate features in Redis, async ML retraining, sampling for accuracy monitoring.)*",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's fraud detection pipelines, real-time scoring, rule engines, ML integration; uses exact tech stack implied (streaming, caching, ML, DB). No red flags.\nClarity: Crystal clear, well-scoped to <100ms latency with specific components; minor -1 for not specifying response format/depth.\nDiscriminative: Excellent test of applied architecture, trade-offs (latency/accuracy), and integration; distinguishes deep understanding from superficial knowledge. Not too broad for screening.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-466",
        "role_title": "Senior Backend Engineer - GitOps Tooling",
        "question": "**Question:**  \nIn ArgoCD, you've deployed an application via GitOps, but a manual `kubectl edit` by a developer has caused configuration drift. Walk me through how you'd detect this drift, confirm it, and design a simple Go-based reconciliation loop to automatically revert it to the desired Git state. What key ArgoCD APIs or CRDs would you use, and how would you handle potential race conditions?",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 10,
          "reasoning": "Directly tests core GitOps skills (drift detection, reconciliation loops) matching role's focus on declarative infra tooling. Crystal clear with specific scenario and asks for design, APIs, and trade-offs like race conditions, strongly distinguishing deep ArgoCD/Go expertise. Minor ding for assuming ArgoCD familiarity not explicitly listed, but it's core GitOps tooling.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-467",
        "role_title": "Backend Engineer - Connection Pooling",
        "question": "**Question:**  \nIn a Go application using PgBouncer for connection pooling to PostgreSQL in a Kubernetes environment, you've observed high connection latency during traffic spikes. Walk me through your step-by-step approach to diagnose and tune the PgBouncer pool sizing (e.g., default_pool_size, reserve_pool_size) while ensuring it handles failover without dropping connections. What key metrics would you monitor, and how would you validate the changes?",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Directly tests core role skills in connection pooling (PgBouncer pool sizing), scaling, failover, and transaction handling in Kubernetes; highly relevant to PostgreSQL/Go context. Crystal clear with specific parameters, step-by-step expectation, metrics, and validation; well-scoped. Strong differentiation via diagnostic reasoning, tuning trade-offs, and monitoring, distinguishing experienced engineers.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-468",
        "role_title": "Junior Backend Engineer - CI Pipelines",
        "question": "**Question:**  \nYou're setting up a GitHub Actions workflow in YAML to build and test a Python application using Docker. The workflow runs `pip install -r requirements.txt` which takes 2 minutes every time.  \n\nWrite a simple 4-step job that:  \n1. Builds a Docker image from a `Dockerfile` (assume it installs Python deps).  \n2. Caches the pip dependencies to speed it up.  \n3. Runs unit tests inside the container.  \n4. Uses matrix strategy to parallelize tests across Python 3.9 and 3.11.  \n\nProvide the full `jobs.<job_id>.steps` YAML snippet (no need for full workflow file).  \n\n*Follow-up (if time): What does the cache key look like, and why use it?*",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core CI pipeline skills (GitHub Actions YAML, caching, matrix parallelization, Docker) from role description (-0 red flags). Clarity: Precise scope (4 steps, YAML snippet only), unambiguous instructions, well-constrained. Discriminative: Requires applied YAML knowledge with trade-offs (caching keys, matrix), follow-up probes deeper understanding; strong separation for entry-level.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-469",
        "role_title": "Senior Backend Engineer - Chaos Engineering",
        "question": "**Question:**\n\nIn Chaos Mesh on Kubernetes, you're designing a failure injection experiment to test pod resilience in a critical service. Describe a scenario where you'd use a **NetworkChaos** to simulate 50% packet loss between pods in a specific namespace, including the key fields you'd set in the Chaos Mesh CRD YAML (e.g., mode, selector, and disruption rules). Why would you choose **One** mode over **All** here, and how would you limit the blast radius to avoid impacting production traffic? \n\n*(Expected: Concise YAML snippet or key fields, rationale on mode for controlled testing, namespace/selector for blast radius; tests practical Chaos Mesh + K8s knowledge in 2-5 mins.)*",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests Chaos Mesh and Kubernetes skills core to chaos engineering role (-1 for assuming Chaos Mesh as 'the' tool, not explicitly listed). Clarity: Precise, well-scoped with examples, avoids ambiguity. Discriminative: Requires applied YAML knowledge, trade-offs (One vs All), and blast radius control, separating practical experts from theorists in <5 mins.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-471",
        "role_title": "Staff Engineer - Zero Trust Architecture",
        "question": "**Question:**  \nIn a Kubernetes-based microservices environment using Envoy as a sidecar proxy, walk me through how you would automate mTLS between services using SPIFFE/SPIRE for identity, including key components you'd configure and a high-level step-by-step approach. What challenges might arise with certificate rotation, and how would you address them?",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core mTLS automation, SPIFFE identity (matches SPIRE), and microservices security in Kubernetes/Envoy context; minor -1 for not explicitly mentioning federation/policy but central to zero trust. Clarity: Precise, well-scoped with components/steps/challenges; no bundling or vagueness. Discriminative: Requires applied knowledge of integration, trade-offs in rotation challenges; distinguishes deep expertise from superficial recall.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-470",
        "role_title": "Backend Engineer - GraphQL Federation",
        "question": "**Question:**  \nIn Apollo Federation, explain how entity resolution works across subgraphs during query execution. Walk through a simple example with two subgraphs (e.g., `User` service exposing a `User` entity and `Order` service referencing it), including the key directives involved and what the gateway does step-by-step. What happens if entity resolution fails?\n\n*(Expected answer: Candidate describes `@key` directive on entity in owning subgraph, `@requires` or `@provides` if needed, reference resolution via `_entities` field on gateway, canonical entity definition, batching via `@ApolloFederationInclude`, and error handling like partial resolution or normalization failures. Tests practical understanding of federation flow.)*",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core Apollo Federation skills (schema stitching, entity resolution, query planning) from role description; no red flags. Clarity: Crystal clear with specific example scope, minor deduction for lacking explicit time/format constraint. Discriminative: Requires deep applied knowledge of directives, flow, trade-offs (batching, errors), strong separation of experts from surface-level knowers; not mere recall.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-472",
        "role_title": "Backend Engineer - Vector Search",
        "question": "**Question:**  \nYou're building a semantic search API using FastAPI, Pinecone for vector storage, and a model like Sentence Transformers for embeddings. Walk me through the key steps to implement a hybrid search endpoint that combines vector similarity (from Pinecone) with a keyword filter (using metadata), including how you'd generate and upsert embeddings for new documents. What Pinecone features would you use, and how would you handle rate limiting with Redis? \n\n*(Expected: 2-4 min verbal explanation covering embedding gen/upsert, Pinecone hybrid query, metadata filtering, Redis for caching/rate limits)*",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's vector search, embeddings, indexing, hybrid search; uses exact tech stack (FastAPI, Pinecone, embeddings). Clarity: Crystal clear steps and scope, minor deduction for no explicit time constraint (expected time noted but not in question). Discriminative: Tests integrated applied knowledge, trade-offs in hybrid search/upsert/rate limiting; strong separation without being too broad.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-477",
        "role_title": "Senior Backend Engineer - Data Catalog",
        "question": "**Question:**  \nYou've implemented a data pipeline using Apache Atlas for metadata management and Kafka for streaming events. Describe a practical approach to automatically extract and register lineage metadata (e.g., from Airflow DAGs processing data in PostgreSQL) into Atlas, including how you'd handle updates if a downstream job fails. What Kafka topic schema and Atlas entity types would you use?",
        "scores": {
          "relevance": 7,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Tests core lineage/metadata skills but assumes unlisted tools (Atlas, Kafka, Airflow; -2 red flag); Clarity: Crystal clear, well-scoped with specific scenario; Discriminative: Excellent on trade-offs, integration depth, schema design, and error handling for strong separation.",
          "composite": 8.333333333333334
        }
      },
      {
        "role_id": "be-479",
        "role_title": "Principal Engineer - Data Architecture",
        "question": "**Question:**  \nYou're leading the data architecture for a platform handling both high-throughput transactional workloads (OLTP) and real-time analytics (OLAP). We use PostgreSQL for transactions, ClickHouse for analytics, Kafka for streaming, Redis for caching, and Kubernetes for orchestration.  \n\nWalk me through your approach to architecting an efficient data pipeline that ingests events from Kafka, supports low-latency OLTP lookups in PostgreSQL, and feeds aggregated analytics into ClickHouse\u2014while ensuring scalability and fault tolerance. What key trade-offs would you consider, and how would you mentor a junior engineer on implementing it?  \n\n*(Expected: 2-5 min response; probes practical architecture strategy, tech stack integration, trade-offs like consistency vs. latency, and mentorship at principal level)*",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's data architecture strategy for analytics/transactional workloads, directly tests listed tech stack (PostgreSQL, ClickHouse, Kafka, Redis, K8s), no red flags. Clarity: Crystal clear, well-scoped with expected time and probes specified, minor deduction for no explicit constraints on format. Discriminative: Tests deep applied knowledge, trade-offs (e.g., consistency vs. latency), integration, scalability, and principal-level mentorship, strongly separates candidates.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-474",
        "role_title": "Backend Engineer - Dashboards API",
        "question": "**Question:**  \nIn our observability platform, we use Grafana dashboards with templating variables (e.g., `${instance}` or `${namespace}`) that are resolved at query time from Prometheus data sources. When building a Go API endpoint to render and share a dashboard snapshot (e.g., for public viewing), how would you handle variable substitution server-side? Describe the key steps, potential pitfalls with PostgreSQL/Redis storage, and a rough Go pseudocode snippet for the substitution logic. (2-4 min)",
        "scores": {
          "relevance": 9,
          "clarity": 10,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core role skills (Go APIs, dashboard templating, variable substitution, sharing) with exact tech (Grafana, Prometheus); minor ding for not explicitly mentioning PostgreSQL/Redis in role but fits observability platform (-1). Clarity: Crystal clear, well-scoped (2-4 min), specific context, precise ask. Discriminative: Tests applied knowledge, trade-offs (pitfalls with DB storage), and practical pseudocode; strong separation of deep vs superficial candidates.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-476",
        "role_title": "Backend Engineer - Live Updates",
        "question": "**Question:**\n\nIn our live updates system using Socket.io and Redis, we need to broadcast dashboard data updates only to users viewing a specific dashboard (e.g., dashboard ID \"abc123\"). Describe how you'd implement room management for this: \n\n1. How do you join/leave rooms when a user connects/disconnects?\n2. How do you trigger a selective broadcast (e.g., on data change)?\n3. How do you handle a user reconnecting mid-session to rejoin the correct room?\n\nProvide concise TypeScript/Node.js code snippets for the key parts (e.g., join logic, emit logic).",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests Socket.io rooms, Redis broadcasting, and reconnection\u2014core to role's live updates, dashboard-specific broadcasting, and reconnection logic (-0 red flags). Clarity: Well-scoped with 3 focused sub-questions, clear TypeScript/Node.js expectations, no bundling issues. Discriminative: Requires applied knowledge of real-time systems with trade-offs (reconnection handling), code snippets test practical skills, strong separation beyond recall.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-483",
        "role_title": "Backend Engineer - WAF Integration",
        "question": "**Question:**  \nIn a Go-based WAF integration using ModSecurity with Nginx, you need to implement custom rate limiting to block IPs exceeding 100 requests per minute. Describe a practical approach using Redis for the rate limiter, including key code snippets for the increment/check logic and eviction strategy. How would you integrate this with ModSecurity rules? (Answer in 2-5 minutes)",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core WAF rate limiting with Go, Redis, ModSecurity/Nginx from role; minor ding for assuming Go/ModSecurity not explicit (-1). Clarity: Precise scope, time limit, clear components requested. Discriminative: Requires applied knowledge of rate limiting (sliding window/token bucket trade-offs), Redis ops, and ModSecurity integration, distinguishing strong candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-475",
        "role_title": "Junior Backend Engineer - Search Analytics",
        "question": "**Question:**  \nYou're analyzing slow search queries in Kibana using Elasticsearch logs for our search analytics platform. A sample log shows a query taking 5+ seconds with this snippet:  \n\n```\n{\n  \"query\": {\n    \"bool\": {\n      \"must\": [\n        { \"match\": { \"title\": \"python tutorial\" } },\n        { \"range\": { \"timestamp\": { \"gte\": \"now-7d\" } } }\n      ]\n    }\n  },\n  \"aggs\": { \"by_user\": { \"terms\": { \"field\": \"user_id\", \"size\": 1000 } } }\n}\n```\n\nWhat\u2019s one likely performance issue here, and how would you fix it using Python (e.g., via elasticsearch-py) or Kibana? Explain briefly.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests Elasticsearch query analysis and optimization, core to search analytics logging (9, minor -1 for Python not in role desc but fits entry-level). Clarity: Crystal clear with concrete log snippet, specific scope, unambiguous (9). Discriminative: Requires applied understanding of ES performance (e.g., high-cardinality terms agg), trade-offs, and fixes; distinguishes candidates with practical knowledge (9).",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-473",
        "role_title": "Senior Backend Engineer - Refund Processing",
        "question": "**Question:**  \nIn a refund processing system using Java and Spring Boot, describe how you would implement partial refunds (e.g., refunding $15 out of a $20 original transaction) while ensuring ledger reconciliation remains balanced. Include how you'd handle a payment provider callback confirming the partial refund, and what data you'd log for audit trails. (Sketch a simple code structure or key methods if possible.)\n\n*(Expected answer outline: Use double-entry ledger (credit original charge, debit refund liability, credit customer on confirmation); idempotent callback handler with transaction ID/versioning; atomic DB updates via Spring @Transactional; audit logs with event sourcing or append-only tables capturing before/after states. Tests Kafka/Redis integration implicitly via scalability mentions.)*",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core refund processing, partial refunds, ledger reconciliation, provider callbacks, and audit trails from role; Java/Spring Boot matches implied stack (-0 red flags). Clarity: Crystal clear, well-scoped with specific scenario, no ambiguity or bundling. Discriminative: Requires applied knowledge of double-entry accounting, idempotency, transactions, and auditing; elicits trade-offs and structure to separate strong candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-481",
        "role_title": "Backend Engineer - Canary Deployments",
        "question": "**Question:**  \nYou're implementing a canary deployment for a Go microservice using Istio and ArgoCD. Walk me through how you'd configure Istio VirtualService and DestinationRule to split 10% of traffic to the canary version (v2), monitor key Prometheus metrics for comparison against the baseline (v1), and set up an automated promotion gate in ArgoCD if the canary succeeds. What specific metrics would you prioritize, and how would you trigger a rollback if they degrade?",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 10,
          "reasoning": "Directly tests core canary deployment skills (traffic splitting, metrics, rollback, promotion gates) with exact role tech (Istio, ArgoCD, Prometheus, Go microservice). Crystal clear, well-scoped walkthrough with specific constraints; elicits trade-offs in metrics, monitoring, and automation, strongly separating experienced candidates. Minor clarity ding for no explicit time constraint, but excellent overall.",
          "composite": 9.666666666666666
        }
      },
      {
        "role_id": "be-482",
        "role_title": "Senior Backend Engineer - API Monetization",
        "question": "**Question:**\n\nYou're building an API monetization platform in Go using Kong as the gateway, PostgreSQL for persistent storage, and Redis for caching. Describe how you would implement usage quota enforcement for API requests, including:\n\n1. Tracking requests per API key and time window (e.g., per hour/day).\n2. Handling quota checks at high scale (e.g., 10k reqs/sec).\n3. Integrating with Stripe for overage billing when quotas are exceeded.\n\nProvide a high-level design with key data structures, Go pseudocode snippets for critical parts (e.g., middleware or service), and trade-offs for consistency vs. performance.",
        "scores": {
          "relevance": 7,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Tests core quota management and billing skills for the role but docked -2 for mentioning Kong/Stripe/Go stack details not explicitly listed in role description. Clarity: Crystal clear, well-scoped with specific subpoints and expectations for design/pseudocode/trade-offs. Discriminative: Excellent at separating candidates via applied high-scale design, trade-offs, and implementation details; not mere recall.",
          "composite": 8.333333333333334
        }
      },
      {
        "role_id": "be-478",
        "role_title": "Backend Engineer - Cost Attribution",
        "question": "**Question:**  \nIn our cost attribution system built with Go and Kubernetes, we need to allocate cloud resource costs (e.g., from AWS or GCP) to teams based on resource tags like `team:engineering` or `team:sales`. Walk me through how you would design and implement a Go function to parse a list of Kubernetes pod metadata (including labels/tags), aggregate costs by team, and output a simple chargeback report. What key considerations would you have for accuracy, performance, and error handling? (Feel free to sketch pseudocode.)\n\n*(Expected: 2-5 min verbal/whiteboard response testing practical Go logic, grouping/aggregation, awareness of K8s labels, and mid-level tradeoffs like concurrency or validation.)*",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (cost attribution, resource tagging, K8s, Go) with no red flags (-0). Clarity: Crystal clear, well-scoped for screening with explicit time/depth expectations. Discriminative: Tests applied Go logic, K8s knowledge, aggregation, and trade-offs (accuracy/perf/error handling), strongly separating mid-level candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-480",
        "role_title": "Junior Backend Engineer - Deployment Automation",
        "question": "**Question:**  \nYou're tasked with deploying a simple Python Flask app to an AWS EC2 instance using Ansible. The app is in a Git repo, and you need to pull the latest code, install dependencies via `pip`, and start the app with `gunicorn`.  \n\nWrite a basic Ansible playbook (or key tasks from it) to automate this deployment on a target host. Assume Docker and AWS setup are already handled, and focus on the Ansible tasks for code deployment and service startup. What error-handling or idempotency features would you add to make it junior-friendly and reliable?  \n\n*(Expected: 5-10 lines of YAML tasks showing `git`, `pip`, `systemd` or similar, plus 1-2 sentences on best practices like `creates:` or `notify:`.)*",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests Ansible for deployment scripts, core to role's config management and environment setup; minor ding as EC2/Docker not explicitly listed but fits AWS deployment context (-1). Clarity: Well-scoped with clear assumptions, expected output, and constraints; no bundling or ambiguity. Discriminative: Requires writing practical YAML tasks plus explaining idempotency/trade-offs, separates those who can apply Ansible from theorists.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-486",
        "role_title": "Backend Engineer - Span Processing",
        "question": "**Question:**  \nIn our span processing pipeline using OpenTelemetry and Go, we're implementing tail sampling to retain only the most relevant traces (e.g., based on error rate or latency). Describe a practical approach you'd take to implement a tail sampler in Go that decides on-the-fly whether to keep a completed trace, including key data structures and any concurrency considerations. What trade-offs would you make for memory usage vs. sampling accuracy?",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core role skill (tail sampling in span processing) with exact tech stack (OpenTelemetry, Go); no red flags. Clarity: Crystal clear, well-scoped for screening with specific focus on data structures/concurrency; no ambiguity or bundling. Discriminative: Tests deep applied knowledge, trade-offs (memory vs accuracy), and concurrency in distributed context; strong separation of strong vs weak candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-484",
        "role_title": "Staff Engineer - Model Registry",
        "question": "**Question:**  \nYou're designing a model registry using MLflow to manage the ML lifecycle across a team of 20 data scientists. Models are trained daily, stored in S3, and deployed via Kubernetes. Walk me through your versioning strategy for models (including how you'd handle staging vs. production versions), and how you'd implement a simple governance workflow to require approval before promoting a model from staging to production. What MLflow features or integrations (e.g., with PostgreSQL or Kubernetes) would you leverage, and why?",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Directly targets core role skills (model registry, versioning, governance, deployment). Specifies MLflow (key for model registry), S3/K8s (storage/deployment), with clear scope. Highly discriminative via trade-offs in versioning/approvals and MLflow integrations; minor ding for assuming MLflow familiarity not explicitly in role desc (-1 relevance). Crystal clear, well-scoped, tests applied deep knowledge.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-489",
        "role_title": "Backend Engineer - Data Quality",
        "question": "**Question:**\n\nIn a dbt project running on Snowflake with Great Expectations for data quality checks, you've noticed intermittent schema drift where a source table occasionally adds a new column, causing downstream dbt models to fail. Describe a practical approach using dbt, Great Expectations, and Python (e.g., in an Airflow task) to detect this proactively and alert your team, including 2-3 key code snippets or configurations you'd implement.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core schema drift detection in dbt/Snowflake/Great Expectations stack for warehouse pipelines (-0 red flags). Clarity: Well-scoped with specific tools, scenario, and request for 2-3 snippets; no ambiguity or bundling. Discriminative: Requires applied knowledge of integration, proactive detection, alerting, and trade-offs in real pipeline failure scenario, strongly separates strong candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-487",
        "role_title": "Senior Backend Engineer - Search Ranking",
        "question": "**Question:**  \nIn a learning-to-rank (LTR) pipeline for search relevance, you've identified that your model's precision@10 is dropping in production after deploying a new version. Walk me through your step-by-step debugging process, including 2-3 key metrics you'd check first and how you'd use your tech stack (e.g., Elasticsearch, Python, ML tools) to investigate and iterate.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core LTR pipeline skills (debugging production issues) matching role's focus on pipelines, feature engineering, model training, and A/B testing; mentions relevant stack without extras (-0 red flags). Clarity: Crystal clear, well-scoped with specific asks (step-by-step, 2-3 metrics, tech stack use), no bundling or ambiguity. Discriminative: Tests applied debugging, trade-offs, and deep production LTR understanding, strongly separates candidates; not recall or trivial.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-485",
        "role_title": "Junior Backend Engineer - Payment Webhooks",
        "question": "**Question:**\n\nYou're building a FastAPI endpoint to receive payment webhooks from a provider like Stripe. The webhook payload contains a `payment_id` and event details. Explain in 3-5 sentences how you'd implement idempotency to avoid duplicate processing if the same webhook is retried. Include relevant Python/FastAPI code snippet (e.g., using Redis or PostgreSQL).",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests idempotency for payment webhooks, core to role; FastAPI/Python matches implied stack, no red flags (-0). Clarity: Precise scope (3-5 sentences, code snippet, specific DB options), unambiguous for screening. Discriminative: Requires applied knowledge of idempotency patterns, DB integration, and trade-offs, strongly separates candidates able to implement vs. theorize.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-488",
        "role_title": "Backend Engineer - Gaming Backend",
        "question": "**Question:**  \nIn a multiplayer game backend using Go and WebSockets, you need to synchronize player positions across 100 connected clients with minimal latency. Redis is available for pub/sub, and PostgreSQL for persistent state.  \n\nDescribe a simple, practical approach to handle state synchronization (e.g., player position updates). Include:  \n- How you'd structure the update flow in Go.  \n- Role of WebSocket vs. Redis.  \n- How to avoid overwhelming clients or the server (1-2 sentences on optimizations).  \n\n*(Expect 3-5 sentence response; follow-up on trade-offs if time allows.)*",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 8,
          "reasoning": "Relevance: Directly targets core role skills (real-time state sync for multiplayer game backend) and exact tech stack (Go, WebSockets, Redis pub/sub, PostgreSQL), no red flags. Clarity: Crystal clear with precise scope, components specified, and expected response length; minor jargon is contextualized. Discriminative: Tests applied architecture knowledge and optimizations with good separation via trade-offs potential, though slightly broad (-1 for possible edge over 10min).",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-493",
        "role_title": "Staff Engineer - Reliability Standards",
        "question": "**Question:**  \nAs a Staff Engineer defining reliability standards for our org, walk me through how you would design a production readiness review (PRR) process for a new Kubernetes-based service. What key criteria would you include, and how would you ensure it catches reliability risks early? (Feel free to sketch a simple checklist or gates on paper if helpful.)",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly matches core role duties (reliability standards, PRR design) with Kubernetes from context; no red flags. Clarity: Well-scoped for screening, clear intent, minor deduction for no explicit time constraint. Discriminative: Tests applied SRE knowledge, trade-offs, and process design, strongly separates experienced Staff Engineers from juniors.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-490",
        "role_title": "Senior Backend Engineer - Environment Management",
        "question": "**Question:**  \nIn our environment management system for preview deployments, we're using Kubernetes namespaces for isolation, with resource quotas and TTL-based cleanup via a Go service. Describe a practical approach you'd take in Go to implement the TTL cleanup logic\u2014specifically, how would you efficiently identify and delete namespaces that have exceeded their TTL (e.g., 24 hours), while minimizing API server load and handling potential race conditions? Include key code snippets or pseudocode for the core loop or query logic.\n\n*(Expected response: Candidate outlines a cron-like scheduler or periodic reconciliation loop using Kubernetes client-go/informers for efficient watching/listing of annotated namespaces, filtering by creation timestamp + TTL annotation, then graceful deletion with finalizers or preconditions. Senior candidates might mention leader election, rate limiting, backoff retries, or integration with custom resources.)*",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's core focus on namespace isolation, quotas, and TTL cleanup in Kubernetes/Go (-0 red flags). Clarity: Crystal clear with specific scope (TTL logic, efficiency, race conditions), well-formed for screening; minor deduction for lacking exact time constraint. Discriminative: Tests applied deep knowledge, trade-offs (API load, races), distinguishes seniors via advanced concepts like leader election; not trivial recall.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-494",
        "role_title": "Backend Engineer - API Mocking",
        "question": "**Question:**\n\nYou're setting up WireMock in a Docker container for mocking a PostgreSQL-based user service API during contract testing with TypeScript/Node.js. The API endpoint is `GET /users/:id`, which should return a templated JSON response like `{ \"id\": \"{{request.path.[1]}}\", \"name\": \"John Doe\", \"email\": \"{{randomEmail}}\" }` only if the request includes a valid `Authorization: Bearer <token>` header.\n\nProvide a concise code snippet (or docker-compose.yaml + stubs config) showing:\n1. How to run WireMock in Docker.\n2. How to configure the stub for header-based request matching and response templating.\n\n(Expect ~3-5 lines of key config; explain any non-obvious parts briefly.)",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests Docker, WireMock, TypeScript/Node.js context, templating, and header matching\u2014core to API mocking infrastructure (-1 for not explicitly covering contract verification). Clarity: Precise scope, constraints (3-5 lines), and expectations make it unambiguous. Discriminative: Requires applied knowledge of WireMock config, Docker integration, and templating syntax to distinguish proficient candidates from those with superficial familiarity.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-495",
        "role_title": "Senior Backend Engineer - Audit Logging",
        "question": "**Question:**  \nIn Go, design a simple tamper-proof audit logging function that appends a log entry (e.g., `{userID: string, action: string, timestamp: time.Time}`) to a Kafka topic, ensuring immutability and integrity against tampering. Include hashing for tamper detection and briefly explain how you'd extend it for ClickHouse storage with retention policies. Provide code snippet and rationale (2-3 sentences).",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core audit logging skills (tamper-proofing, hashing) with Go (likely relevant), Kafka for streaming, and ClickHouse for storage/retention per role (-1 for assuming Go/Kafka not explicitly listed). Clarity: Well-scoped with specific log structure, requirements, code snippet request, and brief extension; no ambiguity. Discriminative: Requires applied design (hashing, Kafka producer), code, trade-offs for immutability, and extension thinking, separating strong candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-492",
        "role_title": "Backend Engineer - CD Pipelines",
        "question": "**Question:**  \nIn an ArgoCD GitOps setup using Helm charts for a multi-environment deployment (e.g., dev, staging, prod), describe a practical approach to implement automated promotion from staging to prod, including a manual approval gate and a rollback mechanism if the deployment fails health checks. What Go-based tool or custom controller might you use to automate the rollback, and why?  \n\n*(Expected answer outline: Use ArgoCD App of Apps or ApplicationSets with environment-specific Helm values; implement approval via ArgoCD's resource hooks or integrate with GitHub Actions for manual gates; for rollback, leverage Argo Rollouts with AnalysisTemplates for health checks or a custom Go controller using the ArgoCD API/client-go to detect failures and trigger `argocd app rollback`. Tests GitOps/CD pipeline design at mid-level.)*",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core GitOps/CD pipeline skills (ArgoCD, Helm, multi-env, approvals, rollbacks) from role; minor ding for Go tool not explicitly listed (-1). Clarity: Precise, well-scoped with context, no ambiguity. Discriminative: Requires applied design knowledge, trade-offs (hooks vs Actions, Rollouts vs custom), distinguishes mid-level expertise from basics.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-499",
        "role_title": "Principal Engineer - Search Platform",
        "question": "**Question:**  \nAs a Principal Engineer leading our search platform, imagine our enterprise search service\u2014built on Elasticsearch, Kafka for event streaming, and Redis for caching\u2014is experiencing increased tail latencies during peak traffic, impacting user experience. Walk me through your step-by-step approach to diagnose and resolve this issue, highlighting key trade-offs in scaling decisions you'd consider for long-term platform strategy.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core search platform leadership skills with exact tech stack (Elasticsearch, Kafka, Redis) from role; minor genericism (-1). Clarity: Crystal clear scenario, step-by-step scoping, no ambiguities. Discriminative: Probes applied diagnostics, resolution, and strategic trade-offs, strongly separating experienced principals from juniors.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-491",
        "role_title": "Junior Backend Engineer - Read Replicas",
        "question": "**Question:**\n\nYou're building a Python service using SQLAlchemy and PostgreSQL with a primary database and one read replica. You notice that some customer-facing queries (e.g., fetching a user's recent orders) are occasionally returning stale data due to replication lag on the read replica.\n\nIn 2-3 sentences, explain how you would modify your code to route **only these customer queries** to the primary database while sending all other read-heavy queries (e.g., analytics) to the read replica. Include a brief code snippet showing the routing logic (using SQLAlchemy sessions).",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Directly tests core role skills (read replica routing, replication lag handling) with exact tech stack (Python, SQLAlchemy, PostgreSQL); crystal clear scope (2-3 sentences, specific query types, code snippet); evaluates applied knowledge of conditional routing and trade-offs, distinguishing candidates who understand session management from those reciting basics. Minor deduction for no exact role match on 'customer queries,' but highly targeted.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-496",
        "role_title": "Junior Backend Engineer - Model Serving",
        "question": "**Question:**  \nYou're building a FastAPI endpoint to serve a pre-trained scikit-learn model for predicting house prices from JSON input (e.g., `{\"area\": 1000, \"rooms\": 3}`). The model is saved as a `joblib` file named `house_model.joblib`.\n\nWrite a minimal FastAPI code snippet (including imports) that:  \n1. Loads the model once at startup.  \n2. Accepts a POST request at `/predict` with JSON input.  \n3. Returns the prediction as JSON (e.g., `{\"prediction\": 250000.0}`).\n\nInclude a simple Pydantic model for input validation. No need for error handling or extras\u2014just the core working code.",
        "scores": {
          "relevance": 9,
          "clarity": 10,
          "discriminative": 8,
          "reasoning": "Relevance: Directly tests FastAPI (API deployment), scikit-learn/joblib (ML model loading), Pydantic (validation)\u2014core to role; minor ding as role emphasizes batching/monitoring not tested (-1). Clarity: Crystal clear, well-scoped with explicit requirements, constraints, and example formats. Discriminative: Requires applied integration of multiple tools with correct startup loading and validation; distinguishes those who can write working code from theorists.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-497",
        "role_title": "Backend Engineer - Payout Systems",
        "question": "**Question:**  \nIn our payout system, we process daily batches of marketplace settlements (e.g., 10k+ transfers) using Go and PostgreSQL, with Kafka for event streaming and Redis for caching. Walk me through how you'd design the batch processing flow to ensure exactly-once delivery of payouts, including handling duplicates, failures, and reconciliation with bank responses. What key Go libraries or patterns (e.g., idempotency) would you use, and how would you leverage Kafka/Redis/PostgreSQL?",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 10,
          "reasoning": "Relevance: Perfectly matches role's core focus on payout batch processing, settlements, validation, reconciliation, and exact tech stack (Go, PostgreSQL, Kafka, Redis). No red flags. Clarity: Crystal clear, well-scoped to batch flow with specific elements; minor deduction as no explicit time constraint for screening. Discriminative: Tests deep applied knowledge, trade-offs (duplicates, failures, exactly-once), and role-specific integration, strongly separating strong candidates.",
          "composite": 9.666666666666666
        }
      },
      {
        "role_id": "be-498",
        "role_title": "Senior Backend Engineer - Profiling Infrastructure",
        "question": "**Question:**  \nIn Pyroscope, you've collected a flame graph for a Go service showing high CPU usage in a specific goroutine. Walk me through your step-by-step process to investigate, optimize, and validate the performance issue using Pyroscope's features (e.g., baseline comparison, diffing) and integrate the fix into a Kubernetes-deployed service with Grafana dashboards for ongoing monitoring. What key Pyroscope CLI or UI commands would you use, and how would you store/query the profiling data efficiently in ClickHouse?",
        "scores": {
          "relevance": 3,
          "clarity": 6,
          "discriminative": 7,
          "reasoning": "Relevance: Superficially mentions performance analysis but assumes Pyroscope/ClickHouse expertise not in role description (build infra, flame graphs generically); red flags: tests unlisted techs (-2), generic perf process (-3). Clarity: Understandable but vague on expected depth/scope for screening, bundles multiple steps without constraints (-2). Discriminative: Tests applied knowledge well but too scenario-specific and broad (>10min, -2).",
          "composite": 5.333333333333333
        }
      },
      {
        "role_id": "be-500",
        "role_title": "Staff Engineer - Streaming Architecture",
        "question": "**Question:**  \nYou're designing a real-time user activity feed using Kafka, Redis, and WebSockets in Rust on Kubernetes. Describe how you'd implement exactly-once fan-out delivery from a single Kafka topic to 10,000+ concurrent WebSocket connections, including your approach to event schemas, deduplication, and scaling across K8s pods. What trade-offs would you make for latency vs. durability?",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 10,
          "reasoning": "Relevance: Directly targets core role skills (streaming infra, event schemas, fan-out, delivery guarantees) with Kafka (implied in streaming) and Kubernetes; minor ding for unmentioned Redis/WebSockets/Rust (-1). Clarity: Well-scoped, specific constraints, unambiguous intent for screening depth. Discriminative: Probes deep applied knowledge, trade-offs (latency/durability), architecture decisions, strongly separates experts.",
          "composite": 9.333333333333334
        }
      }
    ]
  },
  "claude-4-5-haiku": {
    "model": "claude-4-5-haiku",
    "num_samples": 100,
    "avg_relevance": 9.15,
    "avg_clarity": 8.86,
    "avg_discriminative": 9.02,
    "avg_composite": 9.010000000000003,
    "results": [
      {
        "role_id": "be-406",
        "role_title": "Senior Backend Engineer - LLM Serving",
        "question": "# Technical Screening Question\n\n**Describe a scenario where you'd need to tune the batch size and max_tokens parameters in vLLM, and walk me through your approach to finding the right balance. What metrics would you monitor, and how would you handle a situation where increasing batch size actually decreases throughput?**\n\n---\n\n## Why This Question Works:\n\n**Practical & Role-Specific:**\n- Directly relevant to the core responsibility (batching optimization)\n- Tests real-world decision-making, not memorization\n\n**Senior-Level Appropriate:**\n- Requires systems thinking (throughput vs. latency tradeoffs)\n- Expects knowledge of multiple failure modes\n- Assesses debugging methodology\n\n**Time-Bound:**\n- Can be answered substantively in 2-5 minutes\n- Allows follow-ups to probe deeper if needed\n\n**Reveals Key Competencies:**\n- Understanding of LLM serving bottlenecks (memory, compute, I/O)\n- Familiarity with vLLM's batching mechanics\n- Monitoring/observability mindset\n- Problem-solving approach under constraints\n\n---\n\n## What You're",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's core focus on batching optimization and LLM serving with vLLM (no red flags). Clarity: Crystal clear and well-scoped for screening, minor deduction for lacking explicit time constraint. Discriminative: Tests deep applied knowledge, trade-offs, debugging, and metrics\u2014strong separation of senior talent from juniors.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-409",
        "role_title": "Junior Backend Engineer - File Upload",
        "question": "# Screening Question\n\n**You're building a file upload endpoint in FastAPI that accepts image files and stores them in S3. The endpoint needs to:**\n- Accept files up to 10MB\n- Validate that only PNG and JPG files are allowed\n- Return the S3 URL where the file was stored\n\n**Write the code for this endpoint, including:**\n1. The route definition with appropriate parameters\n2. File validation logic\n3. Basic S3 upload logic (you can use pseudocode/boto3 calls)\n\n---\n\n## Evaluation Criteria\n\n\u2713 **Strong answer includes:**\n- Proper use of `UploadFile` from FastAPI\n- File size and extension validation\n- Correct S3 upload implementation (boto3 `put_object` or similar)\n- Appropriate error handling/HTTP status codes\n- Returns the S3 URL\n\n\u26a0\ufe0f **Common gaps to listen for:**\n- Forgetting to validate file size before upload\n- Not checking file extensions or doing it insecurely\n- Missing error handling for S3 operations\n- Not understanding async/await patterns in FastAPI\n\n**Follow-up if",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Directly tests core file upload API skills (multipart handling, validation, S3 integration) matching role; crystal clear with precise scope, constraints, and expectations; strong separation via applied FastAPI/S3 knowledge, validation pitfalls, and error handling\u2014reveals practical ability beyond trivia.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-402",
        "role_title": "Backend Engineer - Model Deployment",
        "question": "# Technical Screening Question\n\n**You need to deploy two versions of a machine learning model to production simultaneously\u2014a stable v1 serving 90% of traffic and a new v2 serving 10% for canary testing. Both models should be accessible through a single endpoint.**\n\n**How would you implement this using KServe, and what are the key components you'd need to configure?**\n\n---\n\n## Why This Question Works:\n\n\u2705 **Practical relevance** \u2014 Directly addresses the core responsibility (deployment strategies)\n\n\u2705 **Mid-level appropriate** \u2014 Requires KServe knowledge but doesn't demand expert-level optimization details\n\n\u2705 **Reveals competency across the stack** \u2014 Tests understanding of:\n- KServe InferenceService configuration\n- Traffic splitting concepts\n- Kubernetes service routing\n- Model versioning\n\n\u2705 **Timeboxed** \u2014 Candidates can outline the approach in 2-3 minutes, with room for follow-ups on implementation details\n\n## Possible Follow-ups:\n- \"How would you monitor metrics to decide when to shift more traffic to v2?\"\n- \"What happens if v2 has high lat",
        "scores": {
          "relevance": 7,
          "clarity": 9,
          "discriminative": 8,
          "reasoning": "Relevance: Tests core deployment strategies but KServe not mentioned in role description (-2); not generic (-0). Clarity: Crystal clear, well-scoped with specific scenario and components; no red flags. Discriminative: Tests applied knowledge of configuration and trade-offs like traffic splitting, good separation for mid-level roles; timeboxed appropriately.",
          "composite": 8.0
        }
      },
      {
        "role_id": "be-403",
        "role_title": "Backend Engineer - Inference Optimization",
        "question": "# Screening Question\n\n**You're optimizing an inference pipeline for a large language model that's hitting latency SLAs in production. The model runs on a single GPU, and you're seeing:**\n- P95 latency: 850ms (SLA: 500ms)\n- GPU memory utilization: 85%\n- Average batch size: 4\n\n**Walk me through your approach to identify the bottleneck and propose 2-3 optimization strategies. What would you measure first, and why?**\n\n---\n\n## Why This Question Works\n\n**Practical scope:** Tests real-world problem-solving without requiring deep implementation details\n\n**Assesses:**\n- Systems thinking (recognizing multiple potential bottlenecks: compute, memory, batching)\n- Prioritization (what to measure first with limited time)\n- Knowledge of core optimization techniques (quantization, batching, memory optimization)\n- Understanding of the inference stack (where TensorRT/Triton would fit)\n\n**Level-appropriate:** A mid-level engineer should know *which* tools exist and *when* to use them, without needing to implement from scratch\n\n**Follow-ups available:**",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core role skills (quantization, batching, GPU memory) in realistic inference optimization scenario (-0 for no red flags). Clarity: Well-scoped with specific metrics/constraints, unambiguous intent for screening. Discriminative: Requires prioritization, systems thinking, and trade-off knowledge to distinguish strong mid-level candidates from weak ones.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-401",
        "role_title": "Backend Engineer - Training Infrastructure",
        "question": "# Screening Question\n\n**You're designing a Ray cluster that trains models on a dataset too large for a single GPU. Walk me through how you would structure the data loading and training code to efficiently distribute work across multiple GPUs. What are the key things you'd consider to avoid bottlenecks?**\n\n---\n\n## Why This Works\n\n\u2705 **Practical & Real** - Directly mirrors the job's core responsibility  \n\u2705 **Right Difficulty** - Mid-level should know distributed basics, but nuances separate strong candidates  \n\u2705 **Open-Ended** - Reveals depth: data parallelism strategies, Ray actor patterns, bottleneck awareness, Kubernetes resource requests  \n\u2705 **Time-Boxed** - Answerable in 3-4 minutes without being trivial  \n\u2705 **Follow-ups Available** - Can probe deeper on Ray task scheduling, fault tolerance, or GPU memory management\n\n**What you're listening for:**\n- Understanding of data sharding/batching across workers\n- Awareness of I/O bottlenecks (data loading shouldn't block training)\n- Mention of Ray's distributed data or actor model",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core distributed ML training skills with Ray, matching job's focus on GPU allocation and orchestration (-0 red flags). Clarity: Crystal clear, well-scoped for screening, specific context avoids ambiguity. Discriminative: Probes applied knowledge of data parallelism, bottlenecks, and Ray patterns, revealing trade-offs and depth to separate strong candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-404",
        "role_title": "Senior Backend Engineer - Feature Platform",
        "question": "# Technical Screening Question\n\n**Scenario-based question:**\n\n\"You're designing a feature store where ML teams need both batch features (computed daily) and real-time features (computed on-request). Walk me through how you'd handle a situation where a real-time feature depends on aggregations from a batch feature\u2014for example, a user's purchase count from the last 30 days.\n\nWhat would be your approach to:\n1. Computing and storing this in Feast\n2. Ensuring consistency between batch and real-time paths\n3. Handling the latency tradeoff\"\n\n---\n\n## Why this works:\n\n\u2705 **Practical** \u2013 Tests real architectural decisions in feature platforms  \n\u2705 **Seniority-appropriate** \u2013 Expects systems thinking, not just API knowledge  \n\u2705 **Tech-specific** \u2013 Naturally brings up Feast concepts (batch sources, online stores, feature views)  \n\u2705 **Open-ended** \u2013 Senior candidates can discuss tradeoffs (Redis consistency, staleness, compute costs)  \n\u2705 **Timeboxed** \u2013 Can be answered thoroughly in 3-4 minutes with follow-ups",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core feature store skills (batch/real-time computation, dependencies) for ML platform role using Feast (implied in context); minor ding for not quoting role's exact tech but perfectly aligned (-1 red flag avoided). Clarity: Well-scoped scenario with 3 focused subpoints, unambiguous, no bundling issues. Discriminative: Probes trade-offs (consistency, latency), systems thinking, and Feast application, strongly separates seniors from juniors.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-410",
        "role_title": "Backend Engineer - Bulk Operations",
        "question": "# Screening Question\n\n**Design a bulk update API endpoint that processes up to 10,000 records. Walk me through how you'd handle:**\n\n1. **Partial failures** \u2014 some records succeed, others fail validation or hit conflicts\n2. **Idempotency** \u2014 the same request submitted twice shouldn't create duplicate side effects\n3. **Client feedback** \u2014 how would you return results to the caller?\n\n**You can use pseudocode or describe your approach. What would be your main design decisions?**\n\n---\n\n## Why This Question Works\n\n- **Practical:** Tests real-world bulk operation challenges they'd face on day one\n- **Reveals depth:** Answers expose knowledge of idempotency keys, transaction boundaries, error handling patterns, and API design\n- **Mid-level appropriate:** Doesn't require exotic knowledge; a solid mid-level engineer should have encountered these problems\n- **Conversational:** Opens dialogue\u2014you can dig into their Redis/Kafka choices, PostgreSQL transaction strategy, or Go concurrency patterns based on their answer\n- **Time-boxed:** Candidates can sketch a solid answer in 2-5 minutes",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's core needs (bulk ops, partial success, idempotency). Clarity: Crystal clear with specific scope (10k records), well-scoped for screening; minor deduction for no explicit time/format constraint. Discriminative: Tests applied design trade-offs (idempotency keys, transactions, error aggregation), reveals depth without being trivial or impossible.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-405",
        "role_title": "Senior Backend Engineer - Model Monitoring",
        "question": "# Screening Question\n\n**You're implementing a monitoring system for a production recommendation model. Over the past week, your metrics show the model's precision dropped from 0.92 to 0.78, but the feature distributions look virtually identical to training data. What are the most likely causes you'd investigate first, and how would you approach diagnosing this systematically?**\n\n---\n\n## Why This Question Works\n\n**Tests practical expertise:**\n- Distinguishes between data drift vs. model/prediction drift (common senior-level insight)\n- Requires knowledge of what monitoring actually catches and what it misses\n- Shows systematic debugging approach for production issues\n\n**Appropriate for seniority:**\n- Not a gotcha question\u2014open-ended to reveal depth of experience\n- Senior engineer should discuss multiple hypotheses, not just one answer\n- Tests judgment about what to prioritize (efficiency matters in production)\n\n**Realistic scenario:**\n- Common real-world situation that trips up junior engineers\n- Directly relevant to the role's core responsibility\n\n**Reveals:**\n- Model monitoring maturity (do they know feature drift \u2260 performance drift?)\n- Production troubleshooting experience\n- Whether they",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's core focus on model monitoring, drift detection, and performance tracking; no red flags. Clarity: Crystal clear scenario with precise metrics, well-scoped for screening; minor deduction as no explicit time/format constraint. Discriminative: Tests deep applied knowledge of drift types, prioritization, and systematic diagnosis, strongly separates seniors from juniors via trade-offs and hypotheses.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-407",
        "role_title": "Staff Backend Engineer - ML Infrastructure",
        "question": "# Screening Question\n\n**You're tasked with designing a training platform where data scientists can submit jobs that need to scale from a single GPU to 100+ GPUs across a cluster. Walk me through how you'd approach this problem\u2014what are the key architectural decisions you'd make, and what trade-offs would you consider?**\n\n---\n\n## Why This Works:\n\n**Tests practical, staff-level expertise:**\n- Requires understanding of distributed systems (Ray/Spark fundamentals)\n- Assesses platform thinking beyond just coding\n- Reveals experience with real scaling challenges\n- Tests cost/complexity trade-offs (staff engineers optimize for this)\n\n**Appropriate for seniority:**\n- Not a gotcha question; experienced engineers have concrete opinions\n- Open-ended enough to see their decision-making process\n- Allows them to showcase leadership perspective (defining standards, trade-offs)\n\n**Clear signal in the answer:**\n- Do they mention fault tolerance, checkpointing, resource scheduling?\n- Do they think about DX (data scientist experience)?\n- Do they consider observability, cost monitoring?\n- Do they acknowledge Ray/Spark trade-offs knowingly?\n\n**Time-",
        "scores": {
          "relevance": 7,
          "clarity": 6,
          "discriminative": 8,
          "reasoning": "Relevance: Tests core ML infra scaling and platform design directly matching role, but generic distributed training (no specific tech stack like role implies) and lacks cost optimization emphasis (-1 generic, -1 misses specifics). Clarity: Clear intent for architectural approach but 'design a system' without time/format/constraints/scope (e.g., team size, budget) (-2 red flag), vague depth. Discriminative: Strong on trade-offs, applied knowledge, and deep signals like fault tolerance/DX/observability, good separation for staff-level.",
          "composite": 7.0
        }
      },
      {
        "role_id": "be-408",
        "role_title": "Junior Backend Developer - Health Endpoints",
        "question": "# Screening Question\n\n**Describe the difference between a liveness probe and a readiness probe in Kubernetes. Why would you implement them differently, and what might each endpoint return in Go?**\n\n---\n\n## Why This Question Works:\n\n\u2713 **Practical & Role-Relevant:** Directly addresses the core responsibility (health endpoints)\n\n\u2713 **Right Difficulty Level:** Junior developers should know this\u2014it's foundational Kubernetes knowledge, not advanced\n\n\u2713 **Multi-Part Assessment:** Tests understanding of:\n- Kubernetes concepts (liveness vs readiness)\n- Implementation reasoning (why they differ)\n- Go coding ability (what the endpoints look like)\n\n\u2713 **2-5 Minute Response:** Candidates can sketch a quick answer without deep system design\n\n\u2713 **Open-Ended:** Reveals depth of understanding\u2014a junior might say \"they're different states,\" while someone stronger explains cascading failures or dependency checks\n\n---\n\n## What You're Looking For:\n\n- **Good answer:** Explains that liveness = \"is the app running?\" and readiness = \"can it handle traffic?\"\n- **Better answer:** Mentions that readiness checks",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's core focus on health check endpoints (liveness/readiness) in Kubernetes/Go. Clarity: Crystal clear, well-scoped multi-part question for screening, minor vagueness on exact Go return format but not deducting. Discriminative: Excellent separation via conceptual understanding, reasoning (trade-offs like cascading failures), and implementation; reveals depth without being recall or trivial. No red flags.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-411",
        "role_title": "Backend Engineer - Admin APIs",
        "question": "# Technical Screening Question\n\n## Design an audit logging system for an admin API\n\n**Scenario:**\nYou're building an admin API where privileged operations (user suspension, permission changes, data exports) must be logged for compliance. The system needs to:\n- Record *what* action was performed, *who* performed it, and *when*\n- Handle high volume (thousands of operations/day)\n- Allow querying audit logs by user, action type, and date range\n- Ensure logs cannot be tampered with\n\n**Your task:**\n1. Sketch a database schema for storing audit logs\n2. Explain how you'd integrate logging into your FastAPI endpoints (show a brief code example or pseudocode)\n3. Discuss one trade-off you'd make between completeness and performance\n\n---\n\n## What This Tests\n\n\u2713 **Practical API design** - How they structure data for a real constraint  \n\u2713 **Python/FastAPI knowledge** - Middleware, decorators, or dependency injection patterns  \n\u2713 **Database thinking** - Schema design, indexing, query patterns for compliance use cases  \n\u2713 **Mid-level judgment** - Trade-",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core role needs (audit logging for admin APIs), tests FastAPI (implied in role context), no red flags (-0). Clarity: Well-scoped scenario with specific requirements, single focused design task with clear subtasks, no bundling issues. Discriminative: Requires applied schema design, integration knowledge, and trade-off analysis, strongly separates mid-level thinkers via practical judgment.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-413",
        "role_title": "Senior Backend Engineer - API Gateway Logic",
        "question": "# Screening Question\n\n**You're implementing a custom Envoy filter in Go that needs to:**\n1. Extract a user ID from request headers\n2. Apply different rate limits based on user tier (stored in a shared cache)\n3. Add response headers with latency metrics\n4. Reject requests that exceed their tier's limit with a 429 status\n\n**Walk me through your approach:** How would you structure this filter? What are the key extension points in Envoy you'd use, and how would you handle the cache lookup without blocking the request path?\n\n---\n\n## Why This Question Works\n\n\u2713 **Practical & Real** \u2014 Actual API gateway use case (rate limiting, header manipulation, caching)  \n\u2713 **Senior-Level** \u2014 Requires understanding of Envoy architecture, concurrency patterns, and performance trade-offs  \n\u2713 **Tech Stack** \u2014 Tests knowledge of Envoy filters and Go integration  \n\u2713 **Concise** \u2014 Answerable in 3-4 minutes with room for follow-ups  \n\u2713 **Reveals Depth** \u2014 Response shows whether they understand filter lifecycle, async operations, and gateway",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests Envoy filters, Go, request transformation, routing logic, and caching - core to API gateway extensions role (-0 red flags). Clarity: Precise tasks with specific non-blocking constraint, unambiguous for screening scope. Discriminative: Probes architecture, concurrency trade-offs, and Envoy extension points, strongly separates experienced candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-412",
        "role_title": "Backend Engineer - Analytics APIs",
        "question": "# Technical Screening Question\n\n**You're building an analytics API endpoint that returns daily revenue aggregations for the past year. The query currently takes 8 seconds, which is too slow for dashboard load times. Walk me through your approach to optimize this\u2014what would you investigate first, and what specific strategies would you consider?**\n\n---\n\n## Why This Question Works:\n\n**Practical Relevance:** Directly mirrors the core responsibility of aggregating and caching time-series data\n\n**Seniority Appropriate:** \n- Mid-level engineers should recognize multiple optimization layers (query-level, caching, architecture)\n- Not expecting mastery of all, but strategic thinking across the stack\n\n**Reveals Key Competencies:**\n- Understanding of ClickHouse query optimization (sampling, pre-aggregation, partitioning)\n- Redis caching strategy decisions (TTL, key design, invalidation)\n- Go API design (pagination, response formatting)\n- Diagnostic thinking (where to start troubleshooting)\n\n**Time Efficient:** Candidate can outline approach in 2-3 minutes, with room for follow-up depth based on their answers\n\n**Natural Follow-ups:**",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (aggregation queries, time-series, caching) without generic flaws (-0 red flags). Clarity: Crystal clear scenario, well-scoped for screening, no ambiguity or missing constraints. Discriminative: Probes diagnostic thinking, trade-offs (query opt, caching strategies), distinguishes strategic depth from superficial answers; 2-3 min response fits perfectly.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-415",
        "role_title": "Senior Backend Engineer - Multipart APIs",
        "question": "# Screening Question\n\n**You're designing a resumable upload API for large files (up to 10GB). A client uploads a file in 5MB chunks, but the connection drops after chunk 3. When the client reconnects, how would you:**\n\n1. **Identify which chunks were successfully persisted?**\n2. **Handle the case where chunk 4 was partially written to S3?**\n3. **Decide whether to use S3's multipart upload API or manage chunks yourself?**\n\n**What trade-offs would you consider between complexity, cost, and reliability?**\n\n---\n\n## Why This Works\n\n\u2705 **Practical & Real** \u2014 Directly mirrors the job responsibility  \n\u2705 **Senior-level** \u2014 Requires architectural thinking, not just syntax  \n\u2705 **Concise** \u2014 Can be answered in 3-4 minutes with good follow-ups  \n\u2705 **Multi-faceted** \u2014 Tests state management, AWS knowledge, and trade-off analysis  \n\u2705 **Room to dig deeper** \u2014 You can probe their reasoning on idempotency, metadata storage, cleanup logic, etc.",
        "scores": {
          "relevance": 7,
          "clarity": 7,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core resumable upload/chunk skills but assumes S3/AWS (not explicitly listed, -2) and bundles multiple sub-questions (-1 from red flags). Clarity: Clear scenario but multiple bundled questions (-2) make it less focused for screening. Discriminative: Excellent on trade-offs, applied AWS knowledge, and edge cases (partial writes, resumption), strongly separates seniors.",
          "composite": 7.666666666666667
        }
      },
      {
        "role_id": "be-416",
        "role_title": "Staff Backend Engineer - External APIs",
        "question": "# Technical Screening Question\n\n**You're designing an external API for partners that need real-time access to customer transaction data. Some partners are high-volume, others are occasional users. Walk me through how you'd approach the rate limiting and monetization strategy for this API\u2014what would you consider, and what trade-offs would you make?**\n\n---\n\n## Why This Question Works:\n\n**Tests practical, staff-level thinking:**\n- Requires understanding of API gateway capabilities (Kong is their tech stack)\n- Demonstrates monetization strategy knowledge (key requirement)\n- Shows partner enablement thinking (tiered access, fairness)\n- Reveals architectural decision-making at scale\n\n**Allows for 2-5 minute response** covering:\n- Rate limiting approaches (fixed vs. token bucket, per-tier quotas)\n- Monetization models (usage-based, tier-based, hybrid)\n- Technical implementation (where enforcement happens\u2014Kong, application layer)\n- Trade-offs (complexity vs. fairness, cost recovery vs. partner friction)\n\n**Differentiates staff-level candidates** by how they discuss:\n- Partner friction and business implications\n- System design trade-offs",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core API strategy, monetization, and partner enablement; aligns perfectly with role despite not naming Kong (-1 minor). Clarity: Crystal clear, well-scoped for screening with explicit focus on rate limiting/monetization and trade-offs. Discriminative: Excellent at separating staff-level candidates via trade-offs, business implications, and architectural depth; not recall-based.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-418",
        "role_title": "Junior Backend Engineer - Service Clients",
        "question": "# Screening Question\n\n**You're building a gRPC client that calls a downstream service. The service occasionally times out or returns temporary errors. Walk me through how you'd implement a basic retry mechanism in Go. What would you consider to prevent making things worse?**\n\n---\n\n## Why This Question Works\n\n\u2705 **Practical & Real** \u2013 Junior engineers actually build this  \n\u2705 **Right Scope** \u2013 Tests Go basics + distributed systems thinking in 2-5 min  \n\u2705 **Reveals Depth** \u2013 Answer shows if they think beyond \"just retry\":\n- Exponential backoff vs fixed delays\n- Max retries / circuit breaker concepts\n- Idempotency awareness\n- Timeout configuration\n\n\u2705 **Appropriate Level** \u2013 Doesn't require advanced patterns, but rewards good thinking\n\n---\n\n## What You're Listening For\n\n**Strong signals:**\n- Mentions exponential backoff or jitter\n- Considers max retry limits\n- Thinks about idempotency (\"don't retry if it's not safe\")\n- References context deadlines in Go\n\n**Red flags:**\n- \"Just retry forever\"\n- No mention",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests Go implementation of retries for service clients, core to role; minor ding as gRPC unspecified but aligns perfectly (-1 no red flags). Clarity: Crystal clear, well-scoped for screening, single focused question with practical context. Discriminative: Excellent at separating via trade-offs (backoff, idempotency, limits), reveals depth without being trivial or overly broad.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-420",
        "role_title": "Backend Engineer - Graceful Shutdown",
        "question": "# Screening Question\n\n**You're deploying a Go backend service to Kubernetes that handles both gRPC and HTTP requests. During a rolling update, you need to ensure in-flight requests complete gracefully before the pod terminates. Walk me through how you'd implement graceful shutdown\u2014specifically, how you'd handle the signal, drain new connections, and wait for existing requests to finish. What are the key timing considerations with Kubernetes' termination lifecycle?**\n\n---\n\n## Why This Works\n\n\u2705 **Practical & Real**: Directly addresses the role's core responsibility  \n\u2705 **Right Scope**: Answerable in 3-4 minutes without being trivial  \n\u2705 **Tests Understanding**: Requires knowledge of:\n- Go signal handling (`context.Context`, `syscall.SIGTERM`)\n- Kubernetes termination flow (SIGTERM \u2192 grace period \u2192 SIGKILL)\n- Connection/request draining mechanics\n- Trade-offs (grace period timeout vs. request latency)\n\n\u2705 **Mid-Level Appropriate**: Expects practical implementation knowledge, not architectural perfection\n\n---\n\n## Strong Answer Signals\n\n- Mentions `signal.",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's core focus on graceful shutdown, signals, and in-flight requests in Go/K8s context (+no red flags). Clarity: Crystal clear, well-scoped for screening, specific components listed (minor deduction for lacking explicit time/format constraints). Discriminative: Tests applied knowledge, trade-offs, and integration of Go signals/K8s lifecycle, strongly separates candidates with practical depth.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-419",
        "role_title": "Backend Engineer - Retry Logic",
        "question": "# Screening Question\n\n**You're designing a retry mechanism for failed Kafka message processing in your Go service. Messages that fail processing should be retried with exponential backoff, but you also need to prevent retry storms that could overwhelm your system.**\n\n**Walk me through how you would implement exponential backoff with jitter, and explain how you'd implement a retry budget to prevent cascading failures. What would you consider when setting these parameters?**\n\n---\n\n## Why This Question Works\n\n**Tests practical distributed systems knowledge:**\n- Exponential backoff implementation (core skill)\n- Jitter concept (prevents thundering herd)\n- Retry budgets (prevents cascading failures)\n- Parameter tuning reasoning (judgment at mid-level)\n\n**Appropriate for mid-level:**\n- Not asking to code it end-to-end (that's senior)\n- Not trivia (they need to think through trade-offs)\n- Evaluates real architectural decisions they'd make\n\n**Reveals important signals:**\n- Do they understand *why* jitter matters?\n- Can they think about resource constraints?\n- Do they consider monitoring/observability?\n- Can they balance reliability",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's core focus on retry infrastructure, backoff, jitter, and budgets in Go/Kafka context (+no red flags). Clarity: Crystal clear and well-scoped for screening, minor deduction for unspecified constraints on parameters. Discriminative: Tests deep trade-offs, judgment, and applied knowledge (why jitter, tuning), strong separation without being too broad.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-414",
        "role_title": "Senior Backend Engineer - Long-Polling",
        "question": "# Technical Screening Question\n\n**Design a long-polling endpoint in Go that handles async job status updates. Walk me through:**\n\n1. **How you'd structure the HTTP handler** to accept a poll request and avoid blocking the entire server\n2. **Your timeout strategy** \u2014 how long should you wait before responding, and how do you prevent client/server resource exhaustion?\n3. **How you'd integrate Redis** to check for job completion without hammering PostgreSQL\n4. **One concrete edge case** you'd need to handle and your solution for it\n\n---\n\n## Why This Works\n\n\u2705 **Practical & Scenario-Based** \u2014 Tests real architectural decisions, not memorization\n\n\u2705 **Multi-Layered** \u2014 Assesses Go concurrency, caching patterns, system design thinking, and edge case awareness\n\n\u2705 **Senior-Level** \u2014 Expects thoughtful tradeoffs (timeout tuning, resource management) rather than just \"here's the code\"\n\n\u2705 **Appropriate Scope** \u2014 Answerable with a whiteboard/verbal explanation in 3-4 minutes, room for depth if they know their stuff\n\n\u2705 **Role-",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (long-polling APIs, connection mgmt, timeouts, fallbacks) with Go, Redis, PostgreSQL integration; minor ding as Go not explicitly in desc (-1). Clarity: Well-structured, numbered parts with precise scope, no bundling issues. Discriminative: Probes trade-offs, architecture, integration, and edge cases for strong candidate separation; appropriately scoped for screening.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-417",
        "role_title": "Junior Backend Developer - Event Sourcing",
        "question": "# Screening Question\n\n**\"Walk me through how you would design an event handler for a `UserRegistered` event in an event sourcing system. Specifically:**\n- **What information would the event contain?**\n- **What would the handler do with that event?**\n- **How would you ensure the same event isn't processed twice?\"**\n\n---\n\n## Why This Question Works\n\n**Tests practical understanding:**\n- Event structure and design (domain knowledge)\n- Handler responsibility (core pattern)\n- Idempotency (distributed systems challenge)\n\n**Appropriate for junior level:**\n- No trick answers or obscure knowledge required\n- Can be answered with a simple, concrete example\n- Shows if they've thought about real implementation details\n\n**Conversational flow:**\n- Allows follow-ups (Kafka partitions? Database constraints? Projection updates?)\n- Easy to gauge depth without being overwhelming\n- Natural discussion about event sourcing fundamentals\n\n---\n\n## What You're Listening For\n\n\u2705 **Good signals:** Event payload clarity, handler side effects, mention of idempotency keys or constraints  \n\u26a0\ufe0f **Watch for:** Confusion between events an",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 8,
          "reasoning": "Relevance: Directly tests core event sourcing skills (event handlers, structure) for the role, no red flags (-0). Clarity: Crystal clear, well-scoped bullet points, unambiguous for screening (-0). Discriminative: Tests applied knowledge and trade-offs like idempotency, distinguishes practical understanding from rote knowledge, junior-appropriate (-0).",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-421",
        "role_title": "Senior Backend Engineer - Security Automation",
        "question": "# Screening Question\n\n**Describe how you would design a secrets rotation mechanism for database credentials across a Kubernetes cluster using HashiCorp Vault. Walk me through your approach, including:**\n\n1. **How would you trigger rotation?** (timing, events, manual vs. automated)\n2. **How would you handle in-flight connections** during rotation to minimize disruption?\n3. **What would you implement to prevent a failed rotation from leaving the system in an inconsistent state?**\n\n---\n\n## Why This Question Works\n\n\u2713 **Practical & Real-World** \u2014 directly relevant to the role's core responsibility of secrets management\n\n\u2713 **Senior-Level** \u2014 expects architectural thinking and understanding of failure modes, not just \"how to use Vault\"\n\n\u2713 **Multi-Dimensional** \u2014 tests knowledge of orchestration, state management, and operational concerns simultaneously\n\n\u2713 **Time-Appropriate** \u2014 can be answered substantively in 2-5 minutes with follow-ups available\n\n\u2713 **Tech-Stack Aligned** \u2014 naturally incorporates Vault, Kubernetes, and automation concepts\n\n---\n\n## What You're Evaluating\n\n- Understanding of secrets",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's secrets rotation focus, Vault/K8s alignment, no red flags. Clarity: Crystal clear with specific subpoints, minor deduction for lacking explicit time/format constraints. Discriminative: Tests deep architectural trade-offs, failure handling, and ops concerns, strongly separates seniors from juniors.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-422",
        "role_title": "Junior Backend Engineer - API Testing",
        "question": "# Technical Screening Question\n\n**Write a simple pytest test for a FastAPI endpoint that creates a user. The endpoint accepts a POST request with `name` and `email` fields, returns the created user with an `id`, and should return a 400 status code if `email` is missing.**\n\n**Requirements:**\n- Write the test code (you can assume the FastAPI app is imported as `app`)\n- Include any necessary test setup/fixtures you'd use\n- Explain what your test is validating\n\n---\n\n## Why This Question Works\n\n\u2705 **Practical & Role-Relevant:** Tests core skills (pytest, FastAPI, API testing)  \n\u2705 **Time-Appropriate:** Solvable in 2-5 minutes  \n\u2705 **Junior-Level:** Doesn't require advanced mocking or complex patterns  \n\u2705 **Reveals Understanding:** Shows familiarity with:\n- Test structure and assertions\n- HTTP status codes\n- Request/response handling\n- Basic test organization\n\n**Follow-ups** (if needed):\n- \"How would you test the database was actually updated?\"\n- \"What if you needed to test 10",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 8,
          "reasoning": "Relevance: Directly tests pytest, FastAPI, and API testing - core to entry-level API test engineer role; no red flags. Clarity: Crystal clear with specific endpoint, requirements, and scoped for screening; assumes app import avoids ambiguity. Discriminative: Tests applied knowledge of test structure, fixtures, assertions, and HTTP handling to separate juniors with practical skills from weak ones; not pure recall but lacks trade-offs for 10.",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-423",
        "role_title": "Staff Engineer - Incident Response Platform",
        "question": "# Screening Question\n\n**Tell me about a time you designed or improved an on-call system or incident response process. Walk me through:**\n\n1. **What problem were you solving?** (alert fatigue, slow response times, unclear escalation, etc.)\n2. **What metrics or SLOs did you use to measure success?**\n3. **What was the hardest part to get right, and how did you handle the tradeoffs?**\n\n---\n\n## Why This Works\n\n\u2713 **Open-ended** \u2013 Reveals their actual incident response experience and maturity  \n\u2713 **Multi-layered** \u2013 Tests problem-solving, SLO thinking, and pragmatism  \n\u2713 **Staff-level signal** \u2013 Staff engineers own systems holistically; this reveals whether they think about metrics, tradeoffs, and operational reality  \n\u2713 **Conversational** \u2013 Natural follow-ups emerge (escalation logic, automation, tooling choices, team buy-in)  \n\u2713 **Tech-agnostic** \u2013 Their answer matters more than specific tools they've used  \n\n**What you're listening for:**\n- Did they measure the impact",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Directly targets core role responsibilities (incident response, on-call optimization, SLO tracking) with behavioral format testing holistic ownership. Crystal clear structure with specific prompts avoids ambiguity. Strong differentiation via tradeoffs, metrics, and real-world problem-solving; staff-level depth without being generic or recall-based. Minor ding for behavioral over pure technical design but aligns perfectly with role's operational focus.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-425",
        "role_title": "Senior Backend Engineer - Graph Analytics",
        "question": "# Technical Screening Question\n\n**You're building a recommendation engine that needs to find \"friends of friends\" connections across a social network with 500 million users and 10 billion edges in Neo4j. A naive Cypher query doing multi-hop traversals is timing out.**\n\n**Walk me through how you'd approach optimizing this:**\n1. What specific Neo4j performance issues would you investigate first?\n2. Would you consider moving this workload to Spark, and if so, when/why?\n3. How would you use caching (Redis) strategically here without creating stale data problems?\n\n---\n\n## Why This Question Works\n\n\u2713 **Practical & Real** - Directly mirrors the job's core challenge (billion-edge scale, recommendation systems)\n\n\u2713 **Multi-layered** - Tests understanding of Neo4j query optimization, Spark's role in the stack, and caching strategy trade-offs\n\n\u2713 **Senior-level** - Requires architectural thinking beyond syntax; expects them to weigh trade-offs, not just recite solutions\n\n\u2713 **Time-appropriate** - Can be answered in 3-4 minutes with a",
        "scores": {
          "relevance": 7,
          "clarity": 7,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core graph traversal/rec skills at scale and Neo4j (7-8 range), but penalize -2 for Spark/Redis not in role desc (-2). Clarity: Clear intent and structured, but multiple bundled questions (-2) and vague scoping. Discriminative: Excellent on trade-offs/caching strategies at senior level, strong separation.",
          "composite": 7.666666666666667
        }
      },
      {
        "role_id": "be-424",
        "role_title": "Backend Engineer - Message Serialization",
        "question": "# Technical Screening Question\n\n**You're designing a message serialization system where producer services publish events to Kafka. Your schema needs to evolve: you're adding a new required field `userId` to an existing event that previously only had `eventId` and `timestamp`.**\n\n**Walk me through:**\n1. **How would you handle this schema change to ensure consumers aren't broken?**\n2. **What's the difference between backward and forward compatibility here, and which one matters for your scenario?**\n3. **If you're using Avro with Schema Registry, what would you actually do to deploy this change safely?**\n\n---\n\n## Why This Question Works\n\n\u2713 **Tests practical understanding** - Not asking to define terms, but apply them to a real problem  \n\u2713 **Mid-level appropriate** - Assumes familiarity with Kafka/Avro, not mastery of edge cases  \n\u2713 **Reveals key competencies:**\n- Schema evolution strategy (backward vs forward compatibility)\n- Knowledge of schema registry patterns\n- Consideration of producer/consumer deployment order\n- Understanding of breaking vs non-breaking changes\n\n\u2713 **Conversational** -",
        "scores": {
          "relevance": 7,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Tests core schema evolution/compatibility skills for the role and mentions Kafka/Avro (inferred from role's serialization focus), but deduct -3 for being 3 bundled questions (-2) and somewhat generic serialization pattern (-1). Clarity: Clear scenario and intent, well-scoped, but multiple questions bundled (-2). Discriminative: Excellent at testing applied trade-offs, strategies, and tools to separate strong candidates.",
          "composite": 8.0
        }
      },
      {
        "role_id": "be-426",
        "role_title": "Junior Backend Engineer - DevOps Scripting",
        "question": "# Screening Question\n\n**You need to create a simple deployment script that:**\n1. Pulls the latest code from a GitHub repository\n2. Builds a Docker image\n3. Runs a basic health check on the container\n4. Reports success or failure\n\n**Write pseudocode or actual code (Python or Bash) showing how you'd structure this script. What error handling would you include, and why?**\n\n---\n\n## Why This Question Works\n\n\u2705 **Practical** \u2013 Tests real DevOps tasks they'll do daily  \n\u2705 **Appropriate Level** \u2013 Doesn't require advanced knowledge, but reveals fundamentals  \n\u2705 **Open-Ended** \u2013 Shows their thinking: error handling, logging, script structure  \n\u2705 **Time-Bound** \u2013 Can sketch this in 2-5 minutes  \n\u2705 **Reveals Gaps** \u2013 Junior candidates often forget error handling or health checks; strong juniors think about both\n\n## What You're Looking For\n\n- **Basic structure:** Sequential steps, clear logic\n- **Error handling:** Do they check if git pull/docker build succeeded?\n- **Health check thinking:** How do they",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's core skills (Git, Docker, scripting for deployments) with no red flags. Clarity: Crystal clear, well-scoped steps, minor deduction for not specifying language preference explicitly. Discriminative: Strong separation via error handling and reasoning, reveals junior gaps in fundamentals without being trivial or overly broad.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-427",
        "role_title": "Backend Engineer - Feature Store",
        "question": "# Technical Screening Question\n\n**Scenario-based question:**\n\n\"You're designing a feature store where you need to serve both batch features for model training and real-time features for inference. A data scientist requests a feature that takes 30 seconds to compute from your data warehouse, but it needs to be available in <100ms for online serving.\n\nWalk me through how you'd approach this problem using Feast. What are the trade-offs you'd consider, and what would you recommend?\"\n\n---\n\n## Why this works:\n\n\u2713 **Practical & real** - Core feature store problem  \n\u2713 **Mid-level appropriate** - Tests architectural thinking, not deep Feast internals  \n\u2713 **Open-ended** - Reveals how they think about latency, caching, and design decisions  \n\u2713 **Timeboxed** - Can explore thoroughly in 3-4 minutes  \n\n**What you're evaluating:**\n- Understanding of batch vs. real-time serving gap\n- Knowledge of Feast's materialization + online store strategy\n- Awareness of caching/pre-computation trade-offs\n- Problem-solving approach (pre-compute? cache",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Directly tests core feature store skills (batch/real-time serving, computation, versioning implied) matching role; Feast aligns perfectly as role focuses on feature store infra. Crystal clear scenario with specific constraints, well-scoped for screening. Strong separation via trade-offs/caching reasoning, Feast strategies distinguish mid-level expertise without trivia. Minor ding: assumes Feast familiarity but it's spot-on for role.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-428",
        "role_title": "Senior Backend Engineer - Payment Orchestration",
        "question": "# Technical Screening Question\n\n**Design a payment provider failover system for a payment orchestration platform. You have 3 payment providers (A, B, C) with different success rates (95%, 92%, 88%), costs, and latencies. A transaction fails with provider A. How would you:**\n\n1. **Decide which provider to failover to?** What factors beyond success rate would you consider?\n2. **Prevent cascading failures?** (e.g., avoid repeatedly routing to a temporarily degraded provider)\n3. **Track this decision** so you can optimize routing over time?\n\n*Assume you have access to: transaction metadata, provider health metrics, PostgreSQL, Redis, and Kafka.*\n\n---\n\n## Why This Question Works\n\n- **Practical & Real**: Directly mirrors the core responsibility (routing + failover)\n- **Senior-Level Depth**: Expects understanding of tradeoffs (cost vs. reliability), circuit breaker patterns, and observability\u2014not just \"use the best provider\"\n- **Tech Stack Integration**: Naturally leads to discussing Redis (circuit breaker state), Kafka (event logging), PostgreSQL (analytics), and Go (implementation",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's core focus on failover, routing, optimization, and tracking; integrates exact tech stack. Clarity: Well-scoped with specifics (3 providers, metrics, tech access), minor deduction for bundled sub-questions. Discriminative: Probes deep trade-offs, patterns (circuit breakers), and observability, strongly separates seniors from juniors.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-429",
        "role_title": "Backend Engineer - Log Aggregation",
        "question": "# Screening Question\n\n**You're designing a log aggregation pipeline that needs to handle 2M events/second. Logs arrive via Kafka, get parsed and enriched by Vector, then stored in ClickHouse.**\n\n**Walk me through how you'd handle a scenario where:**\n- **Parsing fails on 5% of incoming logs** (malformed JSON, unexpected fields)\n- **You need to retain raw logs for debugging but also ensure failed logs don't block the pipeline**\n\n**What would you implement, and why?**\n\n---\n\n## Why This Question Works\n\n**Tests practical depth:**\n- Understanding of real failure modes in log pipelines\n- Knowledge of Vector's error handling capabilities\n- ClickHouse schema design decisions (separate tables? columns?)\n- Go considerations if writing custom handling\n\n**Seniority-appropriate:**\n- Mid-level should know basic patterns but may not have all details polished\n- Room to discuss trade-offs (buffering, dead-letter queues, alerting)\n- Acceptable to say \"I'd research Vector's exact features, but here's my approach...\"\n\n**Observable reasoning:**\n- Listen for: asynchronous handling,",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core log pipeline skills (parsing, enrichment, failure handling, retention) with exact tech stack (Kafka, Vector, ClickHouse); no red flags (-0). Clarity: Crystal clear scenario, well-scoped with specific rates and goals; no bundling or vagueness (-0). Discriminative: Probes deep trade-offs (DLQs, buffering, async, alerting, schema design), distinguishes applied knowledge from rote recall; senior-appropriate depth without being too broad (-0).",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-430",
        "role_title": "Junior Backend Engineer - Search Indexing",
        "question": "# Technical Screening Question\n\n**\"Walk me through how you would index a list of 10,000 product records from a PostgreSQL database into Elasticsearch. What would you consider important, and what potential issues might you run into?\"**\n\n## Why This Question Works:\n\n**Tests practical knowledge:**\n- Understanding of data movement between systems\n- Awareness of bulk indexing (not indexing one-by-one)\n- Basic mapping/schema thinking\n\n**Appropriate for junior level:**\n- No requirement for advanced optimization\n- Open-ended enough to show thinking process\n- Candidates can discuss real concerns they'd encounter\n\n**Reveals important gaps:**\n- Do they know about batch/bulk APIs?\n- Are they aware of memory/performance constraints?\n- Do they think about data transformation?\n- Can they identify common failure modes (timeout, connection issues, invalid data)?\n\n**Follow-up prompts** (if needed):\n- \"How would you handle documents that fail to index?\"\n- \"What if the data keeps growing daily\u2014how would you keep the index updated?\"\n- \"Why wouldn't you just index records one at a time?\"\n\n---\n\n*Expected response time: 3",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core skills (bulk indexing from PostgreSQL to Elasticsearch, mapping) for entry-level search indexing role; minor ding as role emphasizes learning but question fits perfectly (-1 generic feel avoided). Clarity: Crystal clear, well-scoped open-ended walkthrough with practical focus, no ambiguity or missing constraints. Discriminative: Excellent at revealing practical understanding, trade-offs (batch vs single, issues like memory/failures), and thought process to separate juniors with real knowledge from weak ones.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-432",
        "role_title": "Backend Engineer - Data Validation",
        "question": "# Technical Screening Question\n\n**Scenario-based question:**\n\n\"You're building a data validation checkpoint in Great Expectations for a daily customer transaction pipeline in S3. The pipeline should catch:\n- Missing values in the `transaction_id` column\n- Transaction amounts that are statistical outliers (beyond 3 standard deviations)\n- Schema changes (new or dropped columns)\n\nWalk me through how you'd set this up. What Great Expectations components would you use, and how would you handle the case where a legitimate spike in transaction amounts (like a holiday sale) triggers false alerts?\"\n\n---\n\n## Why this question works:\n\n\u2705 **Practical** \u2013 Real scenario mid-level engineers face  \n\u2705 **Multi-layered** \u2013 Tests GE knowledge + data validation thinking + problem-solving  \n\u2705 **Seniority-appropriate** \u2013 Expects familiarity with GE but allows room to explore reasoning  \n\u2705 **Time-bound** \u2013 Can be thoroughly answered in 3-4 minutes  \n\u2705 **Reveals depth** \u2013 Follow-up on the \"false alerts\" part shows if they understand monitoring trade-offs",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core data validation (schema, stats, missing values) and lineage-adjacent pipeline quality using Great Expectations, perfectly matching role; no red flags. Clarity: Crystal clear scenario with specific requirements and well-scoped follow-up; no ambiguity or bundling. Discriminative: Tests applied GE knowledge, setup reasoning, and trade-offs (false positives), strongly separating candidates with practical depth.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-431",
        "role_title": "Staff Engineer - Real-time Collaboration",
        "question": "# Technical Screening Question\n\n**Design a real-time presence system for a collaborative editor where multiple users can see who else is currently viewing the document. How would you handle:**\n\n1. **User join/leave events** \u2014 What's your approach to detecting and broadcasting these events reliably?\n2. **Network failures** \u2014 How would you distinguish between a user who temporarily disconnected vs. one who left intentionally?\n3. **Scalability trade-offs** \u2014 Would you use Redis pub/sub, a presence channel pattern, or something else? Why?\n\n**Follow-up based on their answer:** If your solution uses heartbeats/timeouts, walk me through how you'd tune the timeout window and what happens if it's too aggressive or too lenient.\n\n---\n\n## Why This Question Works\n\n- **Seniority-appropriate**: Tests architectural thinking and trade-off reasoning, not implementation details\n- **Practical**: Real problem they'd solve day-one; not theoretical CRDT minutiae\n- **Reveals depth**: Their answer shows understanding of distributed systems, operational concerns, and when to use which tools\n- **Conversational**: Natural follow-ups exist; you can dig into their",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 10,
          "reasoning": "Directly tests core real-time collaboration skills (presence systems) from role description. Crystal clear with specific sub-questions and well-scoped for screening (-0 red flags). Excellent separation via trade-offs, distributed systems depth, and tunable parameters; follow-up probes deeper understanding. Minor deduct for slight bundling but structured well.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-433",
        "role_title": "Senior Backend Engineer - Platform APIs",
        "question": "# Technical Screening Question\n\n**Scenario-based question (2-5 minutes):**\n\n\"You're designing an internal platform API that allows teams to provision and manage database instances. Multiple services will call this API concurrently, and you need to ensure that:\n1. A database instance can only be provisioned once, even if multiple requests arrive simultaneously\n2. The provisioning process takes 30-60 seconds\n3. Callers need to know the status without polling repeatedly\n\nWalk me through how you'd design this in Go. What patterns or mechanisms would you use to handle the concurrency and reduce polling overhead?\"\n\n---\n\n## Why This Works:\n\n\u2713 **Practical** \u2013 Tests real platform API design decisions (idempotency, concurrency, async status tracking)\n\n\u2713 **Senior-level** \u2013 Expects knowledge of sync primitives, request deduplication, and pub/sub or streaming patterns\n\n\u2713 **Go-specific** \u2013 Opens discussion of mutexes, channels, context handling\n\n\u2713 **Platform-focused** \u2013 Directly relevant to service provisioning, a core platform concern\n\n\u2713 **Time-bound** \u2013 Candidates can sketch a",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core platform API skills (provisioning, concurrency) in Go, matching role's service catalog/resource provisioning focus; minor deduction as role doesn't explicitly list Go (-1). Clarity: Crystal clear scenario, specific requirements, well-scoped with time bound. Discriminative: Probes deep applied knowledge of Go sync primitives, idempotency, async patterns (e.g., channels, pub/sub), revealing senior-level trade-offs vs. basic recall.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-436",
        "role_title": "Backend Engineer - API Documentation",
        "question": "# Technical Screening Question\n\n## Question:\n\nYou're building an API documentation system that needs to auto-generate TypeScript SDK code from OpenAPI specs. Your team has discovered that some API endpoints have optional parameters with complex nested objects, and the generated SDK code is either too verbose or missing type safety for these optional fields.\n\n**How would you approach this problem? Walk me through:**\n1. How you'd modify the OpenAPI schema to properly represent optional nested structures\n2. What TypeScript patterns you'd use in the code generator to handle these cases\n3. One trade-off you'd have to consider between SDK usability and spec accuracy\n\n---\n\n## Why This Question Works:\n\n\u2713 **Practical:** Tests real problems encountered in API documentation tooling  \n\u2713 **Multi-faceted:** Requires knowledge of OpenAPI, TypeScript, and code generation  \n\u2713 **Mid-level appropriate:** Doesn't expect perfect answers, but reveals depth of experience  \n\u2713 **Time-bound:** Answerable conversationally in 3-4 minutes  \n\u2713 **Discussion-friendly:** Opens dialogue about trade-offs and decision-making  \n\n**Follow-up prom",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Directly targets core role skills (OpenAPI specs, SDK automation, TypeScript) with practical nested object issue in API tooling. Crystal clear structure with numbered parts and scoped constraints. Strong separation via trade-off analysis revealing deep understanding; minor deduct for bundled sub-questions but well-scoped overall.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-434",
        "role_title": "Principal Engineer - Database Strategy",
        "question": "# Screening Question\n\n**You're advising a company that currently runs a monolithic PostgreSQL database serving a single region. They're expanding to 3 new geographic regions and need <100ms latency for all users. Walk me through how you'd approach this problem\u2014what are the key trade-offs you'd evaluate, and what factors would drive your technology recommendation between solutions like read replicas, CockroachDB, or a sharded approach?**\n\n---\n\n## Why This Works\n\n**Tests Principal-Level Skills:**\n- Strategic thinking (trade-offs, not just \"what tool is best\")\n- Distributed systems depth (consistency models, latency, operational complexity)\n- Business acumen (understanding constraints drive decisions)\n- Mentorship capability (clear communication of complex reasoning)\n\n**Practical & Focused:**\n- Reflects a real architectural challenge\n- Answerable in 2-5 minutes without deep dives\n- Reveals how they'd actually guide a team through decisions\n\n**Distinguishes Principals:**\n- Junior engineers list features; principals discuss trade-offs\n- Expected to mention: RPO/RTO, consistency requirements, cost, team capability, migration risk",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 10,
          "reasoning": "Relevance: Directly tests core role skills in multi-region DB strategy, migration, tech selection with PostgreSQL context; no red flags. Clarity: Crystal clear, well-scoped with specific constraints (regions, latency); minor -1 for no explicit time/format. Discriminative: Excellent at separating principals via trade-offs, applied knowledge, and reasoning depth vs rote recall.",
          "composite": 9.666666666666666
        }
      },
      {
        "role_id": "be-435",
        "role_title": "Junior Backend Engineer - Queue Consumers",
        "question": "# Screening Question\n\n**You're building a RabbitMQ consumer that processes payment transactions from a queue. The consumer receives a message, updates a PostgreSQL database, and then acknowledges the message. However, you notice that sometimes the same payment gets processed twice.**\n\n**Walk me through:**\n1. **What could cause duplicate processing?**\n2. **How would you fix it?**\n3. **What's the difference between auto-acknowledge and manual acknowledge, and which would you use here?**\n\n---\n\n## Why This Question Works\n\n\u2705 **Practical & Real-world** \u2014 Duplicate processing is a common junior engineer problem  \n\u2705 **Right Difficulty** \u2014 Tests understanding of message queue fundamentals without requiring deep distributed systems knowledge  \n\u2705 **Covers Key Concepts** \u2014 Acknowledgment patterns, idempotency, and failure scenarios (all listed in the role description)  \n\u2705 **Open-ended** \u2014 Reveals how they think through problems, not just memorized answers  \n\u2705 **Time-appropriate** \u2014 Can be thoroughly answered in 3-4 minutes\n\n---\n\n## What You're Looking For\n\n**Strong Answer",
        "scores": {
          "relevance": 7,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Tests core acknowledgment patterns and idempotency from role, but RabbitMQ/PostgreSQL are specific unlisted techs (-2); not generic (-3 avoided). Clarity: Crystal clear, well-scoped numbered parts, no bundling issues. Discriminative: Excellent separation via causes/fixes/trade-offs, reveals applied thinking beyond recall.",
          "composite": 8.333333333333334
        }
      },
      {
        "role_id": "be-437",
        "role_title": "Senior Backend Engineer - Secrets Management",
        "question": "# Screening Question\n\n**You're designing a secrets rotation system for database credentials across 50+ microservices in Kubernetes. Walk me through how you'd architect this using Vault, and specifically explain how you'd handle the scenario where a service fails to pick up a rotated credential before the old one expires.**\n\n---\n\n## Rationale\n\nThis question is effective because it:\n\n1. **Tests practical architecture thinking** - Requires understanding of real-world secrets management complexity, not memorized facts\n\n2. **Appropriate for senior level** - Expects thoughtful design decisions around failure modes, not just \"how to use Vault\"\n\n3. **Covers multiple key skills**:\n   - Vault knowledge (rotation policies, lease management)\n   - Kubernetes operational awareness (deployment, service communication)\n   - Go context (they'd likely implement the consumer application)\n   - Security thinking (credential expiry, availability vs security tradeoffs)\n\n4. **Reveals problem-solving approach** - How they handle edge cases shows maturity:\n   - Do they think about grace periods?\n   - Do they consider monitoring/alerting?\n   - Do they discuss rollback strategies?",
        "scores": {
          "relevance": 7,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Tests core secrets rotation but Vault not explicitly listed in role (subtract 2); covers rotation/expiry well. Clarity: Well-scoped architecture question with specific failure scenario, minor missing constraints like time limit (-1). Discriminative: Excellent at testing trade-offs, failure handling, and practical depth for senior roles.",
          "composite": 8.0
        }
      },
      {
        "role_id": "be-439",
        "role_title": "Backend Engineer - Billing Integration",
        "question": "# Screening Question\n\n**\"Walk me through how you would handle a scenario where a customer upgrades their subscription mid-billing cycle and needs to be prorated. What information would you need from Stripe, and how would you structure the logic to calculate and apply the credit?\"**\n\n---\n\n## Why This Question Works:\n\n**Practical & Role-Specific**\n- Directly tests core responsibility (proration, invoicing)\n- Real problem they'll solve day-one\n\n**Right Difficulty Level**\n- Mid-level should understand subscription concepts\n- Allows room to discuss Stripe APIs, calculation logic, and edge cases\n- Not trivial (requires billing domain knowledge) but not PhD-level\n\n**Reveals Key Competencies**\n- Stripe API familiarity (proration_behavior, line items)\n- Billing math (daily rates, cycle dates)\n- System design thinking (data flow, state management)\n- Communication skills (explaining trade-offs)\n\n**Answerable in 2-5 Minutes**\n- Can sketch approach quickly without deep implementation details\n- Follow-ups available: \"What about failed payments?\" or \"How would you test this?\"",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's core focus on proration/subscriptions/Stripe, no red flags. Clarity: Crystal clear scenario with specific ask, minor vagueness on exact Stripe API version but well-scoped. Discriminative: Tests applied knowledge of billing logic, Stripe integration, trade-offs/edge cases, strong separation without being too broad or recall-based.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-438",
        "role_title": "Staff Engineer - ML Serving Infrastructure",
        "question": "# Technical Screening Question\n\n**\"Walk me through how you'd design a batching strategy for an ML serving system handling requests with variable latency requirements. Specifically, consider a scenario where you have both latency-sensitive requests (sub-100ms SLA) and batch-optimized requests (up to 1s acceptable). How would you structure this in Triton, and what metrics would you track to validate it's working?\"**\n\n---\n\n## Why This Question Works:\n\n**Tests practical expertise:**\n- Understanding of dynamic batching trade-offs\n- Actual Triton configuration knowledge\n- Ability to handle competing constraints (latency vs throughput)\n\n**Appropriate for staff level:**\n- Requires architectural thinking, not just implementation\n- Evaluates observability mindset (metrics/monitoring)\n- Shows how they'd make real production trade-offs\n\n**Realistic scenario:**\n- This is a common real-world problem at scale\n- Reveals how they think about SLAs and system design\n\n**Answerable in timeframe:**\n- Senior candidates can sketch the solution quickly\n- Follow-ups naturally extend discussion if needed (Kubernetes scheduling, TensorRT optimizations,",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 10,
          "reasoning": "Directly tests core role skills (batching strategies, latency optimization for ML serving) with Triton (common in ML infra). Crystal clear scenario with specific SLAs, scopes to Triton structure and metrics. Strongly differentiates via trade-offs, architectural thinking, and observability\u2014no red flags.",
          "composite": 9.666666666666666
        }
      },
      {
        "role_id": "be-440",
        "role_title": "Junior Backend Engineer - Metrics Collection",
        "question": "# Screening Question\n\n**You're instrumenting a Go service that processes user requests. You need to track how long each request takes. Should you use a Prometheus Counter, Gauge, or Histogram for this metric? Explain why, and describe what data would be available in Prometheus/Grafana afterward.**\n\n---\n\n## Why This Works\n\n\u2705 **Appropriate for Junior Level:** Tests understanding of metric types without requiring deep expertise\n\n\u2705 **Practical:** Directly mirrors Day 1 tasks\u2014instrumenting a real service\n\n\u2705 **Observable Reasoning:** Answer reveals if they understand *why* metrics matter, not just syntax\n\n\u2705 **Time-Bound:** 2-3 minutes for a solid response\n\n---\n\n## What You're Looking For\n\n**Strong Answer** includes:\n- Histogram (correct choice)\n- Explains why: need distribution/percentiles, not just a single value\n- Mentions what becomes available: latency buckets, quantiles (p99, p95), average\n- Maybe: \"Could query request latency spikes in Grafana\"\n\n**Acceptable Answer:**\n- Histogram identified + basic explanation of buckets",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's core focus on counter/gauge/histogram patterns for service instrumentation. Clarity: Crystal clear with specific scenario, single focused question, no ambiguity. Discriminative: Requires understanding trade-offs between metric types and explains queryable data (buckets/quantiles), distinguishing conceptual grasp from rote recall; ideal for entry-level.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-442",
        "role_title": "Backend Engineer - Event Streaming",
        "question": "# Screening Question\n\n**You're designing a real-time notification system where one event needs to be delivered to potentially thousands of subscribers. A naive approach fans out the event to every subscriber's queue, but this causes memory issues and slow writes at scale.**\n\n**Walk me through how you'd optimize this using NATS. What patterns or features would you leverage, and why?**\n\n---\n\n## Why This Question Works\n\n**Practical & Role-Specific:**\n- Directly addresses the \"fan-out\" requirement in the job description\n- Tests real understanding of NATS capabilities (subjects, subscriptions, subject hierarchies)\n\n**Mid-Level Appropriate:**\n- Not a gotcha question; assesses experience with actual architectural decisions\n- Expects knowledge of trade-offs, not perfection\n\n**Reveals Key Insights:**\n- Do they know NATS subjects/wildcards reduce fanout complexity?\n- Can they articulate the difference between queue groups vs. broadcast subscriptions?\n- Do they think about memory/performance implications?\n- Can they discuss subject-based filtering as a solution?\n\n**Answerable in 2-5 Minutes:**\n- Candidate can sketch the approach",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests fan-out core to role; assumes NATS in stack (no red flags). Clarity: Well-scoped, unambiguous with context. Discriminative: Probes trade-offs (queue groups vs broadcast, subjects/wildcards), separates experienced users from superficial knowledge in 2-5 min.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-441",
        "role_title": "Senior Backend Engineer - Autocomplete Systems",
        "question": "# Technical Screening Question\n\n## Autocomplete Latency Under Load\n\n**Scenario:**\nYou're building an autocomplete service that needs to handle 100K QPS with sub-50ms latency. Your current implementation queries Elasticsearch for prefix matches, applies personalization filters based on user history (cached in Redis), and ranks results.\n\nUnder load testing, you're seeing:\n- Elasticsearch queries: ~15ms (p99)\n- Redis lookups: ~2ms (p99)\n- Personalization logic: ~8ms (p99)\n- **Total latency: ~80ms (p99) \u2014 exceeding your 50ms SLA**\n\n**Questions:**\n1. Walk me through how you'd diagnose where the latency is actually being lost\n2. What optimizations would you prioritize, and why?\n3. What tradeoffs would you consider?\n\n---\n\n## Why This Works\n\n\u2705 **Tests senior-level thinking:** Requires understanding of systems bottlenecks, not just API knowledge  \n\u2705 **Practical:** Reflects real performance challenges in high-scale autocomplete  \n\u2705 **Open-ended:**",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 10,
          "reasoning": "Relevance: Directly tests core autocomplete optimization, prefix matching, personalization, and exact latency/QPS from role (-1 for no explicit role tech stack mention). Clarity: Crystal clear scenario with precise metrics and focused 3-part structure. Discriminative: Excellent probe of diagnosis, prioritization, and tradeoffs, strongly separates seniors who grasp bottlenecks from juniors.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-443",
        "role_title": "Senior Backend Engineer - Data Lake Architecture",
        "question": "# Screening Question\n\n**You're designing a data lake where business users need to query historical snapshots of customer data from 30 days ago, but the underlying schema has evolved significantly (columns added, renamed, and removed). How would you use Apache Iceberg's features to support this requirement, and what are the tradeoffs you'd consider?**\n\n---\n\n## Why This Question Works\n\n**Tests practical expertise:**\n- Time travel queries (core Iceberg feature)\n- Schema evolution handling (critical for production data lakes)\n- Understanding of snapshots and metadata layers\n\n**Appropriate for senior level:**\n- Requires experience designing systems, not just using APIs\n- Allows discussion of tradeoffs and architectural decisions\n- Open-ended enough to reveal depth of understanding\n\n**Realistic scenario:**\n- Common real-world requirement in mature data lakes\n- Shows how they think about user experience + infrastructure\n\n**Natural follow-ups** (if needed):\n- \"How would your answer change if users queried data from 2 years ago?\"\n- \"What monitoring would you put in place?\"\n- \"How does this interact with your partitioning strategy?\"",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 10,
          "reasoning": "Relevance: Directly tests core role skills (Iceberg table formats, schema evolution, time travel) with no red flags. Clarity: Crystal clear scenario and scope, minor deduction for no explicit time/format constraints but well-formed for screening. Discriminative: Excellent at revealing deep applied knowledge, tradeoffs, and architectural thinking to separate seniors from juniors.",
          "composite": 9.666666666666666
        }
      },
      {
        "role_id": "be-444",
        "role_title": "Backend Engineer - Service Templates",
        "question": "# Technical Screening Question\n\n**You're designing a Cookiecutter template for new Go microservices. A developer will run it once, and the generated service should be immediately deployable to Kubernetes with ArgoCD, including basic observability and security practices.**\n\n**Walk me through:**\n1. **What files/structure would you include** in the template to support this?\n2. **How would you handle variation** \u2014 for example, some services need databases, others don't?\n3. **What's one thing you'd bake into defaults** (vs. leaving for the developer to configure), and why?\n\n---\n\n## Why This Question Works\n\n\u2705 **Practical** \u2014 Tests real templating decisions, not memorization  \n\u2705 **Scope** \u2014 Covers the full stack (scaffolding, CI/CD, K8s, observability)  \n\u2705 **Mid-level appropriate** \u2014 Expects system thinking, not expert-level optimization  \n\u2705 **Reveals priorities** \u2014 Shows what the candidate considers \"essential\" vs. \"nice-to-have\"  \n\u2705 **Conversational** \u2014 Natural follow-ups on trade",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (templating, CI/CD, observability, security, K8s/ArgoCD) with no red flags (-0). Clarity: Well-scoped with 3 focused parts, unambiguous for screening despite multi-part (-0). Discriminative: Tests applied decisions, trade-offs, and priorities, strongly separating candidates via reasoning.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-445",
        "role_title": "Junior Backend Engineer - Database Migrations",
        "question": "# Screening Question\n\n**You need to add a new required column to an existing production table with millions of rows. Write out the steps you would take to do this safely using Alembic, and explain why you can't simply use `Column('new_col', String, nullable=False)` in your migration.**\n\n---\n\n## Why This Works\n\n\u2705 **Practical & Real** \u2014 This is a genuine problem junior engineers face on their first day\n\n\u2705 **Right Level** \u2014 Tests understanding of:\n- Alembic basics (writing migrations)\n- PostgreSQL constraints\n- Production safety thinking (zero-downtime concerns)\n- Schema versioning logic\n\n\u2705 **Time-Appropriate** \u2014 Takes 2-4 minutes for a competent junior to explain\n\n\u2705 **Open-Ended** \u2014 Reveals:\n- Whether they know `nullable=False` + no default = backfill problem\n- If they understand multi-step migration patterns\n- Whether they think about existing data\n- Communication clarity on database concepts\n\n---\n\n## What You're Looking For\n\n**Good Answer Includes:**\n- \"Add the column as nullable first\"\n- \"",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's core focus on database migrations, zero-downtime patterns, and Alembic (no red flags). Clarity: Crystal clear with specific scenario and explanation prompt; minor deduction for lacking explicit time/format constraints. Discriminative: Strongly separates candidates by testing applied knowledge of multi-step migration patterns, production safety, and trade-offs (not recall); open-ended but scoped well.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-446",
        "role_title": "Staff Engineer - Distributed Tracing",
        "question": "# Technical Screening Question\n\n**Design a sampling strategy for a distributed tracing system handling 100k requests/second across multiple services. Walk me through how you'd decide between head-based and tail-based sampling, what trade-offs you'd consider, and how you'd handle the challenge of maintaining trace coherence when different spans are sampled at different rates.**\n\n---\n\n## Why This Question Works\n\n**Tests Staff-Level Thinking:**\n- Requires understanding of architectural trade-offs (not just \"what is sampling\")\n- Demonstrates systems thinking across infrastructure components\n- Shows ability to balance operational constraints with observability goals\n\n**Practical & Real:**\n- This is an actual problem at scale (100k RPS is genuine staff-level territory)\n- Candidates will naturally discuss real concerns: cost, trace completeness, debugging capability\n\n**Open-Ended:**\n- Allows candidates to showcase depth (mentioning Jaeger sampling plugins, ClickHouse retention strategies, Kafka buffering, SLO correlation)\n- No single \"correct\" answer\u2014reveals how they think through complexity\n\n**Natural Follow-ups:**\n- \"How would you implement priority-based sampling for errors?\"\n-",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 10,
          "reasoning": "Relevance: Directly targets core role responsibilities (distributed tracing at scale, sampling strategies) with realistic 100k RPS; no red flags. Clarity: Crystal clear, well-scoped for screening, precise trade-offs specified; minor deduction for lacking explicit time constraint. Discriminative: Excellent test of deep trade-offs, systems thinking, and applied knowledge at staff level, strong separation of strong vs weak candidates; open-ended but focused.",
          "composite": 9.666666666666666
        }
      },
      {
        "role_id": "be-447",
        "role_title": "Backend Engineer - Load Shedding",
        "question": "# Screening Question\n\n**\"Walk me through how you would implement a load shedding mechanism that drops low-priority requests when your service is under high load. What signals would you monitor to decide when to start shedding, and how would you prevent cascading failures downstream?\"**\n\n---\n\n## Why This Question Works\n\n**Tests core competencies:**\n- Load shedding patterns and decision logic\n- Backpressure signal understanding (queue depth, latency, CPU)\n- Graceful degradation thinking\n- Awareness of downstream impact\n\n**Seniority-appropriate:**\n- Mid-level should have opinions on *when* to shed and *what* metrics matter\n- Not asking for production-ready code, just architectural thinking\n- Room to discuss trade-offs (false positives vs. user experience)\n\n**Practical depth:**\n- Reveals whether they've actually dealt with throttling vs. just read about it\n- Follow-ups are natural: \"How would Redis fit in?\" or \"How do you test this?\"\n- Can assess if they think about observability (Prometheus integration)\n\n**Time-efficient:**\n- Candidate can outline approach in 2-3",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's core focus on load shedding, priority queues, throttling, and backpressure\u2014no red flags, directly tests listed skills. Clarity: Crystal clear and well-scoped for screening, minor deduction only for lacking explicit time constraint. Discriminative: Tests applied architectural thinking, trade-offs, and real-world signals, strongly separates experienced candidates; time-efficient as noted.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-448",
        "role_title": "Senior Backend Engineer - Webhook Infrastructure",
        "question": "# Screening Question\n\n**Design a webhook retry mechanism that handles delivery failures while preventing duplicate deliveries to the customer. What would be your approach to storing state, and how would you handle the edge case where a webhook succeeds but the success acknowledgment is lost?**\n\n---\n\n## Why This Question Works\n\n**Practical Knowledge:** Tests understanding of the core challenge in webhook infrastructure\u2014idempotency and reliability under failure conditions.\n\n**Seniority Appropriate:** Expects the candidate to think about:\n- Idempotency keys and deduplication strategies\n- State management (database, cache, or both)\n- Distributed system failure modes\n- Trade-offs between consistency and operational complexity\n\n**Real-World Relevance:** This exact problem appears in production webhook systems and requires senior-level systems thinking.\n\n**Conversational:** Opens into natural follow-ups:\n- \"How would Kafka fit into this design?\"\n- \"What happens under high volume?\"\n- \"How do you monitor delivery success?\"\n\n**Time Appropriate:** Can be outlined in 2-3 minutes, with depth added based on candidate confidence.",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 10,
          "reasoning": "Directly targets core webhook delivery challenges (retry, idempotency, state, failure modes) from role description. Crystal clear with specific edge case; minor deduct for lacking explicit constraints like scale. Excellent at distinguishing senior systems thinkers via trade-offs and deep understanding.",
          "composite": 9.666666666666666
        }
      },
      {
        "role_id": "be-449",
        "role_title": "Junior Backend Engineer - Auth Integration",
        "question": "# Technical Screening Question\n\n**\"Walk me through how you would implement a refresh token flow in a Node.js application. Specifically, explain:**\n\n1. **Where** you'd store the refresh token (client-side vs server-side) and why\n2. **When** you'd use it (what triggers a refresh?)\n3. **One security concern** you'd need to handle\n\nYou don't need to write code\u2014just explain your approach.\"\n\n---\n\n## Rationale\n\n\u2705 **Tests practical OAuth2 understanding** - Refresh tokens are core to the role  \n\u2705 **Right difficulty level** - Junior engineers should know the basics but may not have all details polished  \n\u2705 **Security-focused** - Demonstrates awareness of auth risks (token rotation, storage, expiration)  \n\u2705 **2-5 minute response** - Conceptual explanation, not a coding exercise  \n\u2705 **Reveals real experience** - Distinguishes between memorized facts and applied knowledge\n\n**Red flags:** Confusion between access/refresh tokens, storing refresh tokens insecurely client-side, or inability to name any security concern.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 8,
          "reasoning": "Relevance: Directly tests core OAuth refresh token flow central to role's token handling focus, matches Node.js context, minor deduction for not being social login specific (-1). Clarity: Well-structured with numbered points, clear scope (no code), unambiguous. Discriminative: Tests applied reasoning on storage/ triggers/security trade-offs, separates practical knowledge from trivia, good for entry-level but not elite depth.",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-450",
        "role_title": "Principal Engineer - ML Platform Strategy",
        "question": "# Screening Question\n\n**Describe a situation where you had to choose between multiple ML orchestration or workflow tools for your organization. Walk me through your decision framework\u2014what factors did you weigh, and how did you handle stakeholder concerns about the choice?**\n\n---\n\n## Why This Works\n\n**Tests Principal-Level Thinking:**\n- Requires systems thinking (not just technical merits)\n- Evaluates decision-making under trade-offs\n- Assesses ability to balance technical, organizational, and governance concerns\n\n**Practical & Concrete:**\n- Grounded in real experience (Kubernetes, Kubeflow, MLflow, Ray context)\n- Answerable in 2-5 minutes with specific example\n- Naturally surfaces their approach to architecture and strategy\n\n**Reveals Key Competencies:**\n- **Platform strategy:** How they evaluate tools holistically\n- **Governance:** Maintainability, compliance, cost considerations\n- **Mentorship/Communication:** How they aligned teams around the decision\n- **Technical depth:** Understanding of tool trade-offs (e.g., Kubeflow vs Ray vs MLflow for different workloads)\n\n**Follow-ups",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core ML platform strategy, tooling selection, governance, and stakeholder alignment from role; minor ding for assuming specific experience (-1). Clarity: Crystal clear behavioral question with precise scope for screening. Discriminative: Probes deep trade-offs, frameworks, and real-world application, strongly separating principal-level thinkers from juniors.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-451",
        "role_title": "Backend Engineer - Subscription Billing",
        "question": "# Screening Question\n\n**Walk me through how you'd handle a customer downgrading from a $100/month annual plan to a $50/month annual plan mid-cycle. What are the key considerations, and how would you implement the credit/refund logic?**\n\n---\n\n## Why This Question Works\n\n**Tests practical expertise:**\n- Proration calculations (core to the role)\n- Subscription state management\n- Financial correctness and edge cases\n\n**Appropriate for mid-level:**\n- Assumes familiarity with billing concepts\n- Doesn't require memorized formulas\n- Evaluates problem-solving approach, not just implementation details\n\n**Real-world relevance:**\n- Directly reflects daily work in subscription billing\n- Reveals how they think about atomicity, refunds, and audit trails\n\n---\n\n## What You're Looking For\n\n**Strong answers typically include:**\n- How they calculate prorated amounts (days remaining, daily rate)\n- Where the credit goes (instant refund vs. account balance vs. future invoice)\n- Data consistency concerns (state transitions, idempotency)\n- How they'd validate the calculation and prevent double-refunds\n-",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Directly tests core role skills in proration, plan changes, and billing logic from the role description (no red flags). Crystal clear scenario with strong real-world scope, minor deduction for lacking explicit constraints like time or format. Excellent separation of strong candidates via trade-offs, edge cases, and implementation reasoning (not recall or trivial).",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-453",
        "role_title": "Backend Engineer - Notification Delivery",
        "question": "# Screening Question\n\n**You're designing a notification delivery system where thousands of devices need to receive a push notification within seconds. Walk me through how you'd handle the following scenario:**\n\n*A user sends a notification targeting 50,000 devices. Some devices have both FCM (Android) and APNS (iOS) tokens registered. You need to:*\n1. *Retrieve all device tokens efficiently*\n2. *Batch them appropriately for FCM and APNS APIs*\n3. *Handle partial failures (some batches fail, some succeed)*\n\n**What would your approach be, and what would you consider regarding database queries, batching strategy, and failure handling?**\n\n---\n\n## Why This Question Works\n\n\u2705 **Practical & Real** \u2013 Directly mirrors the actual job responsibility  \n\u2705 **Mid-Level Appropriate** \u2013 Tests architectural thinking without requiring deep expertise  \n\u2705 **Multi-Faceted** \u2013 Covers database efficiency, API integration, and resilience  \n\u2705 **Time-Boxed** \u2013 Can be answered thoroughly in 3-4 minutes  \n\u2705 **Open-Ended** \u2013 Reveals their",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's core needs (device registration, batching, delivery tracking) with FCM/APNS directly relevant; no red flags. Clarity: Crystal clear, well-scoped scenario with specific numbered asks, minor deduction for no explicit time/format constraints. Discriminative: Excellent at separating candidates via trade-offs in queries/batching/failures, reveals architectural depth without being too broad or recall-based.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-452",
        "role_title": "Senior Backend Engineer - Faceted Search",
        "question": "# Screening Question\n\n**You're implementing faceted search for an e-commerce platform with millions of products. Users filter by category, price range, brand, and ratings simultaneously. Your aggregation queries are returning accurate facet counts, but query latency has increased from 200ms to 2+ seconds as the product catalog grew.**\n\n**Walk me through how you would diagnose and optimize this. What are the key bottlenecks you'd investigate in Elasticsearch, and what specific techniques would you apply?**\n\n---\n\n## Why This Works\n\n\u2705 **Practical & Real** - Reflects actual performance challenges at scale  \n\u2705 **Multi-layered** - Tests diagnosis, Elasticsearch knowledge, and optimization strategy  \n\u2705 **Senior-appropriate** - Expects understanding of aggregations, query planning, and tradeoffs  \n\u2705 **2-5 min range** - Answerable without deep implementation details  \n\u2705 **Open-ended** - Reveals depth of experience and problem-solving approach\n\n## What You're Evaluating\n\n- Understanding of Elasticsearch aggregation performance (shard-level work, query overhead)\n- Knowledge of practical optimizations (",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's core focus on optimizing aggregation queries and facet count accuracy at scale in faceted search; no red flags. Clarity: Crystal clear scenario with specific symptoms, well-scoped for screening; minor deduction for lacking explicit time/format constraints. Discriminative: Strongly separates seniors via diagnosis, trade-offs (e.g., shard overhead, sampling), and ES-specific techniques; open-ended but focused.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-454",
        "role_title": "Junior Backend Engineer - ETL Scripts",
        "question": "# Screening Question\n\n**You have a CSV file with 500,000 customer records. One column contains dates in mixed formats (some are \"2024-01-15\", others are \"01/15/2024\"). You need to load this into PostgreSQL, but the database expects a standard datetime format. Walk me through how you'd handle this using pandas, and what you'd do if some rows have invalid dates.**\n\n---\n\n## Why This Question Works:\n\n\u2705 **Practical & Real** - Common ETL problem junior engineers actually face\n\n\u2705 **Right Difficulty** - Tests pandas basics + problem-solving, not memorization\n\n\u2705 **Multi-faceted** - Covers:\n- Data loading (read_csv)\n- Data cleaning/transformation (pd.to_datetime)\n- Error handling (invalid dates)\n- Database awareness (schema requirements)\n\n\u2705 **Time-appropriate** - Can explain solution in 2-5 minutes\n\n---\n\n## What You're Looking For:\n\n**Strong answer includes:**\n- `pd.read_csv()` to load the file\n- `pd.to_datetime()` with `infer_datetime",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core ETL skills (data transformation, error handling) with pandas for entry-level role; minor ding for assuming pandas without explicit mention (-1). Clarity: Crystal clear scenario, specific tech, well-scoped walkthrough with no ambiguity. Discriminative: Requires applied knowledge of pandas functions, error handling trade-offs (e.g., infer_datetime, errors='coerce'), distinguishes problem-solvers from rote learners.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-455",
        "role_title": "Staff Engineer - Developer Portal",
        "question": "# Technical Screening Question\n\n**You're designing the plugin architecture for a developer portal where different teams will contribute integrations (e.g., deployment tools, monitoring systems, secret management). Walk me through how you'd structure this to ensure:**\n\n1. **Plugin isolation** \u2014 a broken plugin doesn't crash the portal\n2. **Shared concerns** \u2014 plugins can access common APIs (auth, service catalog, notifications) without duplicating code\n3. **Team autonomy** \u2014 teams can develop and deploy plugins independently without coordinating with a central platform team\n\n**What are the key architectural decisions you'd make, and what trade-offs would you accept?**\n\n---\n\n## Why This Works\n\n**For Staff Level:** Tests architectural thinking and systems design, not implementation details. Expects them to reason about trade-offs and constraints.\n\n**Practical:** Directly relevant to Backstage plugin patterns and real portal challenges. Draws on their experience scaling developer tools.\n\n**2-5 Minute Response:** Can outline approach without deep code, but reveals:\n- Understanding of module/plugin boundaries\n- How they think about dependency injection and composition\n- Knowledge of deployment/versioning strategies\n- Awareness of operational concerns (",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core role responsibility (plugin architecture for developer portal), matches Backstage-like patterns; minor generic deduction avoided as it's role-specific (-0). Clarity: Well-scoped with 3 precise requirements, clear expectations for decisions/trade-offs, screening-appropriate depth. Discriminative: Probes deep architectural reasoning, trade-offs, and applied knowledge (isolation, shared deps, autonomy), strongly separates staff-level thinkers from juniors; fits 2-5 min response.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-456",
        "role_title": "Backend Engineer - Query Optimization",
        "question": "# Screening Question\n\n**You're analyzing a slow query on a PostgreSQL table with 10M rows. The query filters by `user_id` and `created_at`, but takes 8 seconds. When you run `EXPLAIN ANALYZE`, you see a Sequential Scan instead of an Index Scan, even though an index exists on `(user_id, created_at).**\n\n**Walk me through:**\n1. **Why the planner might choose Sequential Scan over the index**\n2. **How you'd investigate and fix this**\n3. **What tools or commands you'd use to confirm your fix works**\n\n---\n\n## Why This Works\n\n\u2705 **Practical & Real** - Mirrors actual performance debugging  \n\u2705 **Mid-Level Appropriate** - Requires index knowledge + planner understanding, not deep internals  \n\u2705 **Multi-faceted** - Tests diagnostics (EXPLAIN), root cause analysis, and solution validation  \n\u2705 **Time-Bound** - Can be answered thoroughly in 3-4 minutes  \n\u2705 **Follow-ups Ready** - Natural paths to dig deeper (statistics, query re",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's core focus on slow query detection, index recommendations, and plan analysis in PostgreSQL (10/10, no red flags). Clarity: Crystal clear, well-scoped multi-part structure with real scenario; minor deduction for lacking explicit time/format constraints (-1). Discriminative: Excellent at separating candidates via trade-offs (planner decisions, stats, fixes), applied knowledge beyond recall (9/10).",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-458",
        "role_title": "Backend Engineer - API Gateway Plugins",
        "question": "# Technical Screening Question\n\n**Scenario:**\n\nYou're building a Kong plugin that needs to:\n1. Extract a user ID from the request header\n2. Check if that user is rate-limited using Redis\n3. Allow the request through or reject it with a 429 status\n\nWalk me through how you'd structure this plugin in Lua. What are the key lifecycle phases you'd use, and how would you interact with Redis?\n\n---\n\n## Why This Question Works:\n\n\u2705 **Practical** \u2014 Tests real plugin development, not Kong trivia  \n\u2705 **Scoped** \u2014 Can be answered thoroughly in 3-5 minutes  \n\u2705 **Multi-layered** \u2014 Evaluates:\n- Understanding of Kong's request/response lifecycle\n- Lua syntax and plugin structure\n- Redis client usage\n- HTTP status code handling\n\n\u2705 **Mid-level appropriate** \u2014 Assumes familiarity with Kong/Lua but doesn't require advanced optimization\n\n---\n\n## What to Listen For:\n- Mention of `access` phase (where business logic runs before proxying)\n- Use of Kong's Redis connector or similar approach\n- Proper",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Directly tests core Kong plugin development (Lua structure, lifecycle phases, Redis integration) matching API gateway auth/rate-limiting needs. Crystal clear scenario with focused scope, no ambiguity. Strong separation via applied knowledge of phases (access), Redis interaction, and trade-offs, not mere recall. Minor ding for no explicit time constraint but well-scoped for screening.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-459",
        "role_title": "Junior Backend Engineer - Container Security",
        "question": "# Technical Screening Question\n\n**Scenario-Based Question:**\n\n\"You're setting up Trivy to scan Docker images in your CI/CD pipeline. A developer builds an image from `ubuntu:latest` and the scan reports several high-severity vulnerabilities. Walk me through:\n\n1. What those vulnerabilities likely are and why they appear in a base image\n2. How you would approach fixing this\u2014what would you suggest to the developer?\n3. What's one limitation of just scanning and how might you enforce better practices going forward?\"\n\n---\n\n## Why This Works:\n\n\u2705 **Practical** \u2013 Mirrors real junior-level tasks (running scans, interpreting results, suggesting fixes)\n\n\u2705 **Layered** \u2013 Tests three levels: understanding (what vulnerabilities are), problem-solving (how to fix), and systems thinking (policy enforcement)\n\n\u2705 **Time-appropriate** \u2013 Answers in 2-5 minutes; no deep architectural knowledge required\n\n\u2705 **Seniority-aligned** \u2013 Doesn't expect mastery of Kubernetes or complex orchestration; focuses on container fundamentals they'll actually work with day one\n\n\u2705 **",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core container scanning (Trivy/Docker), vulnerability detection, base image management, and policy enforcement for entry-level role (-0 red flags). Clarity: Well-scoped scenario with numbered parts, unambiguous, screening-appropriate depth. Discriminative: Excellent separation via layered testing (understanding -> problem-solving -> systems thinking/trade-offs), not recall/yes-no, practical for juniors.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-457",
        "role_title": "Senior Backend Engineer - SLO Automation",
        "question": "# Screening Question\n\n**You're designing a burn rate alerting system for SLOs in Kubernetes. A service has a 99.9% availability SLO, and you need to alert when the error budget is being consumed too quickly\u2014not just when the SLO is breached.**\n\n**Walk me through:**\n1. **How would you define \"burn rate\"** in this context, and why is it better than just checking current error rates?\n2. **What would be a reasonable alerting strategy?** (e.g., at what burn rate multiples would you trigger alerts, and over what time windows?)\n3. **How would you implement this in Prometheus/Sloth,** or if you've used similar tools, what challenges did you encounter?\n\n---\n\n## Why This Question Works\n\n\u2705 **Practical & Real** \u2013 Senior engineers actually design these systems  \n\u2705 **Multi-layered** \u2013 Tests conceptual understanding, judgment, and implementation knowledge  \n\u2705 **Time-appropriate** \u2013 A strong candidate answers in 3-4 minutes with specifics  \n\u2705 **Reveals depth** \u2013 Distinguishes between someone who's",
        "scores": {
          "relevance": 9,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core SLO/burn rate alerting skills for the role's infrastructure focus, matches Kubernetes/Prometheus context (-1 for minor unlisted 'Sloth' tool). Clarity: Well-structured but multiple bundled sub-questions (-2) and lacks strict time/format constraints. Discriminative: Excellent at separating candidates via definitions, judgment on thresholds/windows, and real implementation trade-offs/challenges.",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-460",
        "role_title": "Backend Engineer - Experiment Tracking",
        "question": "# Technical Screening Question\n\n**You're building an experiment tracking service where data scientists log thousands of metrics per experiment run. A team member proposes storing all metrics in a single PostgreSQL table with columns: `run_id`, `metric_name`, `metric_value`, `timestamp`.**\n\n**What issues might this approach have as the system scales, and how would you redesign it?**\n\n---\n\n## Why This Question Works:\n\n\u2705 **Tests practical architecture thinking** \u2013 Assesses ability to anticipate scaling issues, not memorize syntax\n\n\u2705 **Mid-level appropriate** \u2013 Expects knowledge of database design and ML workflows, but not deep distributed systems expertise\n\n\u2705 **Real-world relevance** \u2013 Directly mirrors decisions made when building experiment tracking systems (similar to MLflow's actual design challenges)\n\n\u2705 **Open-ended** \u2013 Reveals how candidates think about tradeoffs (normalization vs. query performance, time-series data handling, retention policies)\n\n---\n\n## What You're Listening For:\n\n- **Good signals:** Time-series considerations, index strategies, schema normalization, partitioning by run_id or time, separate tables for different metric",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core skills for ML experiment tracking infrastructure (metric logging, scaling), matches role exactly, no red flags. Clarity: Crystal clear scenario and ask, well-scoped for screening, minor deduction for no explicit time/format constraints. Discriminative: Excellent at revealing trade-offs (schema, partitioning, time-series), strong separation of mid-level thinkers, open-ended but focused.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-461",
        "role_title": "Senior Backend Engineer - Fraud Detection",
        "question": "# Screening Question\n\n**Walk me through how you'd design a real-time fraud detection system that needs to make a pass/fail decision on a payment transaction in under 100ms. What are the key components, and where would you use Redis, Kafka, and your ML model in this pipeline?**\n\n---\n\n## Why This Question Works:\n\n\u2705 **Tests core competencies:**\n- Real-time system design (critical for payments)\n- Understanding of the tech stack and *why* each tool fits\n- ML model deployment trade-offs\n- Latency constraints in production\n\n\u2705 **Reveals seniority through depth:**\n- Junior: \"Run the model and return a score\"\n- Senior: Discusses caching strategies, async scoring, fallback rules, batch vs. real-time tradeoffs, model serving architecture\n\n\u2705 **Practical & answerable:** Candidates can outline their approach in 3-4 minutes and go deeper on areas they know well\n\n\u2705 **Conversation starter:** Natural follow-ups on model versioning, handling feature freshness, manual review workflows, etc.",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core fraud detection pipeline skills with exact tech stack (Redis, Kafka, ML) and real-time constraints from role. Clarity: Crystal clear with 100ms scope, but minor deduction for no explicit answer format/depth. Discriminative: Strong separation via trade-offs, component reasoning, and latency handling; reveals seniority without being too broad.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-462",
        "role_title": "Backend Engineer - Alert Routing",
        "question": "# Screening Question\n\n**You're designing an alert routing system where multiple alerts from different services need to be deduplicated and grouped before being sent to PagerDuty. An alert for a database connection timeout might come from 5 different services simultaneously, but you only want to trigger one PagerDuty incident.**\n\n**How would you approach deduplication in this system? Walk me through:**\n1. **What would you use as a deduplication key?**\n2. **Where in your architecture would you implement this check\u2014before or after Alertmanager?**\n3. **How would you handle the storage and TTL of these deduplication records?**\n\n---\n\n## Why This Question Works\n\n- **Practical & Real:** Directly mirrors the actual problem described in the job\n- **Shows System Design Thinking:** Evaluates architectural decisions, not just syntax\n- **Mid-Level Appropriate:** Requires Go/backend experience but doesn't demand expert-level mastery\n- **Reveals Technical Depth:** Answers expose knowledge of:\n  - Alert fingerprinting/grouping concepts\n  - Trade-offs between Alertmanager config vs custom logic",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (alert deduplication/grouping) with PagerDuty mention; minor ding for assuming Alertmanager familiarity not explicit in role (-1). Clarity: Crystal clear, well-scoped multi-part structure with no ambiguity. Discriminative: Excellent separation via trade-offs (keys, architecture placement, storage/TTL), reveals deep applied knowledge beyond recall.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-463",
        "role_title": "Junior Backend Engineer - Full-text Search",
        "question": "# Screening Question\n\n**You're building a search feature for a product catalog. A user searches for \"red shoes\" and you need to return results ranked by relevance. Walk me through how you'd implement this in PostgreSQL using full-text search, and explain what a `tsvector` is and why it matters.**\n\n---\n\n## Evaluation Criteria\n\n**Strong Answer** includes:\n- Explains `tsvector` as a preprocessed text format optimized for search (tokenization, lemmatization)\n- Mentions creating a `tsvector` column or generating it on-the-fly with `to_tsvector()`\n- References `tsquery` for converting search input\n- Discusses ranking (e.g., `ts_rank()` or `ts_rank_cd()`) to order results by relevance\n- Shows awareness of indexing with GIN or GIST for performance\n\n**Acceptable Answer** includes:\n- Core concept of `tsvector` as processed text\n- Basic query matching using `@@` operator\n- At least mentions ranking or indexing\n\n**Red Flags:**\n- Confuses `tsvector` with regular string",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests PostgreSQL full-text search core skills (tsvector, ranking) from role description, no red flags. Clarity: Crystal clear and well-scoped for screening, minor deduction for lacking explicit time constraint. Discriminative: Requires applied knowledge and trade-offs (e.g., indexing choices), strong separation via detailed strong/acceptable criteria provided.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-465",
        "role_title": "Backend Engineer - CDC Pipelines",
        "question": "# Screening Question\n\n**\"Walk me through how you would handle a schema change (e.g., adding a new column) in a source PostgreSQL table when you have an active Debezium CDC pipeline running to Snowflake. What could go wrong, and how would you ensure no data is lost?\"**\n\n---\n\n## Why This Question Works\n\n**Practical & Real:** Schema evolution is a constant challenge in production CDC pipelines\u2014not theoretical.\n\n**Mid-Level Appropriate:** Tests understanding of:\n- Debezium's behavior during schema changes\n- Downstream implications (Snowflake compatibility)\n- Data loss risks and recovery strategies\n- Operational problem-solving\n\n**Opens Conversation:** Candidates can discuss:\n- Signal tables / schema history topics\n- Backfilling strategies\n- Rolling deployments or pipeline restarts\n- Exactly-once semantics under schema changes\n\n**Time-Boxed:** Naturally fits a 3-5 minute discussion with follow-ups like:\n- \"How would you test this?\"\n- \"What if the column is NOT NULL?\"\n- \"How do you monitor for pipeline lag during this?\"\n\nThis reveals both depth",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's CDC pipelines, schema changes, PostgreSQL/Debezium/Snowflake stack. Clarity: Crystal clear scenario with example, well-scoped for screening; minor deduction for no explicit time constraint. Discriminative: Tests deep applied knowledge of schema evolution risks, recovery, trade-offs\u2014strong separation of mid-level expertise.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-467",
        "role_title": "Backend Engineer - Connection Pooling",
        "question": "# Screening Question\n\n**You're implementing a connection pooling layer for a high-traffic application using PgBouncer. Your application has 50 concurrent users, but you're seeing connection timeouts and occasional \"too many connections\" errors even though your PostgreSQL max_connections is set to 200.**\n\n**Walk me through how you would:**\n1. **Diagnose** what's happening (what metrics/logs would you check?)\n2. **Configure** PgBouncer pool_size and reserve_pool_size to fix it\n3. **Explain** the tradeoff you're making with your chosen pool size\n\n---\n\n## Why This Question Works\n\n\u2705 **Practical** \u2013 Tests real troubleshooting skills, not theoretical knowledge  \n\u2705 **Appropriate Level** \u2013 Mid-level should understand pooling concepts and basic PgBouncer config  \n\u2705 **Multi-layered** \u2013 Assesses diagnosis, configuration, and architectural thinking  \n\u2705 **Time-bound** \u2013 Answerable with concrete examples in 3-4 minutes  \n\u2705 **Role-relevant** \u2013 Directly tests the core responsibility (pool",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core connection pooling, PgBouncer config, sizing, and tradeoffs matching role's pool sizing/failover focus (-0 red flags). Clarity: Well-scoped with numbered parts, specific scenario, no ambiguity. Discriminative: Requires diagnosis (applied knowledge), config decisions, and tradeoff explanation, strongly separating candidates with deep understanding from rote learners.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-464",
        "role_title": "Staff Engineer - Presence Systems",
        "question": "# Screening Question\n\n**Design a heartbeat protocol for a presence system that needs to handle 100K concurrent users. Walk me through:**\n\n1. **What information would you include in each heartbeat message, and why?**\n2. **How would you handle a client that stops sending heartbeats\u2014what's your timeout strategy?**\n3. **How would you reduce bandwidth while keeping presence data reasonably fresh?**\n\n**Follow-up:** *If a user has flaky network connectivity and heartbeats are dropping 30% of the time, how would that change your design?*\n\n---\n\n## Why This Works\n\n\u2705 **Practical & Real** \u2014 Staff engineers make these architectural tradeoffs daily  \n\u2705 **Shows Systems Thinking** \u2014 Reveals how they balance freshness, cost, and reliability  \n\u2705 **Appropriate Scope** \u2014 Not a deep-dive, but exposes their reasoning at scale  \n\u2705 **Seniority Signal** \u2014 Listen for mentions of:\n- Exponential backoff, jitter\n- State machine thinking (connected \u2192 stale \u2192 offline)\n- Tradeoffs between accuracy and resource cost\n-",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Directly targets core role skills (heartbeat protocols, presence at scale, connection management) with no red flags. Crystal clear structure with focused sub-questions and scoped follow-up; no ambiguity or overload. Strong separation via trade-offs (bandwidth, timeouts, flaky networks), state machines, backoff\u2014reveals senior systems thinking vs rote knowledge.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-466",
        "role_title": "Senior Backend Engineer - GitOps Tooling",
        "question": "# Technical Screening Question\n\n**\"Walk me through how you would design a reconciliation loop for a GitOps tool that detects and corrects drift between desired state (in Git) and actual state (in a Kubernetes cluster). What are the key components, and what challenges would you anticipate around frequency, performance, and handling conflicts?\"**\n\n---\n\n## Why This Question Works\n\n**Practical & Senior-Level:**\n- Tests hands-on understanding of core GitOps concepts, not just terminology\n- Requires systems thinking (architecture, trade-offs, edge cases)\n- Appropriate for someone who's built or debugged similar systems\n\n**Observable Skills:**\n- Understands reconciliation patterns (controller loops, watch mechanisms)\n- Thinks about operational trade-offs (sync frequency vs. load, false positives)\n- Considers real-world complications (failed reconciliations, user-initiated changes, resource limits)\n- Likely mentions: controllers, informers/watches, exponential backoff, conflict resolution strategies\n\n**Time-Appropriate:**\n- Can sketch a solid answer in 2-5 minutes\n- Allows follow-ups on specifics (ArgoCD's approach",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Directly targets core GitOps reconciliation loops, drift detection, and trade-offs matching role's declarative infra focus (no red flags). Crystal clear with specific scope (components, challenges: frequency/performance/conflicts), minor deduction for lacking explicit time/format constraints. Strong separation via trade-offs, edge cases, and applied systems knowledge; not recall/trivia, scannable in <10min.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-468",
        "role_title": "Junior Backend Engineer - CI Pipelines",
        "question": "# Technical Screening Question\n\n**\"Walk me through how you would set up a GitHub Actions workflow that builds a Docker image and runs Python unit tests in parallel across 3 different test suites. What would you include to make sure the workflow doesn't rebuild the Docker image if the Dockerfile hasn't changed?\"**\n\n---\n\n## Why This Question Works:\n\n**Tests practical skills:**\n- GitHub Actions workflow syntax (job configuration, steps)\n- Docker integration in CI pipelines\n- Job parallelization (matrix strategy)\n- Caching strategies (layer caching, dependency caching)\n\n**Appropriate for junior level:**\n- Not asking for advanced optimization techniques\n- Tests fundamentals they'd use day-one\n- Allows candidates to show what they know without requiring production experience\n\n**Realistic scenario:**\n- Mirrors actual tasks in the role (Docker builds + test parallelization)\n- Shows how they think about pipeline efficiency\n\n**Flexible depth:**\n- Junior candidates can answer at basic level (matrix jobs, basic caching)\n- Strong candidates naturally mention docker/build-cache action, artifacts, or conditional steps\n- Easy to probe deeper with follow-ups",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Directly tests core role skills (GitHub Actions workflows, Docker builds, test parallelization, caching) for entry-level CI pipeline engineer. Crystal clear with specific scenario and efficiency constraint; minor deduction for lacking explicit time/format constraints. Strong separation via trade-offs in caching/parallelization strategies, flexible for junior levels without being trivial.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-470",
        "role_title": "Backend Engineer - GraphQL Federation",
        "question": "# Screening Question: Backend Engineer - GraphQL Federation\n\n## Question:\n\n**You have two federated subgraphs: a \"Users\" subgraph and an \"Orders\" subgraph. The Users subgraph defines a `User` entity with a `@key` directive, and the Orders subgraph needs to reference User data.**\n\n**Walk me through:**\n1. **How would you define the `@key` directive on the User entity, and why is it necessary?**\n2. **How would you extend the User type in the Orders subgraph to add order-related fields?**\n3. **What would happen if a gateway query requests both user information and their orders - briefly describe the query planning process.**\n\n---\n\n## Why This Works:\n\n\u2705 **Practical & Scenario-Based** \u2014 Tests real federation patterns candidates will implement daily\n\n\u2705 **Multi-Layered** \u2014 Assesses understanding of keys, entity references, and gateway query execution\n\n\u2705 **Time-Appropriate** \u2014 Answerable in 3-4 minutes with concrete code examples or explanations\n\n\u2705 **Mid-Level Calibration** \u2014 Doesn",
        "scores": {
          "relevance": 7,
          "clarity": 8,
          "discriminative": 8,
          "reasoning": "Relevance: Directly tests core GraphQL federation skills (schema stitching, entity resolution, query planning) but deduct -3 for generic multi-part structure applicable to many backend roles. Clarity: Well-scoped and unambiguous, but -2 for bundling 3 questions into one. Discriminative: Strong separation via applied knowledge of federation mechanics and trade-offs, not just recall; scenario-based with good depth for screening.",
          "composite": 7.666666666666667
        }
      },
      {
        "role_id": "be-472",
        "role_title": "Backend Engineer - Vector Search",
        "question": "# Screening Question\n\n**You're implementing a hybrid search system that combines keyword matching with semantic similarity. A user searches for \"affordable running shoes,\" but your vector search returns results for \"expensive athletic footwear\" with high semantic similarity, while keyword search correctly filters by price. How would you structure this to balance both signals, and what are the trade-offs you'd consider?**\n\n---\n\n## Why This Works:\n\n\u2705 **Practical** \u2013 Tests real-world problem-solving in vector search systems  \n\u2705 **Mid-level appropriate** \u2013 Requires understanding of embeddings + ranking, but not deep ML theory  \n\u2705 **Time-scoped** \u2013 Can be answered meaningfully in 2-5 minutes  \n\u2705 **Role-specific** \u2013 Directly relevant to hybrid search, index management, and semantic limitations  \n\u2705 **Open-ended** \u2013 Reveals thinking about weighting strategies, re-ranking, and system design\n\n## What You're Listening For:\n\n- Understanding that semantic similarity \u2260 intent matching\n- Awareness of ranking/weighting approaches (score normalization, fusion algorithms)\n- Knowledge of when keyword search catches what vectors",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core hybrid search, semantic retrieval, and vector limitations from role (-0 red flags). Clarity: Crystal clear scenario with precise scope for screening. Discriminative: Probes trade-offs in weighting/fusion/ranking, revealing deep applied understanding vs rote knowledge.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-473",
        "role_title": "Senior Backend Engineer - Refund Processing",
        "question": "# Screening Question\n\n**Design a refund processing system that needs to handle partial refunds and ensure ledger consistency. Walk me through:**\n\n1. **How would you structure the data model** to support multiple partial refunds against a single transaction, ensuring you can always answer \"what's the refund status of this order?\"\n\n2. **What consistency challenges do you anticipate** when a partial refund is initiated but the provider callback hasn't arrived yet? How would you handle a callback that arrives out of order?\n\n3. **How would you use Kafka and/or a database transaction** to ensure the ledger entry and refund record stay in sync, especially if the service crashes between these two operations?\n\n---\n\n## Why This Question Works\n\n\u2713 **Practical depth:** Tests real architectural decisions (data modeling, eventual consistency, idempotency)  \n\u2713 **Seniority-appropriate:** Expects knowledge of distributed systems trade-offs, not just syntax  \n\u2713 **Stack-relevant:** Naturally incorporates Kafka, PostgreSQL, and ledger thinking  \n\u2713 **Open-ended:** Senior engineers show depth through how they prioritize concerns (consistency vs.",
        "scores": {
          "relevance": 7,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Tests core refund/ledger skills but assumes Kafka/PostgreSQL not explicitly listed (-2 for unlisted tech, -1 generic distributed design). Clarity: Crystal clear, well-scoped sub-questions with precise intent. Discriminative: Excellent at probing trade-offs in consistency, out-of-order events, and sync mechanisms, strongly separates seniors.",
          "composite": 8.333333333333334
        }
      },
      {
        "role_id": "be-476",
        "role_title": "Backend Engineer - Live Updates",
        "question": "# Technical Screening Question\n\n## Question:\n\n**\"Walk us through how you'd implement a feature where different users see different real-time updates based on their assigned dashboard. For example, User A should only receive updates for Dashboard 1, while User B only gets updates for Dashboard 2. How would you use Socket.io rooms to prevent data leakage, and what would you do if a user's dashboard assignment changes while they're connected?\"**\n\n---\n\n## Why This Works:\n\n\u2705 **Practical & Real-World** \u2014 Directly mirrors the job's core responsibility  \n\u2705 **Tests Multiple Competencies** \u2014 Room management, broadcasting logic, reconnection handling  \n\u2705 **Appropriate Depth** \u2014 Mid-level should know Socket.io basics but may need to think through edge cases  \n\u2705 **Timeboxed** \u2014 Can be answered with a clear architecture in 3-4 minutes  \n\u2705 **Reveals Problem-Solving** \u2014 Shows how they handle permission boundaries and state transitions\n\n---\n\n## What You're Looking For:\n\n- **Strong Answer:** Uses Socket.io `join()`/`leave()` rooms, considers leaving",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Perfect relevance to role's core needs (rooms, selective broadcasting, reconnections). Crystal clear with specific Socket.io focus and edge case, well-scoped for screening. Excellent at distinguishing via trade-offs in room management and state changes; minor subtract for lacking explicit time/format constraints.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-469",
        "role_title": "Senior Backend Engineer - Chaos Engineering",
        "question": "# Screening Question\n\n**You're designing a chaos experiment to test the resilience of a microservices platform. Walk me through how you would approach injecting a network partition between two critical services for 2 minutes, then validate that the system recovered correctly. What would you monitor, and how would you ensure you don't accidentally take down the entire platform?**\n\n---\n\n## Why This Question Works\n\n**Practical & Open-Ended:** Tests real chaos engineering thinking\u2014not just tool knowledge\n- Covers blast radius control (critical for senior level)\n- Requires understanding of observability (Prometheus/Grafana)\n- Allows candidates to discuss Chaos Mesh implementation naturally\n\n**Senior-Level Indicators to Listen For:**\n- Mention of blast radius limiting (namespace selectors, label targeting)\n- Observability strategy (what metrics matter, when to abort)\n- Recovery validation (how do you know when it's safe?)\n- Rollback/circuit breaker mentality\n- Discussion of staged rollout or dry-run approaches\n\n**Time-Appropriate:** 2-5 minute response with natural follow-ups available (Chaos Mesh manifest details, Go-based tool",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Directly tests core chaos engineering skills (failure injection, blast radius control, recovery validation) matching role; crystal clear with specific scenario, duration, and constraints; strong separation via trade-offs in monitoring, safety, and validation\u2014senior indicators like namespace targeting distinguish experts. Minor ding for assuming microservices without role confirmation, but excellent overall.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-475",
        "role_title": "Junior Backend Engineer - Search Analytics",
        "question": "# Technical Screening Question\n\n**\"Walk me through how you would track and analyze search queries in a system. Specifically, if you wanted to identify which search terms users click on the most, what data would you need to collect, and how would you structure it in a database?\"**\n\n---\n\n## Evaluation Rubric\n\n**Strong Answer (Hire Signal):**\n- Mentions capturing both query text and click events with timestamps\n- Suggests linking queries to results clicked via some identifier (query ID, session ID, etc.)\n- Proposes aggregating/counting clicks by query term\n- References a reasonable schema (e.g., separate tables for queries and clicks, or a denormalized approach)\n\n**Acceptable Answer (Proceed):**\n- Understands the need to log queries and clicks\n- Can describe a basic approach to counting popular queries\n- May lack detail on schema design but shows foundational thinking\n\n**Weak Answer (Red Flag):**\n- Only mentions logging queries without connecting to user actions\n- No consideration of how to relate queries to clicks\n- Vague on database structure or data relationships\n\n---\n\n## Why This Question Works\n\n\u2713 Tests real, day-",
        "scores": {
          "relevance": 9,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core search analytics skills (query logging, click tracking) for the role (-1 for no specific tech stack mention). Clarity: Clear intent and specific focus, but lacks explicit constraints like scale or format (8). Discriminative: Strong separation via trade-offs in data collection, linking, and schema design; rubric shows good candidate differentiation.",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-474",
        "role_title": "Backend Engineer - Dashboards API",
        "question": "# Technical Screening Question\n\n**You're building an API endpoint that retrieves a dashboard with templated variables (like `$datasource` and `$environment`). A user requests the dashboard with query parameters `?datasource=prometheus&environment=prod`.**\n\n**Walk me through:**\n1. How would you handle variable substitution in the dashboard template?\n2. What would you consider for caching this endpoint, and what cache invalidation strategy would you use?\n3. What potential issues might arise if multiple dashboards share variable definitions?\n\n---\n\n## Why This Question Works:\n\n\u2705 **Practical & Real** \u2014 Directly reflects work they'd do (templating, variables, caching)  \n\u2705 **Mid-Level Appropriate** \u2014 Tests design thinking beyond just coding syntax  \n\u2705 **Stack-Relevant** \u2014 Naturally leads to discussing Redis caching, PostgreSQL storage, and Grafana patterns  \n\u2705 **Multi-Layered** \u2014 Allows candidates to show depth while keeping it conversational (2-5 min answer)  \n\u2705 **Reveals Problem-Solving** \u2014 Shows how they think about performance, data consistency",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core dashboard templating, variable substitution, caching, and sharing\u2014matches role exactly (-0 red flags). Clarity: Well-scoped with concrete scenario, clear numbered parts, no ambiguity or bundling issues. Discriminative: Multi-part probes applied knowledge, trade-offs (caching/invalidation), and edge cases (shared vars), strongly separates mid-level thinkers.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-477",
        "role_title": "Senior Backend Engineer - Data Catalog",
        "question": "# Technical Screening Question\n\n**Scenario-based question:**\n\n\"Walk me through how you would design a metadata extraction pipeline that automatically captures lineage information when data flows through multiple Kafka topics into PostgreSQL tables. \n\nSpecifically:\n- How would you identify and track the relationship between source topics and destination tables?\n- What metadata would you extract and store in Apache Atlas?\n- How would you handle schema changes or topic reconfigurations without breaking the lineage?\"\n\n---\n\n## Why this works:\n\n\u2705 **Practical & Role-Specific** \u2014 Directly applies to data catalog, lineage tracking, and the exact tech stack (Kafka \u2192 PostgreSQL \u2192 Atlas)\n\n\u2705 **Senior-Level** \u2014 Requires architectural thinking, not just tool knowledge; tests design decisions and trade-offs\n\n\u2705 **Answerable in 2-5 mins** \u2014 Candidate can outline approach without writing code; allows follow-ups to probe depth\n\n\u2705 **Reveals Real Experience** \u2014 Distinguishes between someone who's built similar systems vs. someone who's only read documentation",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfect match to role's data catalog, lineage tracking, and exact tech stack (Kafka, PostgreSQL, Atlas). Clarity: Crystal clear scenario with specific sub-questions; minor deduction for lacking explicit time/format constraints. Discriminative: Excellent at testing architectural trade-offs, real-world handling of schema changes, and deep understanding vs. superficial knowledge.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-471",
        "role_title": "Staff Engineer - Zero Trust Architecture",
        "question": "# Screening Question\n\n**You're designing a zero trust architecture for a large microservices platform running on Kubernetes. Your team wants to enforce mutual TLS (mTLS) between all services, but you've identified a bootstrapping problem: when a new service pod starts, it needs a valid certificate to communicate, but it can't authenticate to get one without already having credentials.**\n\n**Walk me through how you'd solve this using SPIFFE, and explain the trade-offs of your approach compared to alternatives like sidecar injection or init containers.**\n\n---\n\n## Why This Question Works\n\n**For Staff Level:**\n- Requires systems thinking (bootstrapping paradox isn't trivial)\n- Tests understanding of SPIFFE's design philosophy, not just syntax\n- Expects them to articulate trade-offs\u2014a staff-level responsibility\n\n**Practical & Scoped:**\n- Solves a real problem they'll face on day one\n- Answerable in 2-5 minutes without whiteboarding\n- Reveals how they think about identity federation\n\n**What You're Listening For:**\n- \u2705 Mention of **Workload API** and how SPIFFE si",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 10,
          "reasoning": "Relevance: Perfectly matches role's zero trust, mTLS, and identity focus; directly tests SPIFFE for microservices auth. Clarity: Crystal clear with precise scenario and scope, minor truncation in 'why' section irrelevant. Discriminative: Excellent at separating via systems thinking, trade-offs, and deep SPIFFE understanding\u2014no recall pitfalls.",
          "composite": 9.666666666666666
        }
      },
      {
        "role_id": "be-478",
        "role_title": "Backend Engineer - Cost Attribution",
        "question": "# Technical Screening Question\n\n**Scenario:** Your cost attribution system needs to allocate costs for a shared Kubernetes cluster across 10 teams. Some pods have clear team labels, but about 30% lack proper tagging. Additionally, you need to handle shared infrastructure costs (control plane, networking) that don't map to individual pods.\n\n**Question:** Walk me through how you would design a solution to:\n1. Handle the untagged pods in a way that's fair but traceable\n2. Allocate shared infrastructure costs across teams\n3. What data would you store in PostgreSQL, and how would you structure it to make cost queries flexible?\n\n---\n\n## Why This Works:\n\n\u2705 **Tests practical mid-level experience** \u2013 Real problem they'll face, not theoretical  \n\u2705 **Covers core stack** \u2013 Kubernetes labels, PostgreSQL schema design, cost logic  \n\u2705 **Reveals decision-making** \u2013 How they balance accuracy, traceability, and maintainability  \n\u2705 **Answerable in timeframe** \u2013 High-level design, not implementation details  \n\u2705 **Role-appropriate** \u2013 Directly tied to \"cost",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (K8s tagging, cost allocation, PostgreSQL for reports); no red flags (-0). Clarity: Well-scoped scenario with 3 clear sub-questions; no bundling or ambiguity issues (-0). Discriminative: Probes trade-offs in fairness/traceability, allocation logic, and schema design for flexibility; strong separation of deep thinkers (-0). Exceptional question for the role.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-480",
        "role_title": "Junior Backend Engineer - Deployment Automation",
        "question": "# Screening Question\n\n**You need to deploy a web application to three different AWS environments (dev, staging, production). Each environment requires different configuration settings (database URLs, API keys, logging levels, etc.), but the application code itself remains the same.**\n\n**How would you approach this using Ansible, and what would be your strategy for managing these environment-specific configurations?**\n\n---\n\n## Why This Question Works:\n\n\u2705 **Practical & Real-World** \u2014 Directly mirrors actual deployment scenarios  \n\u2705 **Appropriate Level** \u2014 Doesn't require advanced expertise, but shows if they understand core concepts  \n\u2705 **Covers Key Skills** \u2014 Tests understanding of Ansible, configuration management, and deployment strategy  \n\u2705 **Open-Ended** \u2014 Allows candidates to demonstrate their thinking process  \n\u2705 **Time-Appropriate** \u2014 Answerable in 2-5 minutes with room for follow-ups\n\n---\n\n## What You're Looking For:\n\n**Strong Answer Indicators:**\n- Mentions Ansible inventory groups (dev, staging, prod)\n- References `group_vars` or `host_vars` for environment-specific configs\n-",
        "scores": {
          "relevance": 7,
          "clarity": 9,
          "discriminative": 8,
          "reasoning": "Relevance: Tests core configuration management and deployment skills for the role, but Ansible isn't explicitly listed in role description (-2); not generic but assumes specific tool. Clarity: Crystal clear scenario, well-scoped, precise expectations. Discriminative: Requires applied Ansible knowledge and trade-offs (e.g., group_vars strategy), distinguishes candidates familiar with practical deployment from theorists.",
          "composite": 8.0
        }
      },
      {
        "role_id": "be-479",
        "role_title": "Principal Engineer - Data Architecture",
        "question": "# Screening Question\n\n**You're architecting a system that needs to handle both real-time transactional writes (millions of orders/day) and complex analytical queries (daily reports on 6+ months of historical data). Walk me through how you'd approach this problem\u2014what are the key trade-offs you'd consider, and how would PostgreSQL and ClickHouse fit into your solution?**\n\n---\n\n## Why This Question Works\n\n**Tests Principal-Level Thinking:**\n- Requires understanding of OLTP vs OLAP tradeoffs (not just knowing the difference)\n- Evaluates strategic decision-making, not just technical knowledge\n- Appropriate for someone who will guide architecture decisions for a team\n\n**Practical & Realistic:**\n- Common real-world scenario (lambda/kappa architecture patterns)\n- Lets candidate showcase depth in the tech stack provided\n- Can discuss: data pipeline design, eventual consistency, tool selection rationale\n\n**Time-Appropriate:**\n- Can be answered substantively in 2-5 minutes\n- Natural follow-ups available (Kafka's role, scaling considerations, etc.)\n- No \"gotcha\" trivia\u2014open-ended enough",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's data architecture for analytics/transactional workloads, directly tests PostgreSQL/ClickHouse in context (no red flags). Clarity: Crystal clear scenario and scope, minor deduction for no explicit time/format constraints. Discriminative: Excellent at probing trade-offs, strategic thinking, and applied knowledge to separate principal-level candidates from others.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-481",
        "role_title": "Backend Engineer - Canary Deployments",
        "question": "# Screening Question\n\n**You're implementing a canary deployment where you need to automatically rollback if the new version's error rate exceeds the stable version's by more than 5%. Walk me through how you'd set this up with Istio and Prometheus\u2014specifically, what metrics you'd query, how you'd compare them, and where you'd implement the decision logic.**\n\n---\n\n## Why This Works\n\n**Practical Application:** Tests real canary deployment thinking\u2014the candidate must understand the full feedback loop from metrics collection through automated decision-making.\n\n**Appropriate Depth for Mid-Level:** \n- Assumes familiarity with Istio traffic splitting and Prometheus queries\n- Doesn't require deep implementation details, but reveals gaps quickly\n- Mid-level engineers should know *where* logic lives (Prometheus rule, ArgoCD hook, custom controller)\n\n**Reveals Key Competencies:**\n- Metric selection (error rate, how to calculate per-version)\n- Istio concepts (VirtualService traffic weights, how to query per-canary metrics)\n- Integration thinking (how do these components talk?)\n- Automation mindset (not manual monitoring)\n\n**",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core canary deployment skills (traffic shifting, metrics, rollback) with exact tech stack (Istio, Prometheus) from role; no red flags (-0). Clarity: Precise scope on metrics, comparison, logic placement; well-formed for screening, no bundling or vagueness (-0). Discriminative: Requires applied knowledge of integrations, trade-offs in metric selection/automation; distinguishes mid-level expertise effectively (-0).",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-483",
        "role_title": "Backend Engineer - WAF Integration",
        "question": "# Screening Question\n\n**You're integrating ModSecurity into an Nginx reverse proxy to protect an API. The security team reports that legitimate requests from a partner's webhook service are being blocked by ModSecurity rules, causing false positives. Walk me through your approach to diagnosing and resolving this issue while maintaining security.**\n\n---\n\n## Why This Works\n\n**Practical depth:** Tests real-world WAF troubleshooting that mid-level engineers encounter regularly\n\n**Seniority-appropriate:** Requires understanding of:\n- ModSecurity rule mechanics and logging\n- Nginx configuration and request flow\n- How to balance security vs. availability\n- Root cause analysis methodology\n\n**Reveals important competencies:**\n- Can they interpret WAF logs effectively?\n- Do they understand rule exclusions and tuning?\n- How do they approach security trade-offs?\n- Can they communicate with security teams?\n\n**Answerable in timeframe:** Candidates can outline key steps (check audit logs \u2192 identify triggering rule \u2192 implement exception) without needing to write code",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core WAF integration, rule management, and balancing security/availability from role (-1 for assuming ModSecurity/Nginx not explicitly listed). Clarity: Crystal clear scenario with well-scoped troubleshooting task. Discriminative: Requires applied knowledge of logs, rules, exclusions, and trade-offs, strongly separating capable engineers.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-484",
        "role_title": "Staff Engineer - Model Registry",
        "question": "# Technical Screening Question\n\n**\"Walk me through how you would design a model registry system that handles concurrent model uploads from multiple teams while maintaining version integrity and preventing accidental deployments of untested models. What are the key components you'd implement, and where would you expect bottlenecks or failure modes?\"**\n\n---\n\n## Why This Question Works:\n\n**Practical & Architectural:** Tests real-world system design rather than memorized facts about MLflow.\n\n**Seniority-Appropriate:** Expects staff-level thinking about concurrency, governance, and trade-offs\u2014not just implementation details.\n\n**Conversational:** Naturally opens follow-ups on:\n- Database schema decisions (PostgreSQL locking, transactions)\n- Workflow orchestration (approval gates, automation)\n- Scalability concerns (S3 artifacts, metadata storage)\n- Safety mechanisms (version tags, rollback strategies)\n\n**Time-Bound:** Candidate can outline a solid answer in 2-5 minutes, with depth emerging naturally in discussion.\n\n**Tech Stack Coverage:** Touches Python/MLflow, PostgreSQL, S3, and implicit Kubernetes deployment concerns without forcing artificial references.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 10,
          "reasoning": "Directly tests core role skills in model registry architecture, versioning, deployment automation, and governance. Crystal clear with focused scope on concurrency, integrity, and failure modes. Excellent at probing trade-offs, bottlenecks, and deep architectural thinking to separate strong architects from average engineers. Minor ding on relevance for not explicitly naming role's tech stack (-1).",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-485",
        "role_title": "Junior Backend Engineer - Payment Webhooks",
        "question": "# Technical Screening Question\n\n**\"Walk me through how you would implement idempotency for a payment webhook handler. Specifically, what would you store, where would you store it, and how would you handle a duplicate webhook arriving?\"**\n\n---\n\n## Why This Question Works:\n\n\u2705 **Tests core competency** - Idempotency is fundamental to payment processing and directly mentioned in the role focus\n\n\u2705 **Practical and realistic** - Handles a real problem they'll face (payment providers retry webhooks)\n\n\u2705 **Right difficulty level** - Junior engineers may not know the answer, but can reason through it with guidance\n\n\u2705 **Opens conversation** - Allows follow-ups about trade-offs (Redis vs. DB), TTL strategies, or race conditions\n\n\u2705 **Evaluates system thinking** - Shows if they understand *why* this matters (financial accuracy, duplicate charges)\n\n---\n\n## What You're Looking For:\n\n- **Good answer**: \"Store the webhook ID in Redis/DB, check before processing, return success if duplicate\"\n- **Great answer**: Mentions TTL, eventual consistency, or idempotency keys from payment provider",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests idempotency, a core skill explicitly listed in role description for payment webhooks (no red flags). Clarity: Crystal clear and well-scoped, minor deduction for lacking explicit constraints like tech stack. Discriminative: Strong separation via applied knowledge, trade-offs (storage, TTL, duplicates), and reasoning; not trivial recall.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-486",
        "role_title": "Backend Engineer - Span Processing",
        "question": "# Screening Question\n\n**You're designing a tail sampling processor in Go that needs to decide whether to keep or drop traces based on error rates and latency percentiles. The sampler receives spans from Kafka and must make decisions within 100ms to avoid blocking the pipeline.**\n\n**Walk me through:**\n\n1. **How would you structure the sampler to aggregate span data efficiently?** (What data do you need to track, and how do you avoid memory bloat?)\n\n2. **What challenges arise when sampling decisions depend on data you might not have received yet?** (e.g., a trace's final latency or whether it contains errors)\n\n3. **How would you handle the case where a sampling decision arrives too late\u2014after some spans have already been dropped?**\n\n---\n\n## Why This Question Works\n\n- **Practical**: Tests real pain points in building observability pipelines\n- **Multi-layered**: Can't just recite OpenTelemetry docs\u2014requires systems thinking\n- **Level-appropriate**: Mid-level engineers should know basic concepts but might struggle with the edge cases\n- **Time-bounded**: Candidate can answer parts of it at different depths (2-5 min",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (tail sampling, span processing) with Go, Kafka, and distributed tracing constraints; minor ding for not mentioning storage/attributes (-1). Clarity: Well-scoped with 100ms limit, clear multi-part structure without bundling overload. Discriminative: Probes deep systems thinking, trade-offs (memory, incomplete data, late decisions), strong separation beyond rote knowledge.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-482",
        "role_title": "Senior Backend Engineer - API Monetization",
        "question": "# Screening Question\n\n**\"Walk me through how you would design a rate-limiting and quota enforcement system for an API monetization platform. Specifically, consider: (1) how you'd track usage across different pricing tiers in real-time, (2) where you'd store this data, and (3) how you'd handle the trade-off between accuracy and performance when a customer approaches their quota limit.\"**\n\n---\n\n## Why This Question Works\n\n**Practical & Relevant:** Directly addresses core responsibilities (quota management, usage tracking) without being contrived.\n\n**Seniority-Appropriate:** Senior engineers should think about architectural trade-offs, not just implement a basic counter. Expect discussion of:\n- Redis for low-latency tracking vs. PostgreSQL for durability\n- Eventual consistency vs. strict enforcement\n- Rate limiting algorithms (sliding window, token bucket, etc.)\n- Handling distributed systems challenges\n\n**Reveals Key Competencies:**\n- System design thinking\n- Understanding of Go/Redis/PostgreSQL in real-world constraints\n- Awareness of billing/monetization edge cases (overage handling, billing cycles)\n- Communication of complex trade-offs\n\n**",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's core needs (quota management, usage tracking, pricing tiers) with no red flags. Clarity: Crystal clear, well-scoped with specific numbered points, minor deduction for no explicit time/format constraints. Discriminative: Excellent at probing trade-offs, distributed systems thinking, and tech choices (Redis/PostgreSQL implied), strongly separates strong candidates.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-489",
        "role_title": "Backend Engineer - Data Quality",
        "question": "# Technical Screening Question\n\n**Scenario-based question:**\n\n\"You're building a data quality check in Great Expectations for a critical fact table in Snowflake that's loaded daily via Airflow. The table should have at least 100k rows, but this morning it only has 50k rows. Walk me through:\n\n1. How would you structure a Great Expectations validator to catch this volume anomaly?\n2. What would you check first in Airflow to diagnose the root cause?\n3. How would you prevent this from silently failing again?\"\n\n---\n\n## Why This Works\n\n\u2705 **Practical & Real:** Mid-level engineers face this exact scenario  \n\u2705 **Multi-faceted:** Tests Great Expectations, Airflow troubleshooting, and systems thinking  \n\u2705 **Observable Depth:** Reveals whether they understand:\n- Data quality framework mechanics (not just syntax)\n- Pipeline debugging methodology\n- Proactive monitoring vs. reactive fixes\n\n\u2705 **Time-bound:** Can be answered substantively in 3-4 minutes  \n\u2705 **Seniority-appropriate:** Doesn't require deep",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core data quality (volume anomalies) and key tools (Snowflake, Airflow) from role; minor ding as Great Expectations unmentioned but fits perfectly (-1). Clarity: Crystal clear scenario with numbered parts, well-scoped for screening. Discriminative: Tests applied knowledge, troubleshooting methodology, and trade-offs (reactive vs proactive), strongly separating mid-level expertise.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-487",
        "role_title": "Senior Backend Engineer - Search Ranking",
        "question": "# Technical Screening Question\n\n**\"Walk me through how you'd approach building a learning-to-rank model for search relevance. Specifically, what features would you engineer, and how would you handle the challenge of getting reliable training labels at scale?\"**\n\n## Why This Question Works:\n\n\u2713 **Tests Core Competency** - Directly assesses learning-to-rank expertise and understanding of the full pipeline\n\n\u2713 **Practical & Realistic** - Mirrors actual senior-level decisions (feature selection, labeling strategies)\n\n\u2713 **Multiple Dimensions** - Reveals:\n- Feature engineering thinking (BM25 scores, click data, semantic similarity, etc.)\n- Label generation approaches (clicks, ratings, implicit signals, crowdsourcing tradeoffs)\n- Awareness of real-world constraints (scale, data quality, cold-start problems)\n\n\u2713 **Senior-Level Depth** - Expects thoughtful tradeoffs and system-level thinking, not just textbook answers\n\n\u2713 **Natural Follow-ups** - Easy to probe deeper:\n- \"How would you validate model quality before A/B testing?\"\n- \"What do you",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's core focus on learning-to-rank pipelines, feature engineering, and implicit label challenges (no red flags). Clarity: Crystal clear and well-scoped for screening, minor deduction for lacking explicit time/format constraints. Discriminative: Tests deep applied knowledge, trade-offs (e.g., labeling at scale), and senior-level thinking to separate strong candidates.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-488",
        "role_title": "Backend Engineer - Gaming Backend",
        "question": "# Technical Screening Question\n\n**Design a real-time state synchronization system for a multiplayer game where 100 players are in the same match. A player performs an action (e.g., moves their character), and all other players need to see that update within 100ms.**\n\n**Walk me through:**\n1. How would you structure the message flow from one client's action to all other clients?\n2. Where would you use Redis vs. PostgreSQL in this system?\n3. What's one potential issue with naive broadcasting, and how would you handle it?\n\n---\n\n## Why This Question Works\n\n\u2713 **Practical & Concrete** \u2014 Directly mirrors the role's core responsibility  \n\u2713 **Mid-Level Appropriate** \u2014 Doesn't require deep systems knowledge, but reveals architectural thinking  \n\u2713 **Tech Stack Validation** \u2014 Naturally incorporates Go, WebSocket, Redis, and PostgreSQL  \n\u2713 **Time-Bound** \u2014 Candidate can outline a solid approach in 3-4 minutes  \n\u2713 **Reveals Gaps** \u2014 Shows whether they've thought about latency, consistency, and scaling\n\n---\n\n## What",
        "scores": {
          "relevance": 7,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Tests core state synchronization but assumes unlisted tech (Go/WebSocket; Redis/PostgreSQL mentioned but not confirmed in role; -2 for extras). Clarity: Crystal clear, well-scoped with numbered parts and 100ms constraint. Discriminative: Excellent at probing architecture, trade-offs (e.g., naive broadcasting pitfalls), and DB choices to separate strong thinkers from basics.",
          "composite": 8.333333333333334
        }
      },
      {
        "role_id": "be-490",
        "role_title": "Senior Backend Engineer - Environment Management",
        "question": "# Technical Screening Question\n\n**\"Walk us through how you'd design a Kubernetes namespace isolation strategy for preview environments that need to be automatically cleaned up after 48 hours. What would you consider for resource quotas, network policies, and the TTL mechanism itself?\"**\n\n---\n\n## Why This Question Works\n\n**Practical & Real:** Directly mirrors the job's core responsibility of building an environment management system.\n\n**Multi-layered:** Tests understanding across several domains:\n- Kubernetes architecture (namespaces, resource quotas, network policies)\n- Infrastructure automation (TTL cleanup logic)\n- System design thinking (tradeoffs between isolation, cost, complexity)\n\n**Seniority-appropriate:** Expects a senior engineer to think holistically about constraints and edge cases, not just implement a feature.\n\n**Time-boxed:** Can be answered substantively in 2-5 minutes while allowing for follow-ups on specifics (e.g., \"How would you handle in-flight requests during cleanup?\" or \"Why network policies vs. service mesh?\").\n\n**Signals you're listening for:**\n- Understanding of resource limits and quota enforcement\n- Awareness of cleanup complexity (final",
        "scores": {
          "relevance": 10,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's core needs (namespace isolation, quotas, TTL cleanup) with exact Kubernetes tech. Clarity: Clear intent but lacks explicit constraints like timebox or answer format (-2 for 'design a system' style). Discriminative: Excellent at testing trade-offs, applied K8s knowledge, and edge cases to separate seniors from juniors; appropriately scoped for screening.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-491",
        "role_title": "Junior Backend Engineer - Read Replicas",
        "question": "# Screening Question\n\n**Scenario & Question:**\n\nYour application uses PostgreSQL with a read replica. You need to route a user's login request to the primary database, but route their \"view order history\" request to a read replica to reduce load.\n\nWrite pseudocode or a short Python example showing:\n1. How you'd structure the routing logic to direct queries to primary vs. replica\n2. One potential issue that could occur and how you'd handle it\n\n---\n\n## Why This Question Works\n\n\u2713 **Practical**: Directly mirrors the job responsibility (query routing)  \n\u2713 **Junior-appropriate**: Tests understanding of *why* read replicas are useful and basic routing patterns, not deep system design  \n\u2713 **Time-bound**: Can sketch a solution in 2-5 minutes  \n\u2713 **Reveals thinking**: Shows if candidate understands read-write separation, and whether they think about edge cases (e.g., replication lag where users see stale data)  \n\u2713 **Tech-relevant**: Uses Python + PostgreSQL context from the stack\n\n---\n\n## What You're Looking For\n\n**Good signals:**\n- Routes writes to primary",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's core focus on read replica routing and replication lag (no red flags, directly tests PostgreSQL context). Clarity: Crystal clear scenario, well-scoped for screening with numbered asks (minor -1 for lacking explicit time/format constraint). Discriminative: Strong separation via applied routing logic + edge case reasoning (e.g., lag handling), reveals junior-level trade-offs beyond recall.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-493",
        "role_title": "Staff Engineer - Reliability Standards",
        "question": "# Screening Question\n\n**Describe a time when you designed or implemented a production readiness standard or checklist for a team. Walk me through:**\n\n1. **What specific reliability gaps or incidents** prompted you to create it?\n2. **What 3-4 key criteria did you include**, and why those over others?\n3. **How did you handle resistance or adoption challenges** from engineering teams?\n4. **What metrics or signals told you it was actually working?**\n\n---\n\n## Why This Question Works\n\n\u2705 **Practical & Scoped** \u2013 Tests real-world experience with tangible artifacts (standards/checklists), not theoretical SRE knowledge\n\n\u2705 **Staff-Level Signal** \u2013 Distinguishes between someone who *follows* standards vs. someone who *designs and drives adoption* of them across teams\n\n\u2705 **Reveals Key Competencies:**\n- Diagnosis of reliability problems\n- Prioritization and decision-making\n- Stakeholder influence and change management\n- Measurement and iteration mindset\n\n\u2705 **Conversational** \u2013 Opens natural follow-ups on specific choices (observability, deployment safety, runbook quality, etc",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 10,
          "reasoning": "Directly tests core role responsibilities (defining reliability standards, production readiness reviews, incident frameworks) with behavioral depth on design, adoption, and measurement. Crystal clear structure with numbered prompts; highly discriminative for staff-level SRE experience distinguishing implementers from leaders. Minor subtract for bundled sub-questions but well-scoped overall.",
          "composite": 9.666666666666666
        }
      },
      {
        "role_id": "be-492",
        "role_title": "Backend Engineer - CD Pipelines",
        "question": "# Screening Question\n\n**Describe how you would structure a GitOps-based CD pipeline for promoting an application across dev \u2192 staging \u2192 production environments using ArgoCD. Walk us through your approach to handling approval gates and rollbacks.**\n\n---\n\n## Evaluation Rubric\n\n**Strong Answer (Hire):**\n- Explains separate ArgoCD Application manifests per environment\n- Mentions Git as source of truth and how promotion works (e.g., updating image tags in Git)\n- Describes approval mechanisms (manual sync, pull request reviews, or notification integrations)\n- Addresses rollback strategy (Git history, previous commits, or ArgoCD sync to prior state)\n- Shows awareness of practical concerns (drift detection, secrets management)\n\n**Acceptable Answer (Proceed):**\n- Outlines basic environment separation in ArgoCD\n- Explains Git-driven promotion workflow\n- Mentions one approval/rollback mechanism\n- May lack depth on operational edge cases\n\n**Weak Answer (Pass):**\n- Vague about ArgoCD mechanics or how Git triggers deployments\n- No clear approval or rollback strategy\n- Confuses GitOps with traditional CI/",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core GitOps CD pipelines, multi-environment promotion, approvals, and rollbacks with ArgoCD (exact match to role; no red flags). Clarity: Crystal clear and well-scoped for screening, minor deduction for no explicit time/format constraints. Discriminative: Excellent separation via trade-offs (approvals, rollbacks, drift), supported by rubric; not trivial recall or overly broad.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-495",
        "role_title": "Senior Backend Engineer - Audit Logging",
        "question": "# Screening Question\n\n**Design an audit log entry that must be tamper-proof and queryable. Walk me through:**\n\n1. **What data would you include** in each audit log entry beyond the obvious (who, what, when)?\n2. **How would you detect tampering** if someone modified a log entry in the database?\n3. **What's the tradeoff** between immutability guarantees and query performance on large datasets?\n\n**Follow-up:** If you had to choose between storing logs in PostgreSQL vs. ClickHouse for this use case, what factors would drive your decision?\n\n---\n\n## Why This Question Works\n\n\u2705 **Practical & Specific** \u2014 Tests real decisions they'd make on day one (hashing chains, checksums, columnar vs. row storage)\n\n\u2705 **Senior-Level** \u2014 Expects understanding of tradeoffs, not just textbook answers (compliance needs vs. query speed)\n\n\u2705 **Security-Focused** \u2014 Directly assesses tamper-proof thinking without being a riddle\n\n\u2705 **Time-Appropriate** \u2014 Can answer core concept in 2-3 min, elaborate in",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core audit logging skills (tamper-proofing, querying, retention implications) for the role (-0 red flags). Clarity: Well-structured with numbered parts and scoped follow-up, unambiguous for screening. Discriminative: Probes trade-offs, applied security knowledge, and DB choice factors, strongly separating senior candidates who understand hashing/immutability vs. columnar storage.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-494",
        "role_title": "Backend Engineer - API Mocking",
        "question": "# Screening Question\n\n**Scenario:**\n\nYou're building an API mock for a payment service that needs to:\n1. Match requests by specific headers (e.g., `X-API-Key`) and request body fields\n2. Return different responses based on the matched request\n3. Simulate realistic delays and occasional failures\n\n**Question:**\n\nWalk me through how you would configure a WireMock stub to handle a POST request to `/api/payments` that:\n- Only matches when `X-API-Key` header is present AND the request body contains `\"amount\": 100`\n- Returns a success response (HTTP 200) with a transaction ID\n- Returns a failure response (HTTP 400) for requests with `\"amount\": 0`\n\nWhat challenges might you encounter if you later needed to verify that a client called this endpoint with the correct payload during testing?\n\n---\n\n## What This Assesses\n\n\u2705 **Practical WireMock knowledge** \u2013 Request matching strategies and stub configuration  \n\u2705 **API mocking reasoning** \u2013 Understanding when/why to use specific matching rules  \n\u2705 **Contract testing awareness** \u2013 Recognizing the need for verification",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 8,
          "reasoning": "Relevance: Directly tests WireMock for API mocking, core to role's request matching/response templating; minor deduct for not explicitly covering contract verification (-1). Clarity: Precise scenario, unambiguous matching/response specs, well-scoped. Discriminative: Requires applied WireMock config knowledge and foresight on verification challenges (e.g., statefulness, assertions); good separation but not elite trade-off depth.",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-496",
        "role_title": "Junior Backend Engineer - Model Serving",
        "question": "# Screening Question\n\n**You need to create a FastAPI endpoint that accepts an image, runs it through a pre-trained ML model, and returns predictions. The model takes 2 seconds to load from disk, but your endpoint might receive multiple requests per second.**\n\n**Walk me through:**\n1. How would you avoid reloading the model on every request?\n2. What would happen if two requests arrive simultaneously and hit your endpoint?\n3. How would you handle a request that times out while waiting for model inference?\n\n---\n\n## Why This Works\n\n\u2705 **Practical**: Tests real deployment scenarios (model lifecycle, concurrency, timeouts)  \n\u2705 **Appropriate Level**: Junior engineer should know basic patterns; doesn't require advanced optimization  \n\u2705 **Reveals Thinking**: Shows understanding of FastAPI startup events, async/concurrency, and basic operational concerns  \n\u2705 **Conversational**: Naturally leads to follow-ups (model size, batching, monitoring) without being yes/no\n\n## What You're Looking For\n\n- **Strong answer**: Loading model in startup event, async handlers, request timeouts via `timeout` parameter\n- **Good answer",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core ML model deployment skills (loading, concurrency) for the entry-level API role, matches FastAPI implicitly via context (-0 red flags). Clarity: Well-structured with 3 focused sub-questions, unambiguous scope for screening (-0 red flags). Discriminative: Probes applied knowledge of startup events, async handling, and timeouts with trade-offs, strongly separates candidates revealing practical thinking.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-497",
        "role_title": "Backend Engineer - Payout Systems",
        "question": "# Technical Screening Question\n\n**You're building a payout system that needs to process 100,000 seller payouts daily. Each payout requires:**\n- Validating the seller's bank account against an external bank API\n- Calculating final amounts (accounting for fees and adjustments)\n- Storing the transaction record\n- Publishing an event for downstream systems\n\n**Walk me through your approach:**\n1. How would you structure this to avoid bottlenecks?\n2. What would you consider the critical path vs. non-critical operations?\n3. How would you handle failures in the bank validation API?\n\n---\n\n## Why This Works\n\n\u2705 **Practical**: Mirrors real payout system design decisions  \n\u2705 **Mid-level appropriate**: Requires understanding of batch processing, system design, and fault tolerance\u2014not deep expertise  \n\u2705 **Tech-relevant**: Opens discussion on async processing (Kafka), caching (Redis), and database design (PostgreSQL)  \n\u2705 **Time-bound**: Can be answered in 3-4 minutes with follow-ups  \n\u2705 **Reveals thinking**: Shows whether they understand concurrency, resilience",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core payout system skills (batch processing, validation, reconciliation) matching role; minor ding for assuming unlisted tech like Kafka/Redis (-1). Clarity: Well-structured with clear scenario, numbered parts, scoped for screening. Discriminative: Probes trade-offs in bottlenecks, critical path, failures\u2014reveals deep system design thinking and resilience understanding.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-499",
        "role_title": "Principal Engineer - Search Platform",
        "question": "# Screening Question\n\n**\"Tell me about a time you designed or significantly improved a search infrastructure that handled scale challenges. What were the bottlenecks you identified, how did you prioritize them, and what was the outcome? If you were advising a team on whether to invest in a new search platform versus optimizing their existing one, what factors would influence that decision?\"**\n\n---\n\n## Why This Works\n\n**Tests practical knowledge:**\n- Real experience with search systems at scale\n- Ability to diagnose performance issues (indexing, query latency, throughput)\n- Understanding of tradeoffs in search architecture\n\n**Appropriate for Principal level:**\n- Requires strategic thinking beyond just technical implementation\n- Assesses mentorship/advisory capability (\"advising a team\")\n- Evaluates decision-making frameworks, not just tools\n\n**Reveals key competencies:**\n- Search platform expertise (core requirement)\n- Systems thinking (bottleneck identification and prioritization)\n- Leadership maturity (guiding technology decisions)\n- Communication (explaining complex tradeoffs clearly)\n\n**Realistic time frame:** 3-4 minutes for a strong answer\n\n**Red flags to listen for:**",
        "scores": {
          "relevance": 9,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core search platform strategy, scale challenges, and advisory decision-making from role description (-1 for no specific tech stack mention). Clarity: Clear behavioral + hypothetical structure, well-scoped for screening (-2 for bundling two related but distinct questions). Discriminative: Strong separation via real experience, bottleneck analysis, prioritization, tradeoffs, and strategic factors; reveals depth vs superficial answers.",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-498",
        "role_title": "Senior Backend Engineer - Profiling Infrastructure",
        "question": "# Technical Screening Question\n\n**You're implementing continuous profiling for a Go microservice that processes 10,000 requests/second. The profiling data is being stored in ClickHouse, but engineers are reporting that flame graph queries take 30+ seconds to load when comparing profiles across a 1-hour window.**\n\n**Walk me through how you'd approach diagnosing this performance issue. What are the key factors you'd investigate, and what optimizations might you consider\u2014both at the profiling collection level and the storage/query level?**\n\n---\n\n## Why This Question Works\n\n\u2713 **Practical & Real:** Reflects an actual senior-level challenge in profiling infrastructure  \n\u2713 **Depth:** Tests understanding across the full stack (Pyroscope \u2192 ClickHouse \u2192 Grafana frontend)  \n\u2713 **Seniority-Appropriate:** Expects architectural thinking, not just syntax knowledge  \n\u2713 **Time-Bounded:** Can explore 2-5 minutes; natural stopping points at each layer  \n\u2713 **Open-Ended:** Reveals how they prioritize (sampling rates vs. schema vs. indexing strategy)",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (profiling, flame graphs, storage optimization in ClickHouse) for high-throughput Go services; minor ding for assuming Pyroscope/Grafana not explicitly listed (-1). Clarity: Crystal clear scenario with specific constraints (10k req/s, 1hr window, 30s queries), well-scoped. Discriminative: Excellent at separating seniors via trade-offs (sampling, schema, indexing, collection optimizations); reveals prioritization and depth without being too broad.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-500",
        "role_title": "Staff Engineer - Streaming Architecture",
        "question": "# Screening Question\n\n**You're designing a real-time notification system that needs to fan out a single user event to potentially thousands of subscribers across multiple geographic regions. The system uses Kafka as the event source and must support both WebSocket connections and traditional HTTP polling clients.**\n\n**Walk me through how you'd approach the architecture\u2014specifically:**\n1. **How would you structure the Kafka topic(s) and consumer groups?**\n2. **Where would you use Redis, and for what specific purposes?**\n3. **What delivery guarantee would you target, and what trade-offs does that involve?**\n\n**Feel free to make reasonable assumptions about scale, latency requirements, or failure modes.**\n\n---\n\n## Why This Works\n\n- **Practical depth**: Tests whether they've actually designed multi-consumer streaming systems, not just used them\n- **Appropriate scope**: A Staff engineer should reason through infrastructure tradeoffs (exactly-once vs. at-least-once, centralized vs. distributed fan-out, caching strategy)\n- **Tech stack coverage**: Naturally incorporates Kafka, Redis, and real-time concerns without feeling forced\n- **Reveals thinking**: Their assumptions and tradeoffs",
        "scores": {
          "relevance": 7,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core fan-out and streaming skills from role, but penalizes -2 for mentioning Redis (not in role description) and -1 for generic design feel. Clarity: Crystal clear, well-scoped with specific numbered points and assumption guidance. Discriminative: Excellent at probing trade-offs, applied architecture knowledge, and reasoning depth to separate strong Staff engineers.",
          "composite": 8.333333333333334
        }
      }
    ]
  },
  "baseline": {
    "model": "baseline",
    "num_samples": 100,
    "avg_relevance": 8.5,
    "avg_clarity": 8.04,
    "avg_discriminative": 8.48,
    "avg_composite": 8.340000000000003,
    "results": [
      {
        "role_id": "be-401",
        "role_title": "Backend Engineer - Training Infrastructure",
        "question": "\"Design a scalable and fault-tolerant system to manage distributed machine learning training jobs using Ray and Kubernetes. Your solution should handle job scheduling, GPU resource allocation, and recovery from failures. Provide a high-level architecture, including how Ray clusters are managed, how jobs are scheduled, and how failures are detected and recovered. Explain how you would ensure scalability and fault tolerance across a growing number of training jobs and GPUs.\"",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's core needs (distributed ML infra, scheduling, GPU allocation, orchestration) using relevant tools (Ray, K8s); no red flags. Clarity: Crystal clear, well-scoped high-level design with specific components; minor deduction for lacking explicit time/format constraints. Discriminative: Tests deep applied knowledge, trade-offs in scalability/fault-tolerance, architecture decisions; strong separation of strong vs weak candidates; not too broad for screening.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-402",
        "role_title": "Backend Engineer - Model Deployment",
        "question": "\"When deploying a machine learning model using KServe, how would you design a deployment strategy that includes automated rollback in case of a failed inference request, and what role does Redis play in this process?\"",
        "scores": {
          "relevance": 4,
          "clarity": 7,
          "discriminative": 7,
          "reasoning": "Relevance: Low due to KServe and Redis not mentioned in role (red flag -2, generic -3); tests deployment/rollback but wrong specific tech. Clarity: Clear intent and well-formed, but lacks explicit constraints (-1 for minor jargon). Discriminative: Good test of applied design with trade-offs, differentiates ML deployment expertise.",
          "composite": 6.0
        }
      },
      {
        "role_id": "be-403",
        "role_title": "Backend Engineer - Inference Optimization",
        "question": "\"Design a Python script that uses TensorRT to optimize a model for inference latency. The script should:\n- Load a PyTorch model (e.g., ResNet50) and convert it to a TensorRT engine.\n- Apply dynamic batching to reduce GPU memory usage.\n- Include a simple benchmark to measure inference latency before and after optimization.\n- Output a report showing the latency improvement and GPU memory per batch.\"",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core inference optimization skills (quantization implied via TensorRT, batching, GPU memory) for latency-sensitive models; minor ding as role doesn't explicitly list TensorRT but fits perfectly (-1 red flag avoided). Clarity: Crystal clear with specific requirements, well-scoped steps, no ambiguity. Discriminative: Requires applied knowledge of model conversion, optimization techniques, benchmarking, and trade-offs in batching/memory\u2014strong separation of strong vs weak candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-404",
        "role_title": "Senior Backend Engineer - Feature Platform",
        "question": "\"Design a feature pipeline for a real-time feature serving system using Feast and Redis. The pipeline should support both online and offline feature computation. Explain how you would structure the feature store, how you would handle feature versioning, and how you would ensure consistency between online and offline feature values. Include considerations for feature discovery and how you would monitor system health.\"",
        "scores": {
          "relevance": 9,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core feature platform skills (computation, serving, discovery) with Feast (feature store standard); minor ding for specifying Redis (not in role desc, -2) but still highly relevant. Clarity: Well-formed and unambiguous, but 'design a pipeline' lacks explicit time/format constraints (-2). Discriminative: Excellent at probing trade-offs (versioning, consistency), architecture, monitoring; distinguishes deep Feast expertise from superficial knowledge.",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-405",
        "role_title": "Senior Backend Engineer - Model Monitoring",
        "question": "\"Design a drift detection system for a production ML model using Python and Prometheus/Grafana. The system should detect data drift, model drift, and concept drift. Explain how you would collect, store, and visualize the metrics. Include a high-level architecture and at least one concrete example of how you'd implement a drift detection algorithm in Python (e.g., Kullback-Leibler divergence, Kolmogorov-Smirnov test, or a statistical test).\"",
        "scores": {
          "relevance": 9,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core role skills (drift detection, monitoring, alerting via Prometheus/Grafana); minor ding for not explicitly covering performance tracking/alerting (-1). Clarity: Well-scoped with specific drifts, components, and example required; lacks minor constraints like time complexity (-1, -1 for design scope). Discriminative: Tests architecture, metrics pipeline, visualization, and concrete algo implementation with trade-offs, strongly separates skilled ML engineers.",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-406",
        "role_title": "Senior Backend Engineer - LLM Serving",
        "question": "\"Design and implement a system to optimize token-level batching in vLLM for a high-throughput LLM serving environment. The system should handle dynamic request arrivals, manage KV cache efficiently, and support streaming responses. Provide a high-level design including key components, and describe how you would evaluate its performance and scalability.\"",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core role responsibilities (batching optimization, KV cache, streaming) and specifies vLLM from LLM serving context. Clarity: Well-scoped high-level design with clear requirements, minor deduction for lacking explicit time/format constraints. Discriminative: Tests applied system design, trade-offs in dynamic batching/KV management, and evaluation\u2014strong separation of strong vs weak candidates.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-407",
        "role_title": "Staff Backend Engineer - ML Infrastructure",
        "question": "\"Design a scalable and fault-tolerant ML training pipeline using Ray, Kubernetes, and Spark. Your design should include:  \n- A high-level architecture diagram (text-based or ASCII)  \n- How you would handle data preprocessing and feature engineering  \n- How you would manage training jobs and distributed execution  \n- How you would ensure fault tolerance and recovery  \n- How you would monitor and optimize training jobs for cost and performance\"",
        "scores": {
          "relevance": 7,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Tests core ML infra skills (pipelines, scaling, fault tolerance, optimization) but assumes unmentioned tech (Ray, Spark) and ignores serving/cost strategy focus (-2 for tech not in role). Clarity: Well-structured with specific components, minor vagueness on diagram format and scope. Discriminative: Excellent at probing trade-offs, architecture, and applied ML ops knowledge, strongly separates candidates.",
          "composite": 8.0
        }
      },
      {
        "role_id": "be-408",
        "role_title": "Junior Backend Developer - Health Endpoints",
        "question": "\"Design and implement a health check endpoint in Go that returns a JSON response indicating the status of liveness, readiness, and metrics. The endpoint should:\n- Return a 200 OK status with a JSON body when healthy\n- Return a 503 Service Unavailable status when unhealthy\n- Include a `status` field (value: 'healthy' or 'unhealthy')\n- Include a `liveness` field (value: 'healthy' or 'unhealthy') \n- Include a `readiness` field (value: 'healthy' or 'unhealthy')\n- Include a `metrics` field (value: 'available' or 'unavailable') \n- Be implemented in a minimal Go HTTP server (no external dependencies)\n- Include error handling for unexpected issues\n- Return 503 when the system is unhealthy (e.g., due to a failed internal check)",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 8,
          "reasoning": "Relevance: Directly tests core role skills (liveness/readiness/metrics endpoints) in Go (implied by role context), minor deduct for not explicitly stating Go in question (-1). Clarity: Crystal clear specs, well-scoped for screening, no bundling or ambiguity. Discriminative: Tests applied HTTP/JSON/Go skills with error handling and state logic, distinguishes solid entry-level devs from weak ones; slightly implementation-heavy but feasible.",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-409",
        "role_title": "Junior Backend Engineer - File Upload",
        "question": "Design and implement a FastAPI endpoint that allows users to upload a file. The endpoint should:\n1. Accept a multipart form with `file` and `metadata` fields.\n2. Validate the file (ensure it's not empty and has a valid MIME type).\n3. Store the file in AWS S3 using a unique key (e.g., `user/{user_id}/file_{timestamp}.ext`).\n4. Store metadata in a PostgreSQL database.\n5. Return a success response with the file's URL and stored metadata.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core file upload API skills, multipart handling, validation, S3 storage, and DB integration from role (-1 for minor assumption of user_id source, not generic). Clarity: Precise requirements with clear fields, validation, storage, and response specs. Discriminative: Requires integrating FastAPI, AWS SDK, SQLAlchemy/psycopg2, validation logic, error handling, and trade-offs like key generation/security\u2014strong separation of capable entry-level engineers.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-410",
        "role_title": "Backend Engineer - Bulk Operations",
        "question": "\"Design a Go backend API endpoint to handle bulk data imports for a system that manages user profiles. The endpoint should support:\n- Accepting a batch of user profile updates via a JSON array\n- Ensuring idempotency (no duplicate processing of the same user updates)\n- Handling partial success (some updates may succeed, others may fail)\n- Processing the data in a background job via Kafka\n- Using Redis to track processed user IDs to ensure idempotency\n- Returning a detailed response with success/failure counts and error details for each update",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (bulk ops, partial success, idempotency) with specified tech (Go, Kafka, Redis); minor ding for assuming user profiles. Clarity: Crystal clear with precise requirements and scope. Discriminative: Requires applied knowledge of async processing, idempotency patterns, error handling, and tech integration, forcing trade-offs and strong separation.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-411",
        "role_title": "Backend Engineer - Admin APIs",
        "question": "\"Design and implement a secure admin API endpoint in Python using FastAPI that allows an admin user to create a new user account. The endpoint must:\n- Require a valid admin token (JWT) for access\n- Validate the admin token using a secret key\n- Accept a user\u2019s email and password (hashed using bcrypt)\n- Store the user in PostgreSQL with a unique constraint on email\n- Prevent duplicate email creation\n- Log all admin actions (user creation) to a Redis cache with a structured log entry (timestamp, user email, admin token ID, action type), and persist the log to a PostgreSQL audit table\n- Include error handling for invalid tokens, duplicate emails, and other common issues",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core admin API skills (auth, auditing, workflows) and exact tech stack (FastAPI, JWT, bcrypt, PostgreSQL, Redis) from role; minor ding for not explicitly mentioning privileged access beyond JWT (-1). Clarity: Crystal clear with precise requirements and error handling specified; well-scoped for screening. Discriminative: Excellent separation via applied knowledge of security, DB constraints, logging pipeline, and error handling; tests trade-offs in auth/logging without being too broad.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-412",
        "role_title": "Backend Engineer - Analytics APIs",
        "question": "Design and implement a Go-based analytics API that serves time-series data from ClickHouse with caching using Redis. Your solution should support efficient aggregation queries (e.g., daily, hourly) and handle data freshness and cache invalidation. Describe your design decisions, including how you handle cache invalidation, query performance, and data consistency.",
        "scores": {
          "relevance": 7,
          "clarity": 7,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core time-series, aggregation, and caching skills but assumes unlisted tech (Go, ClickHouse, Redis) (-2). Clarity: Clear intent but lacks scoping constraints like time/format (-1). Discriminative: Excellent at probing trade-offs in caching, invalidation, performance, and consistency, strongly separating candidates.",
          "composite": 7.666666666666667
        }
      },
      {
        "role_id": "be-413",
        "role_title": "Senior Backend Engineer - API Gateway Logic",
        "question": "Design and implement a Lua script in Envoy that validates incoming HTTP requests and transforms the request headers based on a custom business rule. The rule is:  \n- If the `X-Client-Id` header is present and starts with `PROD-`, then:\n  - Add a `X-Environment: production` header.\n  - Strip the `X-Client-Id` header and set it to `PROD-<client-id>` (e.g., `PROD-123`).\n- If the `X-Client-Id` header is present and starts with `TEST-`, then:\n  - Add a `X-Environment: staging` header.\n  - Strip the `X-Client-Id` header and set it to `TEST-<client-id>` (e.g., `TEST-123`).\n- If the `X-Client-Id` header is missing, do nothing.\n- All other headers must be preserved.",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core Envoy/Lua skills for API gateway extensions, request transformation, and custom routing rules. No red flags. Clarity: Crystal clear with precise business rules and constraints; minor ambiguity on 'strip and set' intent but well-scoped. Discriminative: Requires applied Lua/Envoy knowledge, header manipulation, conditionals, and edge cases for strong separation; not pure recall.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-414",
        "role_title": "Senior Backend Engineer - Long-Polling",
        "question": "Design and implement a long-polling endpoint in Go that efficiently handles concurrent clients, manages connection timeouts, and gracefully degrades when Redis is unavailable. The endpoint should support:\n1. A simple `POST /poll` that accepts a `pollId` and returns a message or `204 No Content` if no message is available.\n2. Connection timeout handling (e.g., 30 seconds) with automatic reconnection on timeout.\n3. Timeout cleanup after 30 seconds of inactivity.\n4. Fallback to polling every 10 seconds if Redis is unreachable (use a simple retry mechanism).\n5. Connection management using Redis to track active clients and avoid duplicate polling.\n6. Use Redis as a message store (store messages in Redis with TTL of 300 seconds).\n7. Use PostgreSQL to store client session metadata (e.g., `poll_id`, `client_id`, `last_active`, `status`).\n8. Implement a simple health check at `/health` that returns 200 if both Redis and PostgreSQL are reachable.",
        "scores": {
          "relevance": 4,
          "clarity": 3,
          "discriminative": 2,
          "reasoning": "Relevance: Superficially mentions Go and long-polling but heavily diverges into Redis/PostgreSQL management, health checks, and full system design beyond core role focus (-3 generic design, -2 extras not in role). Clarity: Multiple bundled requirements (8 points) make it ambiguous and unscoped for screening (-2); no constraints on implementation depth/format (-2). Discriminative: Far too broad (>10min, full system impl) for screening, tests everything at once with weak separation (-2).",
          "composite": 3.0
        }
      },
      {
        "role_id": "be-415",
        "role_title": "Senior Backend Engineer - Multipart APIs",
        "question": "Design and implement a resumable upload system using FastAPI, Python, and S3. The system should support chunked uploads, store upload metadata in S3, and allow resuming from any point. Include a simple example of how a client would initiate and resume an upload.",
        "scores": {
          "relevance": 10,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's core focus on resumable uploads, chunk management, and S3 (core tech stack). Clarity: Clear intent and scope, but lacks explicit constraints (e.g., chunk size limits, time limits for screening). Discriminative: Tests deep applied knowledge of APIs, state management, and trade-offs in resumable systems; strong separation between good and weak candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-416",
        "role_title": "Staff Backend Engineer - External APIs",
        "question": "\"Design a scalable and secure external API using Go and OpenAPI, with Kong as the gateway, deployed on Kubernetes. Your design should include key components, security considerations, rate limiting, logging, and observability. Provide a high-level architectural overview, and explain how you would implement API monetization for partners. Include how you'd structure the API to support partner enablement and integration patterns.\"",
        "scores": {
          "relevance": 9,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core role skills (API strategy, monetization, partner enablement, integration patterns) with relevant tech (Go, OpenAPI, Kong, K8s); minor ding for assuming specific tools not in desc (-1). Clarity: Well-scoped high-level design with clear components listed, but lacks time/format constraints (-1) and bundles multiple aspects. Discriminative: Excellent at testing applied architecture, trade-offs (security, scaling, monetization), and role-specific strategy, strongly separating strong candidates.",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-417",
        "role_title": "Junior Backend Developer - Event Sourcing",
        "question": "\"Design a simple event handler for a `UserCreated` event in an event-sourced system using Kafka and PostgreSQL. The event should be consumed by a handler that persists the user's state in a PostgreSQL database. Implement the handler class, describe how it would handle state transitions (e.g., from `UNKNOWN` to `ACTIVE`), and explain how you\u2019d ensure data consistency between Kafka and PostgreSQL.\"",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core event handling, state management, and persistence for event sourcing role (-1 for specifying Kafka/PostgreSQL not in role desc). Clarity: Well-scoped design with specific event, tech, and consistency focus. Discriminative: Requires applied knowledge of handlers, state transitions, and exactly-once semantics, distinguishing strong candidates via trade-offs.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-418",
        "role_title": "Junior Backend Engineer - Service Clients",
        "question": "> \"Design and implement a gRPC client in Go that supports automatic retry with backoff and circuit breaker pattern. The client should handle transient errors (e.g., connection timeout, network errors) and gracefully degrade when the service is unavailable. Use Protobuf for the service interface and Docker to containerize the client. Provide a minimal working example with a simple service interface and a client that demonstrates retry and circuit breaker behavior.\"",
        "scores": {
          "relevance": 3,
          "clarity": 6,
          "discriminative": 7,
          "reasoning": "Relevance: Superficially mentions tech stack (Go, gRPC) but demands full implementation of core skills (retry, circuit breaker) PLUS unrelated extras (Protobuf service, Docker containerization) not in role; generic design question (-3), tests minor/unlisted tech (-2). Clarity: Understandable but vague on retry/backoff params, circuit breaker thresholds, expected depth; multiple components bundled (-2), missing constraints. Discriminative: Good test of applied patterns with trade-offs, but overly broad for screening (>10min effort).",
          "composite": 5.333333333333333
        }
      },
      {
        "role_id": "be-419",
        "role_title": "Backend Engineer - Retry Logic",
        "question": "Imagine you're implementing a retry mechanism for a distributed service that handles order processing. The service may fail due to transient issues like network latency or database timeouts. You need to implement a retry strategy that uses exponential backoff with jitter, and includes a retry budget to prevent infinite retries on persistent failures.",
        "scores": {
          "relevance": 10,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's core focus on retry infrastructure, exponential backoff, jitter, and retry budgets. Clarity: Clear scenario and requirements, but lacks explicit constraints (e.g., max retries, time limits, code format). Discriminative: Strong test of applied knowledge and trade-offs in retry design, distinguishes candidates who understand distributed systems retries from those with superficial knowledge.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-420",
        "role_title": "Backend Engineer - Graceful Shutdown",
        "question": "*In a Kubernetes environment, how would you implement a graceful shutdown for a Go gRPC server that handles in-flight requests and supports connection draining, especially when receiving a SIGTERM signal?*",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core role requirements (graceful shutdown, connection draining, in-flight requests, SIGTERM) with exact tech stack (Kubernetes, Go, gRPC). No red flags. Clarity: Precise and well-scoped for screening; minor deduction as it lacks explicit time/format constraints. Discriminative: Requires applied knowledge of signal handling, gRPC lifecycle, and K8s deployment patterns, testing trade-offs effectively without being trivial or overly broad.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-421",
        "role_title": "Senior Backend Engineer - Security Automation",
        "question": "*You're tasked with creating a Python script that automates the rotation of database secrets stored in HashiCorp Vault. The script should:*\n1. *Authenticate to Vault using a Kubernetes service account (Kubernetes `ServiceAccount` with `vault` role bound via `RoleBinding`)*\n2. *Read a list of database secrets from a configuration file (e.g., JSON or YAML)*\n3. *For each secret, generate a new random password (12 characters, lowercase, alphanumeric) and rotate it in Vault*\n4. *Log the operation with timestamps and success/failure status*\n5. *Fail fast if any step fails, and output a human-readable error message*",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core security automation (secrets rotation in Vault) and Python scripting for cloud infra; minor ding as Vault auth is specific but fits role (-1). Clarity: Precise requirements with clear steps, auth method, constraints, and fail-fast policy. Discriminative: Requires applied knowledge of Vault API, K8s auth, error handling, and secure practices; distinguishes via trade-offs in auth/secrets handling.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-422",
        "role_title": "Junior Backend Engineer - API Testing",
        "question": "Write a pytest test for a FastAPI endpoint that returns a list of users. The endpoint should accept a query parameter `page` and `limit`, and return a JSON response with a `users` array and `total` count. Your test should:\n- Use `test_client` to make a request\n- Test the response structure and data\n- Include a fixture for the test database\n- Verify that the query parameters are correctly applied (e.g., page=1, limit=10)\n- Handle edge cases like invalid page or limit values (e.g., negative numbers, non-numeric)",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests pytest, FastAPI testing with test_client, fixtures, and query param handling\u2014core to API test writing role (-1 for not explicitly mentioning contract testing). Clarity: Precise requirements, well-scoped with specific actions and edge cases. Discriminative: Requires applied knowledge of fixtures, client usage, assertions, and edge case reasoning to separate capable entry-level testers.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-423",
        "role_title": "Staff Engineer - Incident Response Platform",
        "question": "> \"Design a system to manage on-call rotations for a team of 10 engineers, where each engineer is on-call for 5 days, then off for 3 days. The system must handle automatic rotation, provide real-time visibility into on-call schedules, and support manual overrides. It should be implemented in Go, with a PostgreSQL database to store schedules and a Slack API to notify engineers when their shift begins and ends. Explain your approach, including data model, how you'd handle edge cases (e.g., engineers on leave, shift overlaps), and how you'd implement the rotation logic.\"",
        "scores": {
          "relevance": 7,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Tests core on-call optimization skill but too narrowly focused on rotations (minor aspect) vs broader incident response/SLO tooling; specifies unmentioned Go/PostgreSQL/Slack (-2). Clarity: Well-scoped with specific constraints/tech, minor ambiguity on full implementation depth. Discriminative: Excellent at probing design, data modeling, edge cases, and logic trade-offs, strongly separates candidates.",
          "composite": 8.0
        }
      },
      {
        "role_id": "be-424",
        "role_title": "Backend Engineer - Message Serialization",
        "question": "\"Design a message serialization system for a distributed system that uses Kafka as the messaging backbone. The system must support schema evolution with backward and forward compatibility, using Avro with Schema Registry. Handle schema validation at both producer and consumer sides. Provide a concrete example of how a schema change would be handled when a new field is added to a message, and explain how the system ensures backward compatibility. Also, describe how you would validate schemas at runtime and what monitoring or alerting strategies you would implement to detect schema mismatches.\"",
        "scores": {
          "relevance": 9,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core schema evolution, compatibility, and validation skills; Kafka/Avro/Schema Registry are spot-on for message serialization infra (-1 for assuming Kafka not explicitly listed). Clarity: Well-formed and unambiguous, but multiple components bundled (-2). Discriminative: Excellent on trade-offs, concrete examples, runtime validation, and monitoring; strong separation of deep vs shallow knowledge.",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-425",
        "role_title": "Senior Backend Engineer - Graph Analytics",
        "question": "Design a scalable graph analytics pipeline to compute user-based recommendations using Neo4j and Apache Spark. The pipeline should handle a billion-edge dataset and support real-time updates. Describe how you would structure the pipeline, the data flow, and how you would optimize traversal queries for performance and scalability. Include considerations for handling real-time updates and potential bottlenecks.",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's graph analytics, social/rec pipelines, billion-edge scale, traversal optimization, and implied tech (Neo4j/Spark common for graphs). No red flags. Clarity: Well-scoped with specific tech/data size/updates; minor deduction as no explicit time/format constraints. Discriminative: Probes deep applied knowledge of pipeline design, trade-offs (real-time vs batch, bottlenecks), optimization\u2014strong separation of strong vs weak candidates.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-426",
        "role_title": "Junior Backend Engineer - DevOps Scripting",
        "question": "Write a Bash script that builds and pushes a Docker image to a private Docker registry (e.g., Docker Hub or AWS ECR). The script should:\n- Accept a Docker image name (e.g., \"myapp:latest\") as a command-line argument\n- Validate that the image name is provided and has a valid format (e.g., contains a tag)\n- Use `docker build` to build the image from a Dockerfile in the current directory\n- Push the built image to a private Docker registry using `docker push`\n- Include error handling for common issues (e.g., missing Dockerfile, failed build, failed push)\n- Output a success or failure message at the end",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core DevOps automation skills (Bash scripting, Docker builds/push, private registries) essential for deployment scripts/CI pipelines; minor ding as role doesn't explicitly list private registries (-1). Clarity: Crystal clear with specific requirements, validation, and error handling; well-scoped for screening. Discriminative: Requires applied knowledge of Bash args/parsing, Docker CLI, validation, and error handling; distinguishes those who can write robust scripts from superficial knowledge.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-427",
        "role_title": "Backend Engineer - Feature Store",
        "question": "\"Design a feature store pipeline that ingests streaming data from Kafka, computes features using a Python function, stores them in Redis for real-time serving, and persists them to PostgreSQL for historical tracking. The pipeline should support feature versioning and handle data drift detection. Explain how you would implement feature versioning and data drift detection in this system.\"",
        "scores": {
          "relevance": 9,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core role skills (feature store, computation, versioning, real-time serving) with relevant tech; minor ding for assuming Kafka/Redis/PostgreSQL not explicitly listed (-1). Clarity: Well-scoped design question with specific components, but lacks explicit constraints like scale or time (-2). Discriminative: Excellent at testing applied ML infra knowledge, trade-offs in versioning/drift, distinguishes strong candidates.",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-428",
        "role_title": "Senior Backend Engineer - Payment Orchestration",
        "question": "*Design a failover strategy for a payment orchestration system that routes transactions to multiple payment providers (e.g., Stripe, PayPal, Braintree). The system must ensure transaction success, minimize cost, and maintain low latency. Consider provider availability, transaction cost, and success rates. Provide a step-by-step plan including how you would evaluate provider health, dynamically route transactions, and handle failures. Include considerations for cost optimization and transaction latency.*",
        "scores": {
          "relevance": 9,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core role skills (failover, routing, cost optimization, success rates) with relevant providers; minor generic feel but no red flags (-0). Clarity: Well-scoped with clear requirements and step-by-step ask, but 'design' lacks explicit time/format constraints (-1, -1 red flag). Discriminative: Excellent at probing trade-offs (availability/cost/latency), dynamic routing, health checks\u2014separates deep thinkers from superficial answers.",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-429",
        "role_title": "Backend Engineer - Log Aggregation",
        "question": "**\"Design a scalable log aggregation pipeline using Go and Kafka to ingest, parse, and store logs in ClickHouse. Include key considerations for performance, reliability, and observability.\"**",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly matches role's core focus on high-volume log pipelines (millions/sec), parsing/enrichment/retention; uses relevant tech (Go, Kafka, ClickHouse) with no red flags. Clarity: Well-scoped design question with specific components and considerations; minor deduction for lacking explicit time/format constraints. Discriminative: Requires deep trade-offs in scalability/performance/reliability for high-throughput systems, strongly separates strong candidates.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-430",
        "role_title": "Junior Backend Engineer - Search Indexing",
        "question": "You're building a search index for a product catalog with 100,000 products. Each product has a title, description, and price. You need to index these records into Elasticsearch using Python. How would you design the indexing pipeline to ensure efficient, reliable, and scalable performance?",
        "scores": {
          "relevance": 7,
          "clarity": 6,
          "discriminative": 8,
          "reasoning": "Relevance: Tests core indexing skills and Elasticsearch (implied by search index role), but generic/not entry-level specific and no Python details in role (-1 generic, -2). Clarity: Clear intent but lacks constraints on time, batch size, error handling scope (-2 missing constraints). Discriminative: Good for applied pipeline design with trade-offs (efficiency/reliability/scalability), separates those understanding bulk indexing basics.",
          "composite": 7.0
        }
      },
      {
        "role_id": "be-431",
        "role_title": "Staff Engineer - Real-time Collaboration",
        "question": "Design a real-time collaboration system that supports multiple users editing a shared document simultaneously. The system must handle concurrent edits, resolve conflicts when users edit overlapping regions, and ensure that all users see the same content in real time. Use CRDTs to manage conflict resolution. You must support a simple document structure (e.g., a text document with line breaks and text segments). Describe your design choices, including how you would store the document state, how you would handle concurrent edits, and how you would resolve conflicts using a CRDT.",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's core focus on real-time collaboration, conflict resolution, and operational transforms via CRDTs (no red flags). Clarity: Crystal clear scope with simple document structure and specific design aspects requested; minor deduction as no explicit time/format constraints. Discriminative: Tests deep applied knowledge of CRDTs, trade-offs in concurrent editing, and system design choices, strongly separating strong architects from weaker candidates.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-432",
        "role_title": "Backend Engineer - Data Validation",
        "question": "\"Design and implement a data validation framework using Great Expectations to validate data from a PostgreSQL table (e.g., `sales` table) before loading it into S3. The validation should check for missing values, data type correctness, and statistical outliers (e.g., sales > 1000000). Include a minimal example of how this would be used in an Airflow DAG to trigger validation and fail the pipeline if any validation fails.\"",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core data validation (schema, stats, outliers) and pipeline integration with key tools (Great Expectations, PostgreSQL, S3, Airflow); minor ding as GE not explicitly listed but perfectly matches role focus (-1). Clarity: Crystal clear, well-scoped with specific table, checks, and Airflow integration; no bundling or ambiguity. Discriminative: Requires applied design/implementation knowledge, trade-offs in validation/outliers, and pipeline failure handling; strong separation of strong vs weak candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-433",
        "role_title": "Senior Backend Engineer - Platform APIs",
        "question": "\"Design a scalable, secure, and consistent service catalog API in Go using gRPC that allows developers to discover, provision, and manage platform services (e.g., databases, storage, compute). The API must support versioned service definitions, support both synchronous and asynchronous provisioning, and provide a way to list available services with filtering by category, region, and tags. Additionally, the API must support rate limiting and authentication via JWT tokens. Describe your design decisions, including how you would handle versioning, asynchronous provisioning, and security.\"",
        "scores": {
          "relevance": 9,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core role responsibilities (service catalog, provisioning APIs) with Go/gRPC matching platform API focus; minor ding for assuming gRPC specificity (-1). Clarity: Well-scoped with clear requirements, but lacks explicit time/format constraints for screening (-2). Discriminative: Excellent at probing trade-offs in versioning, async flows, security, and scalability, distinguishing strong API designers.",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-434",
        "role_title": "Principal Engineer - Database Strategy",
        "question": "\"Design a database strategy for a multi-region, globally distributed application using PostgreSQL, CockroachDB, Redis, and Kafka. Your strategy must include:  \n- A clear rationale for selecting each database technology (PostgreSQL, CockroachDB, Redis, Kafka)  \n- A detailed architecture for data replication, consistency, and availability across regions  \n- A plan for handling data migration from a monolithic PostgreSQL database to this distributed setup  \n- A discussion of operational excellence and monitoring for database performance and health  \n- A brief mention of how you would mentor junior engineers in database strategy and architecture\"",
        "scores": {
          "relevance": 4,
          "clarity": 8,
          "discriminative": 3,
          "reasoning": "Relevance: Tangentially related to core role (multi-region DB strategy) but generic and bundles unrelated techs (Redis, Kafka not core DBs); forces use of unmentioned CockroachDB/Redis/Kafka (-2 each, generic -3). Clarity: Well-structured and unambiguous, but lacks time/format constraints for screening (-1, multiple bundled parts -2 mitigated by bullets). Discriminative: Too broad (design full system + migration + ops + mentoring >10min -2), tests recall over deep tradeoffs, weak separation.",
          "composite": 5.0
        }
      },
      {
        "role_id": "be-435",
        "role_title": "Junior Backend Engineer - Queue Consumers",
        "question": "\"Design and implement a Python consumer for a RabbitMQ queue that processes messages with the following requirements:  \n1. Acknowledge messages only after successful processing (with a 5-second timeout for processing).  \n2. Implement idempotency by using a PostgreSQL database to track processed message IDs.  \n3. Handle message failures gracefully by moving failed messages to a dead-letter queue (DLQ).  \n4. Ensure the consumer restarts automatically after a crash (using Docker and a health check).  \n5. Include basic logging and error handling.",
        "scores": {
          "relevance": 7,
          "clarity": 6,
          "discriminative": 8,
          "reasoning": "Relevance: Directly tests core skills (acks, DLQ, idempotency) and exact tech (Python, RabbitMQ, PostgreSQL), but Docker/health checks go beyond entry-level focus (-2 for minor tech not core). Clarity: Clear requirements but vague on implementation scope, depth, and exact Docker setup; multiple bundled aspects (-2). Discriminative: Strong on applied knowledge/trade-offs in message handling, separates good entry-level candidates well.",
          "composite": 7.0
        }
      },
      {
        "role_id": "be-436",
        "role_title": "Backend Engineer - API Documentation",
        "question": "\"Design and implement a function in TypeScript that takes an OpenAPI 3.0 schema object and generates a human-readable, markdown-formatted documentation block for a given endpoint. The function should include:  \n- Path parameters, query parameters, request body, and response schema  \n- Example values for all parameters and responses  \n- Versioning support (e.g., `/v1/users`)  \n- Proper handling of nested schemas  \n- Markdown formatting with headers and code blocks  \n- Error handling for invalid schema structures\"",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests OpenAPI schema handling, documentation generation, versioning, and nested schemas\u2014core to API docs tooling role (-1 for no explicit SDK mention). Clarity: Precise scope with exact requirements listed, unambiguous for screening. Discriminative: Requires applied TypeScript skills, design trade-offs (e.g., example gen, nesting, errors), distinguishes strong implementers from weak ones.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-437",
        "role_title": "Senior Backend Engineer - Secrets Management",
        "question": "\"Design a secure secrets management solution using HashiCorp Vault and Kubernetes, including automatic secret rotation for database credentials, encryption-at-rest for stored secrets, and audit logging. How would you configure Vault to ensure that Kubernetes pods can securely access secrets without exposing them in logs or configuration files? Explain your approach to managing access policies, rotating database credentials automatically, and handling audit logs.\"",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's core focus on secrets management, Vault, rotation, encryption-at-rest, and audit logging in Kubernetes context. Clarity: Crystal clear and well-scoped for screening, minor deduction for lacking explicit time/format constraints. Discriminative: Tests deep applied knowledge, trade-offs in Vault config, policies, and integration, strongly separating strong candidates.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-438",
        "role_title": "Staff Engineer - ML Serving Infrastructure",
        "question": "\"Design a scalable and fault-tolerant ML serving solution using Triton Inference Server with Kubernetes. Your design should include model versioning, dynamic batching, and latency optimization strategies. Include a high-level architecture diagram and explain how you would implement dynamic batching and model versioning. Also, describe how you would monitor system health and detect model drift.\"",
        "scores": {
          "relevance": 10,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's core needs (ML serving, batching, versioning, latency) with Triton/K8s as relevant tools. Clarity: Clear and well-scoped but bundles diagram request and multiple components (-2). Discriminative: Tests deep applied knowledge, trade-offs in design/monitoring/drift; strong separation for experts.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-439",
        "role_title": "Backend Engineer - Billing Integration",
        "question": "\"Design and implement a Python function that handles the proration of a subscription price change in a billing system using Stripe. The function should:\n- Accept the old and new subscription prices, the subscription start date, and the current date.\n- Calculate the prorated amount for the current period based on the time elapsed between the start date and the current date.\n- Account for the fact that proration only applies to the current billing period, not future periods.\n- Return the prorated amount to be applied to the invoice.\"",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core proration skill for billing/subscription role using Stripe (mentioned), minor ding for no full role desc tech stack but spot-on focus (-1). Clarity: Crystal clear inputs/outputs, well-scoped function, no ambiguity. Discriminative: Requires applied math/logic for proration (time ratios, period boundaries), tests deep billing understanding and edge cases like partial periods, strong separation.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-440",
        "role_title": "Junior Backend Engineer - Metrics Collection",
        "question": "You're adding metrics to a Go service using Prometheus. The service has a health check endpoint that returns a 200 status code when healthy and a 500 status code when unhealthy. You want to expose the health status as a metric, so you decide to use a Gauge. You set up the metric with a constant value of 1 for healthy and 0 for unhealthy. However, you notice that the metric doesn't update when the service becomes unhealthy \u2014 it stays at 1 even when the service fails.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 8,
          "reasoning": "Relevance: Directly tests core metrics skills (Gauge pattern) and Go/Prometheus from role, entry-level appropriate (-0 red flags). Clarity: Crystal clear scenario with specific issue, well-scoped. Discriminative: Tests applied Prometheus knowledge (likely Set vs. Inc), reveals understanding of metric mutation; good separation but not extreme trade-offs.",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-441",
        "role_title": "Senior Backend Engineer - Autocomplete Systems",
        "question": "**\"Design a distributed autocomplete system that supports real-time personalization and achieves sub-50ms latency at 100K QPS. How would you structure the data pipeline from ingestion to user query processing, and what specific optimizations would you apply to ensure low latency and high throughput? Please describe how you'd handle personalization (e.g., user-specific recommendations) and how you\u2019d balance consistency and performance in a distributed environment.\"**",
        "scores": {
          "relevance": 10,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's core requirements (autocomplete, personalization, exact latency/QPS targets). Clarity: Clear intent and well-scoped, but lacks explicit time/format constraints for screening (-1) and slightly bundles pipeline + optimizations + personalization (-1). Discriminative: Excellent at testing trade-offs, architecture, and deep optimizations; distinguishes strong systems thinkers from weak ones.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-442",
        "role_title": "Backend Engineer - Event Streaming",
        "question": "Design a system to fan out real-time updates from a PostgreSQL database to multiple downstream services using NATS and Redis. The system must support filtering by event type and allow replay of events from a specific point in time. Describe how you would structure the event ingestion pipeline, handle filtering, and ensure durability and replayability.",
        "scores": {
          "relevance": 9,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (fan-out, filtering, replay) with PostgreSQL (likely DB in role context); minor ding for specifying NATS/Redis not in role desc (-2 red flag adjusted). Clarity: Well-scoped design question with specific requirements, but lacks explicit constraints like scale/throughput (-1 from red flag). Discriminative: Requires applied knowledge of pipelines, trade-offs in durability/filtering/replay with specific tech, strongly separates candidates.",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-443",
        "role_title": "Senior Backend Engineer - Data Lake Architecture",
        "question": "\"Design a data pipeline for ingesting and processing daily sales data into a data lake using Apache Iceberg. The data comes from a variety of sources (e.g., point-of-sale systems, web analytics) and is stored in S3. The pipeline must support schema evolution, allow efficient partition pruning for performance, and enable time travel queries for auditability. Describe how you would structure the pipeline, including the data flow, table format configuration, partitioning strategy, and how you would handle schema evolution and time travel.\"",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's core needs (data lake, Iceberg table formats, schema evolution, partition pruning, time travel). No red flags. Clarity: Crystal clear, well-scoped design question with explicit requirements; minor deduction for no strict time/format constraints. Discriminative: Tests applied architecture knowledge, trade-offs in partitioning/schema/time travel, strongly separates experienced candidates.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-444",
        "role_title": "Backend Engineer - Service Templates",
        "question": "\"Design a service template using Cookiecutter that generates a Go-based microservice with best practices, including proper directory structure, configuration management, logging, and CI/CD setup via GitHub Actions. The template should also include a minimal observability layer (e.g., logging with structured format and metrics via Prometheus) and enforce security best practices (e.g., environment-specific configuration, secure secrets handling, and use of default TLS settings). Describe how you would structure the template, what files would be included, and how GitHub Actions would validate and deploy the service to Kubernetes with ArgoCD.\"",
        "scores": {
          "relevance": 9,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (service scaffolding with Cookiecutter, CI/CD, observability, security) and exact tech (Go, GitHub Actions, Kubernetes/ArgoCD); minor ding for not explicitly mentioning 'templates with best practices' but covers it (-1). Clarity: Well-formed and specific, but 'design a service template' lacks minor constraints like expected detail level or time (-2). Discriminative: Excellent at testing applied knowledge, trade-offs in structure/secrets/observability/CI/CD, distinguishes deep expertise from superficial knowledge.",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-445",
        "role_title": "Junior Backend Engineer - Database Migrations",
        "question": "You're working on a Python application using SQLAlchemy and Alembic for database migrations. You need to create a migration that adds a new column `email` to the `users` table, but you want to ensure that the migration handles the case where some users may already have an email in the database.",
        "scores": {
          "relevance": 9,
          "clarity": 6,
          "discriminative": 7,
          "reasoning": "Relevance: Directly tests Alembic/SQLAlchemy migrations and handling existing data, core to role's database migration focus (-1 for generic 'handles the case' without zero-downtime/rollback specifics). Clarity: Clear scenario but vague on 'handles the case' (backfill? nullability? constraints?), missing explicit constraints (-2 for vagueness, -1 for ambiguous jargon). Discriminative: Good test of applied migration knowledge like upgrade/downgrade with defaults/backfills, separates those understanding real-world pitfalls from basics.",
          "composite": 7.333333333333333
        }
      },
      {
        "role_id": "be-446",
        "role_title": "Staff Engineer - Distributed Tracing",
        "question": "\"Design a sampling strategy for a high-throughput, distributed system using OpenTelemetry and Jaeger, where traces are generated at 10,000 transactions per second (TPS) and must be stored in ClickHouse. Consider the trade-offs between different sampling strategies (e.g., rate-based, probabilistic, deterministic) and the impact on observability, performance, and cost. Propose a hybrid sampling strategy that balances trace visibility, performance, and cost, and explain how you would implement and validate this strategy in production.\"",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's core focus on distributed tracing, sampling strategies at scale, with exact tech stack (OpenTelemetry, Jaeger, ClickHouse). No red flags. Clarity: Crystal clear, well-scoped with specific TPS and trade-offs; minor deduction for lacking explicit time constraint. Discriminative: Tests deep trade-offs, design, implementation, and validation\u2014distinguishes architects from juniors effectively.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-447",
        "role_title": "Backend Engineer - Load Shedding",
        "question": "*Design a load shedding mechanism for a high-traffic API endpoint that uses Envoy as a proxy and Redis for rate limiting. The endpoint experiences random spikes in traffic, causing service degradation. When the system detects a spike, it should automatically trigger load shedding to prioritize critical requests (e.g., user authentication) over non-critical ones (e.g., analytics reporting).*",
        "scores": {
          "relevance": 9,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core load shedding, prioritization, and adaptive handling from role; minor ding for specifying Envoy/Redis not in role desc (-1). Clarity: Clear intent and scenario, but lacks explicit constraints like time or output format (-1). Discriminative: Excellent at probing trade-offs in detection, prioritization, and integration, separating strong systems thinkers.",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-448",
        "role_title": "Senior Backend Engineer - Webhook Infrastructure",
        "question": "\"Design a resilient webhook delivery system in Go using Kafka and PostgreSQL/Redis for delivery guarantees, retry logic, and analytics. Specifically, how would you ensure message delivery is guaranteed, handle failures, and track delivery status with analytics?\"",
        "scores": {
          "relevance": 10,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core role requirements (guaranteed delivery, retry logic, analytics) with relevant tech (Go, Kafka, PostgreSQL/Redis). Clarity: Clear intent and specific, but lacks scoping constraints like time or detail level (-2 red flag). Discriminative: Tests applied system design, trade-offs in resilience/failures/analytics, strong separation of strong vs weak candidates (not pure recall).",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-449",
        "role_title": "Junior Backend Engineer - Auth Integration",
        "question": "*Design a secure OAuth2 flow for a social login (e.g., Google) integrated into a Node.js + TypeScript application using PostgreSQL. Include how you would handle token storage, refresh, and prevent replay attacks.*",
        "scores": {
          "relevance": 9,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core OAuth2 flows, token handling, refresh, and social login from role; matches Node.js/TS stack (assuming common for entry-level), PostgreSQL storage relevant (-1 minor for no explicit Node/TS mention in role). Clarity: Clear and well-scoped for screening, but lacks explicit constraints like time or response format (-2). Discriminative: Excellent at probing security trade-offs, applied knowledge of refresh/prevention, distinguishes deep vs superficial understanding.",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-450",
        "role_title": "Principal Engineer - ML Platform Strategy",
        "question": "\"Design a scalable and secure ML platform strategy for a large enterprise with distributed teams across multiple geographies, including considerations for data governance, model lifecycle management, and team enablement. Your design must address how to ensure consistent model quality, compliance with regulatory requirements (e.g., GDPR, HIPAA), and integration with existing CI/CD pipelines. Please describe your approach to tooling selection, governance models, and how you would onboard new ML engineers to the platform.\"",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's core responsibilities (strategy, tooling, governance, enablement) with no red flags. Clarity: Crystal clear and well-scoped for screening, minor deduction for lacking explicit time/format constraints. Discriminative: Tests deep applied knowledge, trade-offs (scalability/security/governance), and strategic thinking to separate strong strategists from juniors.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-451",
        "role_title": "Backend Engineer - Subscription Billing",
        "question": "\"Design a system to handle proration for a subscription billing model where users can change plans mid-month. Your design should include how usage metering is integrated, how proration is calculated, and how it's stored and updated in the database. Use the following constraints:  \n- All calculations must be precise to the second (e.g., 10.5 seconds of usage = 10.5).  \n- The system must support plan changes at any time, not just at the start of a billing period.  \n- You must use the provided tech stack: Java, PostgreSQL, Kafka, Spring Boot, Redis.  \n- Consider edge cases like partial billing periods and overlapping changes.  \n- Avoid using external libraries for financial calculations.\"",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (proration, usage metering, plan changes) with exact tech stack; minor ding for over-specifying stack (-1). Clarity: Well-scoped with precise constraints, unambiguous despite system design scope. Discriminative: Probes deep applied knowledge, trade-offs, edge cases, and tech integration for strong separation.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-452",
        "role_title": "Senior Backend Engineer - Faceted Search",
        "question": "\"Design and implement a faceted search system that supports dynamic filtering and accurate facet counts at scale. Consider performance, correctness, and scalability when designing your solution. Focus on the challenges of maintaining facet count accuracy when dealing with large datasets and high query loads. How would you ensure accurate facet counts without sacrificing performance?\"",
        "scores": {
          "relevance": 10,
          "clarity": 6,
          "discriminative": 8,
          "reasoning": "Relevance: Perfectly matches role's core focus on faceted search, dynamic filtering, and facet accuracy at scale (no red flags). Clarity: Clear intent but 'design and implement' is overly broad for screening without constraints like time, tech stack, or scope (-2 for lacking constraints). Discriminative: Strong on trade-offs (accuracy vs performance at scale), separates candidates with deep understanding from superficial ones.",
          "composite": 8.0
        }
      },
      {
        "role_id": "be-453",
        "role_title": "Backend Engineer - Notification Delivery",
        "question": "\"Design a system to deliver push notifications in real-time to mobile devices using Go, Redis, and FCM/APNS. Your solution should handle device registration, batching, and delivery tracking. Explain how you\u2019d ensure reliability, scalability, and performance, and how you\u2019d handle failure scenarios.\"",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's core requirements (device registration, batching, delivery tracking) and specifies Go/Redis/FCM/APNS. Clarity: Well-scoped system design with specific components; minor deduction for lacking explicit time/format constraints. Discriminative: Tests deep applied knowledge of trade-offs, reliability, scalability, and failures, strongly separating strong candidates.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-454",
        "role_title": "Junior Backend Engineer - ETL Scripts",
        "question": "Write a Python script using pandas and PostgreSQL that reads a CSV file, performs a basic data transformation (e.g., filtering, aggregating), and writes the result back to a PostgreSQL table. The script should include error handling for common issues like missing files, invalid data types, and database connection failures. Use Airflow to schedule the script to run daily at 2 AM.",
        "scores": {
          "relevance": 3,
          "clarity": 4,
          "discriminative": 5,
          "reasoning": "Relevance: Directly mentions pandas/PostgreSQL/ETL (core) but Airflow scheduling is advanced for entry-level role focused on learning basics (-3 generic ETL, -2 Airflow not entry-level core). Clarity: Bundled multi-part (script + Airflow) without constraints (-2), vague on transformation specifics. Discriminative: Tests ETL basics but Airflow adds unnecessary barrier for screening; weak separation at entry-level.",
          "composite": 4.0
        }
      },
      {
        "role_id": "be-455",
        "role_title": "Staff Engineer - Developer Portal",
        "question": "*Design a scalable plugin architecture for a developer portal built with Backstage using React and Node.js. Your design should support dynamic service discovery and documentation generation, and enable plug-in teams to onboard new services with minimal friction. Include considerations for plugin lifecycle, configuration, and extensibility. Describe how you would structure the core plugin system to support modular development and ensure maintainability across a growing team.*",
        "scores": {
          "relevance": 9,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core role responsibilities (plugin architecture, service discovery, documentation, onboarding) and exact tech stack (Backstage, React, Node.js); minor generic feel but no red flags. Clarity: Well-formed and unambiguous, but lacks explicit screening constraints (e.g., time/depth/format). Discriminative: Excellent at testing trade-offs, architectural thinking, and deep Backstage knowledge to separate strong architects from average devs.",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-456",
        "role_title": "Backend Engineer - Query Optimization",
        "question": "\"Explain how you would instrument and analyze a PostgreSQL database to detect and diagnose slow queries using pganalyze, and walk through a real-world scenario where you used this approach to improve performance. Include specific SQL queries, indexes, and plan analysis steps.\"",
        "scores": {
          "relevance": 7,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Tests core slow query detection and plan analysis but assumes pganalyze (not mentioned in role) and demands personal real-world experience (-3 generic red flag partially, -2 unlisted tech). Clarity: Well-formed and scoped but bundles explanation, scenario, and specifics without time/format constraints (-2). Discriminative: Excellent at separating via applied trade-offs, tools, and real experience; not trivial recall.",
          "composite": 8.0
        }
      },
      {
        "role_id": "be-457",
        "role_title": "Senior Backend Engineer - SLO Automation",
        "question": "\"Design a system that automatically detects and alerts on SLO burn rate violations in a Kubernetes environment using Go, Prometheus, and PostgreSQL. Include how you would track error budgets, handle alerting, and ensure reliability in production. Be specific about how you'd use Sloth for SLO definitions and how you'd integrate with Kubernetes monitoring (e.g., via Prometheus).\"",
        "scores": {
          "relevance": 7,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core SLO/burn rate/error budget skills and key tech (Kubernetes, Prometheus, Go, PostgreSQL), but deduct -2 for Sloth (unmentioned in role) and -1 for generic design scope. Clarity: Well-formed and specific, minor deduction for lacking time/format constraints. Discriminative: Excellent at testing applied system design, integrations, trade-offs, and production reliability, strongly separating candidates.",
          "composite": 8.0
        }
      },
      {
        "role_id": "be-458",
        "role_title": "Backend Engineer - API Gateway Plugins",
        "question": "What are the key differences between Kong's `on_pre_balance` and `on_post_balance` lifecycle events in a plugin, and how would you use them to implement a custom authentication flow that validates user session state and enriches the response with user metadata?",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests Kong plugin development (core to API gateway plugins for auth/transformation), no red flags. Clarity: Precise and well-scoped, minor deduction only if constraints like code format unspecified. Discriminative: Requires deep understanding of Kong lifecycle, trade-offs in auth flow placement, and applied implementation for strong candidate separation.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-459",
        "role_title": "Junior Backend Engineer - Container Security",
        "question": "\"Walk me through how you would set up a CI/CD pipeline to scan container images for vulnerabilities using Trivy, and explain how you would ensure these scans are both effective and non-disruptive to the development workflow.\"",
        "scores": {
          "relevance": 7,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Tests core container scanning skills for the role but specifies Trivy (unmentioned in role desc, -2) and CI/CD (relevant but entry-level focus is implementation/learning vuln detection). Clarity: Well-formed with clear intent, though lacks minor constraints like tools/time. Discriminative: Excellent at probing applied knowledge, trade-offs (effective vs non-disruptive), and practical workflow integration, strongly separating candidates.",
          "composite": 8.0
        }
      },
      {
        "role_id": "be-460",
        "role_title": "Backend Engineer - Experiment Tracking",
        "question": "\"Using MLflow, design and implement a Python script that tracks a simple machine learning experiment. The script should:  \n1. Initialize an MLflow experiment with a unique name (e.g., 'experiment_123').  \n2. Log hyperparameters (e.g., learning rate, batch size) and metrics (e.g., accuracy, loss).  \n3. Save a model artifact (e.g., a trained scikit-learn model) to MLflow's artifact store.  \n4. Ensure the experiment is properly tracked and closed.  \n5. Use Docker to containerize the script so it can be run in a production-like environment.  \n6. Provide instructions on how to run the script locally and in Docker.\"",
        "scores": {
          "relevance": 5,
          "clarity": 6,
          "discriminative": 5,
          "reasoning": "Relevance: Directly tests MLflow (relevant for experiment tracking) but adds Docker (unmentioned in role) and goes beyond core metric logging/model artifacts (-2); generic scripting could apply broadly (-3, net 10-5=5). Clarity: Clear steps but bundles multiple tasks (script + Docker + instructions) without time/format constraints (-2); vague on 'simple ML' details (7-2=5, adjusted to 6). Discriminative: Tests applied MLflow knowledge (good) but Docker/containerization dilutes ML infra focus and risks over-broad scope (>10min, -2); basic implementation over trade-offs (7-2=5).",
          "composite": 5.333333333333333
        }
      },
      {
        "role_id": "be-461",
        "role_title": "Senior Backend Engineer - Fraud Detection",
        "question": "\"Design a real-time fraud scoring pipeline for a payment system that must handle 10K transactions per second. The pipeline should integrate a rule engine with a machine learning model and support manual review queues. Describe how you would structure the data flow, key components, and how you'd balance real-time performance with model accuracy and reliability.\"",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's core skills (fraud pipelines, rule engines, ML integration, manual queues) with exact tech focus. Clarity: Crystal clear and well-scoped with 10K TPS constraint, though minor deduction for unspecified output format/depth. Discriminative: Excellent at testing architecture trade-offs (performance vs accuracy/reliability), deep understanding, and applied knowledge for strong candidate separation; appropriately scoped for screening (<10min high-level).",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-462",
        "role_title": "Backend Engineer - Alert Routing",
        "question": "\"Design a system to route alerts from a distributed system to the appropriate on-call team using Alertmanager, with support for dynamic escalation policies, silence management, and deduplication. Explain how you would structure the routing logic, manage silences, and ensure alerts are not duplicated during high-volume events.\"",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Directly tests core role skills (routing, escalation, silence, deduplication) using specified Alertmanager; crystal clear with focused scope on key components; probes applied knowledge, trade-offs in high-volume scenarios for strong differentiation. Minor ding for assuming Alertmanager familiarity without role confirmation, but aligns closely.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-463",
        "role_title": "Junior Backend Engineer - Full-text Search",
        "question": "You are tasked with implementing a simple full-text search feature in a Python application using PostgreSQL. The application has a table `products` with columns `id`, `name`, and `description`. Users can search for products by entering a query string. When a query is submitted, return a list of products matching the search term, ranked by relevance.",
        "scores": {
          "relevance": 9,
          "clarity": 8,
          "discriminative": 8,
          "reasoning": "Relevance: Directly tests PostgreSQL full-text search core to role (tsvector/ranking implied), minor ding for not explicitly naming tsvector (-1). Clarity: Clear task and goal, but lacks constraints on output format, query handling, or depth (-2). Discriminative: Requires applied knowledge of FTS implementation and ranking, separates those who know SQL/Python integration from theorists; not trivia but needs trade-offs for 10.",
          "composite": 8.333333333333334
        }
      },
      {
        "role_id": "be-464",
        "role_title": "Staff Engineer - Presence Systems",
        "question": "Design a presence system that tracks real-time user presence and typing indicators using Go, Redis, and WebSockets. The system must support millions of concurrent users. Describe your architecture, data model, and how you would handle scale and reliability.",
        "scores": {
          "relevance": 9,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (presence, typing indicators, scale) and specifies Go/Redis/WebSockets (assuming role match); minor deduction for not explicitly mentioning heartbeats/state sync. Clarity: Well-scoped for screening but lacks precise constraints (e.g., exact scale metrics, latency targets). Discriminative: Excellent at probing architecture, trade-offs, scaling/reliability decisions for strong separation.",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-465",
        "role_title": "Backend Engineer - CDC Pipelines",
        "question": "*Design a CDC pipeline using Debezium and Kafka to replicate data from a PostgreSQL database to Snowflake. Include the configuration of Debezium's connector, handling of schema changes, and an approach to ensure exactly-once delivery. Explain how you would handle initial data synchronization (snapshot) and ensure data consistency during schema changes.*",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Directly tests core CDC pipeline skills (schema changes, snapshots, exactly-once) with exact tech stack (Debezium, Kafka, PostgreSQL, Snowflake) from role. Crystal clear and well-scoped for screening; minor deduction for no explicit time/format constraints but highly specific. Strong trade-offs in exactly-once and consistency distinguish experts.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-466",
        "role_title": "Senior Backend Engineer - GitOps Tooling",
        "question": "\"Design a drift detection mechanism in a GitOps pipeline using ArgoCD and Helm. Your solution should detect when a deployed Kubernetes manifest diverges from its Git source, and automatically trigger a rollback to the last known good state if drift exceeds a configurable threshold. Explain your approach, including how you would implement reconciliation, detect drift, and handle rollback. Consider edge cases such as partial drift, temporary mismatches, and network issues.\"",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core GitOps skills (drift detection, reconciliation, rollback) with exact tech stack (ArgoCD, Helm, K8s manifests) from role. No red flags. Clarity: Crystal clear, well-scoped with specific requirements and edge cases; minor deduction for no explicit time/format constraint. Discriminative: Tests deep applied knowledge, trade-offs, and edge cases, strongly separating strong candidates who can reason through GitOps complexities from weak ones.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-467",
        "role_title": "Backend Engineer - Connection Pooling",
        "question": "\"Design and implement a Go-based connection pool manager that uses PgBouncer as a proxy to manage PostgreSQL connections. The manager should support dynamic pool sizing based on load, automatic failover to a backup PostgreSQL instance when primary fails, and monitor connection health using a health check endpoint. How would you structure the configuration, handle failover, and ensure connection health is maintained in a Kubernetes environment with horizontal pod autoscaling (HPA)?\"",
        "scores": {
          "relevance": 4,
          "clarity": 5,
          "discriminative": 7,
          "reasoning": "Relevance: Superficially mentions Go and PostgreSQL but heavily focuses on PgBouncer/Kubernetes/HPA not in role (red flag -2 tech not listed, generic infra design -3). Clarity: Bundled multi-part design question without scope/time constraints in screening context (red flag -2 multiple questions, -2 design w/o constraints). Discriminative: Tests applied trade-offs in pooling/failover but too broad for screening (>10min, advanced infra knowledge).",
          "composite": 5.333333333333333
        }
      },
      {
        "role_id": "be-468",
        "role_title": "Junior Backend Engineer - CI Pipelines",
        "question": "\"Design a GitHub Actions workflow that builds and tests a Python project using Docker. The workflow should include caching for Python dependencies, parallelize tests across multiple CPU cores, and run tests in a containerized environment. Provide a clear explanation of your choices for each step, including caching strategy and parallelization method.\"",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core CI pipeline skills (workflow syntax, caching, test parallelization) for GitHub Actions in Python/Docker context (-1 for minor Docker addition not explicit). Clarity: Well-scoped with specific requirements and explanation request, unambiguous for screening. Discriminative: Requires applied knowledge of caching strategies, parallelization trade-offs, and design choices, strongly separates candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-469",
        "role_title": "Senior Backend Engineer - Chaos Engineering",
        "question": "*Design a failure injection experiment using Chaos Mesh to simulate a node failure in a Kubernetes cluster, and implement a recovery validation mechanism that ensures the application remains available and consistent after the failure. Include details on how you would configure the experiment, monitor the impact, and validate recovery using metrics and logs.*",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets Chaos Mesh, Kubernetes node failure, blast radius control, and recovery validation\u2014core to chaos engineering role (no red flags). Clarity: Crystal clear, well-scoped for screening with specific components, minor deduction for lacking explicit time/format constraints. Discriminative: Tests applied design, configuration, monitoring, trade-offs in Chaos Mesh/K8s, and validation logic\u2014strong separation of strong vs weak candidates.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-470",
        "role_title": "Backend Engineer - GraphQL Federation",
        "question": "*Design a schema stitching strategy for a federated GraphQL gateway that connects a user subgraph and a product subgraph. The user subgraph defines a `User` type with fields `id`, `name`, and `email`, while the product subgraph defines a `Product` type with fields `id`, `name`, and `field`. The user subgraph also contains a field `products` of type `[Product!]!` which references the product subgraph. Implement a solution that correctly resolves the `products` field on a `User` object when queried via the gateway. Provide a clear explanation of how the query planning and entity resolution work in this scenario, including how the gateway handles the cross-subgraph resolution.*",
        "scores": {
          "relevance": 9,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core federated GraphQL skills (schema stitching, query planning, entity resolution) with exact role tech stack; minor deduction for not mentioning supergraph explicitly (-1). Clarity: Well-scoped with specific schemas and clear intent, but lacks explicit constraints on format/response depth (-1) and bundles design/explanation (-1). Discriminative: Excellent at probing trade-offs in stitching, planning, and resolution, distinguishing deep Apollo Federation knowledge from superficial understanding.",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-471",
        "role_title": "Staff Engineer - Zero Trust Architecture",
        "question": "*Design a solution using SPIFFE and mTLS to secure inter-service communication in a Kubernetes cluster where services need to be authenticated and authorized using identity-based policies. Include a flow from service startup to actual communication. Explain how SPIFFE ensures zero trust, and describe how you would integrate with HashiCorp Vault for identity management and policy enforcement.*",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core role skills (zero trust, mTLS, policy enforcement) with exact tech (SPIFFE, Kubernetes) from description; no red flags. Clarity: Well-scoped with specific flow and integration; minor deduction as no explicit time/format constraint. Discriminative: Tests deep applied knowledge, trade-offs, and architecture; strong separation between superficial and expert responses; not trivial recall.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-472",
        "role_title": "Backend Engineer - Vector Search",
        "question": "Design a system to handle semantic search with hybrid retrieval using Pinecone and PostgreSQL. The system should support embedding generation, index management, and retrieval with a fast, scalable, and reliable pipeline.",
        "scores": {
          "relevance": 8,
          "clarity": 5,
          "discriminative": 7,
          "reasoning": "Relevance: Directly tests core skills (embeddings, index mgmt, hybrid search) and matches role, but assumes Pinecone/pgSQL not explicitly listed (-2 for unlisted techs). Clarity: Clear intent but 'design a system' lacks scope/constraints like scale/size (-2 red flag, vague depth). Discriminative: Probes applied knowledge/tradeoffs in pipeline design, separates good from weak, but broad scope risks >10min answers (-2).",
          "composite": 6.666666666666667
        }
      },
      {
        "role_id": "be-473",
        "role_title": "Senior Backend Engineer - Refund Processing",
        "question": "Design a system to process partial refunds for a payment platform, ensuring ledger reconciliation and audit trails. The system must handle asynchronous provider callbacks and support rollback on failure. How would you structure the refund processing pipeline in a distributed, fault-tolerant environment using Java, Spring Boot, Kafka, and PostgreSQL? Include considerations for state management, error handling, and audit logging.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core role skills (partial refunds, ledger reconciliation, audit trails, provider callbacks) with exact tech stack (Java, Spring Boot, Kafka, PostgreSQL); minor -1 for not explicitly mentioning rollback but it's implied. Clarity: Well-scoped design question with clear constraints, tech specified, no bundling or vagueness. Discriminative: Probes deep applied knowledge of distributed systems, state management, fault-tolerance, and trade-offs in pipeline design using specified stack, strongly separates strong candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-474",
        "role_title": "Backend Engineer - Dashboards API",
        "question": "Write a Go function to render a Grafana dashboard JSON template with dynamic variables. The function should:\n- Accept a dashboard JSON as input\n- Accept a map of variable values (e.g., `map[string]string{\"instance\": \"db1\", \"region\": \"us-east\"}`)\n- Replace all variable references in the dashboard JSON (e.g., `{{instance}}` or `{{region}}`) with their values\n- Output the rendered JSON as a string\n- Handle edge cases like missing variables, invalid JSON, and malformed variable references",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests Go (core for APIs), JSON handling, template rendering, and variable substitution\u2014exact match for dashboard management role (-0 red flags). Clarity: Precise inputs/outputs, explicit edge cases, well-scoped for screening. Discriminative: Requires applied Go/JSON skills, error handling, edge cases with trade-offs (e.g., strict vs. graceful failure), distinguishes strong implementers.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-475",
        "role_title": "Junior Backend Engineer - Search Analytics",
        "question": "\"Imagine you're building a query logging system for a search engine. Users submit search queries, and we want to record the query, the user's session ID, and the timestamp. After processing, we want to store these logs in Elasticsearch. However, we also need to ensure that the logs are not duplicated due to network issues or retries.",
        "scores": {
          "relevance": 8,
          "clarity": 8,
          "discriminative": 8,
          "reasoning": "Relevance: Directly tests core query logging skill for search analytics role using Elasticsearch (inferred relevance); minor deduction for not mentioning click tracking/relevance metrics (-2 per red flag). Clarity: Well-scoped scenario with clear requirements, but lacks explicit constraints on solution format/depth (-2 per red flag). Discriminative: Good test of applied knowledge on deduplication (idempotency, unique keys), distinguishing candidates who understand trade-offs vs basic logging.",
          "composite": 8.0
        }
      },
      {
        "role_id": "be-476",
        "role_title": "Backend Engineer - Live Updates",
        "question": "Design a scalable real-time dashboard update system using Socket.io and Redis. The system must support room-based selective broadcasting, automatic reconnection, and handle concurrent connections efficiently. Provide a high-level architecture and explain how you would implement the following:",
        "scores": {
          "relevance": 9,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core skills (live updates, room management, selective broadcasting, reconnection) and matches tech (Socket.io implied, Redis for scaling); minor ding as Redis not explicitly in role but fits perfectly. Clarity: Clear and well-scoped for high-level design, but lacks explicit constraints like scale metrics (-1 red flag avoided). Discriminative: Excellent at probing architecture, trade-offs, and implementation depth for real-time systems, separating strong candidates.",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-477",
        "role_title": "Senior Backend Engineer - Data Catalog",
        "question": "\"Design a system to automatically extract metadata from a data pipeline using Apache Atlas, and ensure lineage is properly tracked through the pipeline. Describe how you would integrate Kafka for real-time event streaming, Airflow for orchestration, and PostgreSQL for storing metadata. Include specific examples of how you would define entities, relationships, and attributes in Apache Atlas, and how you would trigger metadata updates when data is transformed or moved through the pipeline.\"",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (metadata extraction, lineage tracking) with relevant tools (Atlas for catalog/lineage, Kafka/Airflow/PostgreSQL fit data pipelines/governance); minor ding as role doesn't explicitly list these integrations (-1). Clarity: Well-scoped design question with specific components, examples requested, and clear triggers; no bundling or vagueness. Discriminative: Requires applied knowledge of integrations, Atlas entity modeling, and real-time triggers, testing trade-offs and depth to separate strong candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-478",
        "role_title": "Backend Engineer - Cost Attribution",
        "question": "Explain how you would design a system to track and attribute cloud costs to individual teams or projects, using resource tagging and a database. Consider the following constraints:\n- Each cloud resource (e.g., EC2 instance, S3 bucket) has a set of tags (like `team`, `project`, `environment`)\n- Costs are billed at the monthly level, and you need to generate monthly chargeback reports\n- The system must support real-time cost tracking and monthly reporting\n- You must store cost data efficiently and avoid overwriting or losing data\n- You must handle edge cases like missing tags or inconsistent tagging\n- You should use Go, PostgreSQL, and Prometheus for monitoring",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core role skills (cost attribution, tagging, chargeback reports) with exact tech stack (Go, PostgreSQL, Prometheus); minor ding for assuming Prometheus is listed. Clarity: Well-scoped with specific constraints, unambiguous intent for screening. Discriminative: Probes deep design trade-offs (real-time vs monthly, edge cases, efficiency), separates strong architects from basic coders.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-479",
        "role_title": "Principal Engineer - Data Architecture",
        "question": "> \"You're designing a data architecture for a company that processes 10M+ daily transactions and runs complex analytical queries on aggregates. The transactional system is currently a PostgreSQL database with high write throughput. You need to build a scalable, cost-efficient data warehouse for analytical queries.  \n>  \n> Describe how you would design the architecture, including choices for data ingestion, storage, and query processing. Justify each decision with clear trade-offs. Consider performance, cost, scalability, and data consistency.\"",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core data architecture strategy, tech selection (builds on PostgreSQL), and analytics/transactional workloads from role; no red flags. Clarity: Crystal clear scenario with specifics (10M+ txns, PostgreSQL), well-scoped; minor deduction for no explicit time limit. Discriminative: Requires applied knowledge of trade-offs across ingestion/storage/query (e.g., CDC vs batch, Snowflake vs BigQuery, columnar stores), strongly separates experts from juniors; not too broad for screening.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-480",
        "role_title": "Junior Backend Engineer - Deployment Automation",
        "question": "\"Write a simple Ansible playbook that deploys a Python application using Docker to AWS EC2. The playbook should:\n- Launch an EC2 instance (using a specified AMI and instance type)\n- Install Docker on the instance\n- Build and run a Docker container from a local Dockerfile\n- Ensure the container starts automatically on boot\"",
        "scores": {
          "relevance": 4,
          "clarity": 8,
          "discriminative": 7,
          "reasoning": "Relevance: Low - Ansible is unmentioned in role (focus: deployment scripts, config mgmt, rollbacks, env setup); tests advanced Docker/AWS/EC2 not core to entry-level; generic devops (-3), misses role focus (-2), minor tech only (-2). Clarity: Clear intent and well-scoped, but lacks minor constraints like AMI ID (-1 red flag implicit, still high). Discriminative: Good applied knowledge of playbook writing with multi-step logic, separates those who can vs can't; not trivial recall.",
          "composite": 6.333333333333333
        }
      },
      {
        "role_id": "be-481",
        "role_title": "Backend Engineer - Canary Deployments",
        "question": "Design a canary deployment pipeline using Istio and ArgoCD that automatically rolls back a service if the canary traffic metrics exceed a predefined threshold (e.g., error rate > 1% or latency > 500ms) over a 5-minute window. Include details on how traffic shifting, metric monitoring, and rollback automation are implemented.",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's core focus on canary deployments, traffic shifting, metrics, and rollback; directly tests Istio/ArgoCD implied by infrastructure needs. Clarity: Crystal clear with specific thresholds, window, and implementation details requested; minor deduction for no explicit time/format constraints. Discriminative: Tests deep applied knowledge of integration, trade-offs in monitoring/automation, distinguishes experts from juniors.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-482",
        "role_title": "Senior Backend Engineer - API Monetization",
        "question": "\"Design a system to track API usage and enforce quotas for different pricing tiers. Describe how you would structure the data model in PostgreSQL, implement quota enforcement in Go, and integrate with Stripe for billing. Include how you would handle edge cases like quota overages and billing disputes.\"",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Directly tests core role skills (API usage tracking, quotas, pricing tiers, billing) with exact tech stack (PostgreSQL, Go, Stripe). Crystal clear and well-scoped for screening, though minor deduction for lacking time/format constraints. Excellent trade-off probing via edge cases distinguishes strong candidates.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-483",
        "role_title": "Backend Engineer - WAF Integration",
        "question": "\"Design a Go service that integrates with ModSecurity to detect and log suspicious HTTP requests, including rate limiting and bot detection. The service should use Redis for rate limiting, PostgreSQL for persistent logging, and Nginx as the proxy. Explain how you would structure the service, handle the ModSecurity events, and ensure accurate bot detection using attack pattern analysis.\"",
        "scores": {
          "relevance": 8,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core WAF integration, rate limiting, bot detection, and attack patterns with Go/Redis/PostgreSQL; minor ding for ModSecurity/Nginx not in role desc (-2). Clarity: Well-scoped design question with specific tech, but lacks time/format constraints (-1, not fully 9-10). Discriminative: Strong on trade-offs in service structure, event handling, and bot analysis; distinguishes deep applied knowledge.",
          "composite": 8.333333333333334
        }
      },
      {
        "role_id": "be-484",
        "role_title": "Staff Engineer - Model Registry",
        "question": "\"Design a model registry system using MLflow and S3 that supports model versioning, automated deployment to Kubernetes, and governance through access control. Walk through your design decisions, including how you would structure the data model, how you'd manage model versions, how you'd automate deployment, and how you'd implement access control. Be specific about how these components integrate with MLflow, SML, and Kubernetes.\"",
        "scores": {
          "relevance": 8,
          "clarity": 7,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (model registry, versioning, deployment, governance) and key tech (MLflow, S3, Kubernetes), but penalize -2 for undefined 'SML' not in role desc. Clarity: Clear intent and specific components, but vague on scope/depth and 'SML' ambiguity (-1 jargon). Discriminative: Excellent for probing trade-offs, integration, and deep design thinking to separate strong architects.",
          "composite": 8.0
        }
      },
      {
        "role_id": "be-485",
        "role_title": "Junior Backend Engineer - Payment Webhooks",
        "question": "*You're processing a payment webhook from Stripe. The event contains the `id` and `data.object.payment_intent.id`. You need to ensure the webhook is processed only once even if it's delivered multiple times. How would you implement idempotency at the webhook receiver level using Python and FastAPI?*",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core idempotency skill for payment webhooks role using exact tech (Python/FastAPI); minor -1 for not mentioning signature verification. Clarity: Crystal clear scenario, specific fields, well-scoped for screening. Discriminative: Requires applied knowledge of idempotency (e.g., DB checks, caching), trade-offs like race conditions, distinguishes strong entry-level candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-486",
        "role_title": "Backend Engineer - Span Processing",
        "question": "Design a tail sampling strategy for OpenTelemetry spans in a high-throughput Kafka-based tracing pipeline. The system must handle 100K+ spans per second, with 10% of spans being high-value (e.g., user login, payment processing), and 90% being low-value (e.g., internal service calls). The pipeline processes spans via a Go service that consumes from Kafka, applies sampling logic, and writes to ClickHouse. Tail sampling must ensure that high-value spans are retained with 95% accuracy, while low-value spans are dropped with a configurable threshold. Implement a sampling decision logic that avoids data loss for critical operations and uses minimal CPU overhead. Describe your approach, including how you would validate its effectiveness.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core role skills (tail sampling, span processing, Kafka/Go/ClickHouse pipeline) with precise metrics; minor ding for not mentioning attribute enrichment/storage optimization (-1). Clarity: Crystal clear, well-scoped with throughput, ratios, accuracy targets, and tech stack; no ambiguity or missing constraints. Discriminative: Requires deep applied knowledge of tail sampling trade-offs, low-CPU implementation, validation in high-throughput context; distinguishes experts via design decisions and effectiveness metrics.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-487",
        "role_title": "Senior Backend Engineer - Search Ranking",
        "question": "Design a system to evaluate the performance of a learning-to-rank (LTR) model in a production search environment. The system should:",
        "scores": {
          "relevance": 7,
          "clarity": 4,
          "discriminative": 6,
          "reasoning": "Relevance: Tests core LTR evaluation skills relevant to role (pipelines, production), but generic/misses specific tech stack and role emphases like feature engineering or A/B testing (-3 generic). Clarity: Clear high-level intent but 'design a system' lacks scope/constraints like components, metrics, scale, or time (-2 red flag), multiple interpretations possible. Discriminative: Tests applied knowledge of eval systems (metrics, offline/online, A/B) with some trade-offs, but too open-ended (>10min, vague depth).",
          "composite": 5.666666666666667
        }
      },
      {
        "role_id": "be-488",
        "role_title": "Backend Engineer - Gaming Backend",
        "question": "Design a real-time state synchronization mechanism for a multiplayer game where clients connect via WebSocket and need to keep their game state in sync. The state includes player positions, health, and score. Describe how you would structure the state, handle network latency, and ensure consistency across clients. Specifically, consider the impact of network latency and how you would prevent desynchronization or \"stale\" states.",
        "scores": {
          "relevance": 9,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (real-time state sync, WebSocket implied for multiplayer backend) with exact state elements mentioned; minor deduct for not mentioning matchmaking/anti-cheat (-1). Clarity: Well-scoped and unambiguous, but lacks explicit constraints like scale or perf targets (-1 from red flag on design scope). Discriminative: Excellent at probing trade-offs (latency, consistency models), deep understanding of sync techniques (e.g., snapshots, interpolation, reconciliation); distinguishes strong candidates.",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-489",
        "role_title": "Backend Engineer - Data Quality",
        "question": "\"Design a data quality monitoring system using dbt, Great Expectations, and Airflow to detect freshness, volume anomalies, and schema drift in a Snowflake warehouse. Walk through your approach, including how you\u2019d structure the data quality checks, define metrics, and schedule the checks in Airflow. Explain how you\u2019d detect schema drift and handle volume anomalies using statistical methods.\"",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's core needs (freshness, volume anomalies, schema drift) and specifies exact tools (dbt, Great Expectations, Airflow, Snowflake). Clarity: Well-scoped with specific components, though minor deduction for lacking explicit time/format constraints. Discriminative: Tests applied design, trade-offs, and statistical methods, strongly separating candidates with deep understanding.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-490",
        "role_title": "Senior Backend Engineer - Environment Management",
        "question": "\"Design and implement a simple Go service that manages a preview environment for a microservice. The service should:",
        "scores": {
          "relevance": 4,
          "clarity": 3,
          "discriminative": 5,
          "reasoning": "Relevance: Superficially mentions Go (assuming in role) but tests generic service design, not core namespace isolation/quotas/TTL; generic (-3), misses specifics. Clarity: Incomplete/broken (cuts off), multiple bundled reqs (-2), no constraints (-2). Discriminative: Vague design task tests basics but poor separation due to ambiguity and breadth (>10min, -2).",
          "composite": 4.0
        }
      },
      {
        "role_id": "be-491",
        "role_title": "Junior Backend Engineer - Read Replicas",
        "question": "You're implementing a read replica routing system using Python and PostgreSQL with SQLAlchemy. Your system needs to route read queries to the appropriate replica based on a consistent, deterministic rule. The primary database is always at `primary.db.example.com:5432`. Read replicas are at `replica1.db.example.com:5432`, `replica2.db.example.com:5432`, and `replica3.db.example.com:5432`.",
        "scores": {
          "relevance": 9,
          "clarity": 6,
          "discriminative": 7,
          "reasoning": "Relevance: Directly tests core read replica routing skills with PostgreSQL/SQLAlchemy (9), minor ding for assuming exact tech stack not explicitly listed (-1). Clarity: Clear setup but incomplete-missing specific task, constraints, or expected output (6). Discriminative: Good setup for testing routing logic and replication considerations, but lacks prompt for trade-offs or lag handling to strongly differentiate (7).",
          "composite": 7.333333333333333
        }
      },
      {
        "role_id": "be-492",
        "role_title": "Backend Engineer - CD Pipelines",
        "question": "\"Design a GitOps-based continuous deployment pipeline using ArgoCD and GitHub Actions that supports multi-environment promotion with approval gates and rollback automation. Explain how you would structure the pipeline, the role of each tool, and how you ensure safety and reliability.\"",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's core skills (GitOps, multi-env promotion, approvals, rollbacks) and specifies exact tools; no red flags. Clarity: Crystal clear and well-scoped for screening, minor deduction for lacking explicit time/format constraints. Discriminative: Tests deep applied knowledge, trade-offs, and architecture decisions to separate strong candidates.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-493",
        "role_title": "Staff Engineer - Reliability Standards",
        "question": "\"Design a production readiness review (PRR) checklist for a new Go service deployed to Kubernetes, with monitoring and alerting via Prometheus and PagerDuty. The checklist should include at least one reliability-focused item (e.g., circuit breakers, timeouts), one observability item (e.g., metrics, logs), and one incident management item (e.g., escalation path). Explain your rationale for including each category.\"",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role responsibilities (PRR design, reliability standards) with specific tech stack (Go, K8s, Prometheus, PagerDuty) matching role focus; minor ding for assuming those exact tools not explicitly listed. Clarity: Crystal clear with explicit requirements, categories, and rationale request; well-scoped for screening. Discriminative: Requires applied design thinking, trade-offs in reliability/observability/incident mgmt, and justification, strongly separating candidates with SRE depth.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-494",
        "role_title": "Backend Engineer - API Mocking",
        "question": "\"Design a WireMock stub configuration in TypeScript that handles a GET request to `/api/v1/users/{id}` with the following requirements:\n- Match the path and query parameters (e.g., `?active=true`)\n- Match the request headers, specifically `Authorization: Bearer <token>` and `X-Client-ID: 123`\n- Return a JSON response with user data for a specific user ID (e.g., `id: 42`)\n- Include a 200 status code and a `Content-Type: application/json` header\n- Handle a 404 if the user ID is not found (use a 404 stub with a custom error message)\n- Ensure the stub is reusable and can be easily configured with dynamic values (e.g., via environment variables or configuration files)\"",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests WireMock configuration in TypeScript for API mocking, request matching, and response templating\u2014core to role (-1 minor for assuming WireMock specifically). Clarity: Well-scoped with precise requirements, no ambiguity, single focused task. Discriminative: Requires applied knowledge of matchers, stubs, conditional logic (404), and reusability\u2014distinguishes deep understanding from superficial knowledge.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-495",
        "role_title": "Senior Backend Engineer - Audit Logging",
        "question": "\"Design a Go service that receives audit events from Kafka and writes them to ClickHouse with immutable storage and a time-based retention policy. The service should ensure data integrity and prevent tampering. Explain how you would implement tamper-proof storage and handle retention. Include considerations for high availability, scalability, and performance.\"",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core role skills (tamper-proof storage, retention) using relevant tech (Go, Kafka, ClickHouse); minor ding as role doesn't explicitly list Kafka/ClickHouse (-1). Clarity: Well-scoped design question with clear requirements and considerations, no bundling or vagueness. Discriminative: Probes deep trade-offs in integrity, HA, scalability, and performance, strongly separating strong candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-496",
        "role_title": "Junior Backend Engineer - Model Serving",
        "question": "\"Design and implement a FastAPI-based model serving endpoint that loads a pre-trained scikit-learn model (e.g., Random Forest Classifier) from disk and serves predictions via a REST API. The endpoint should support batch inference on a list of input data (a list of dictionaries), handle model loading and caching via Redis for performance, and include basic error handling and logging.\"",
        "scores": {
          "relevance": 4,
          "clarity": 6,
          "discriminative": 8,
          "reasoning": "Relevance: Low - generic FastAPI/ML serving but adds unmentioned Redis (red flag -2), ignores role's core entry-level focus on model loading/batching/monitoring; superficially mentions tech stack. Clarity: Understandable but vague on specifics like Redis usage details, input format, model path (missing constraints). Discriminative: Good - tests applied implementation with batching/caching/error handling, separates those who can code vs theory.",
          "composite": 6.0
        }
      },
      {
        "role_id": "be-497",
        "role_title": "Backend Engineer - Payout Systems",
        "question": "Design a system to process payout batches for a marketplace platform. Each batch contains multiple user payouts, and payouts must be validated against bank account details before being processed. The system must support batch processing, retry mechanisms, and reconciliation of processed payouts. Describe your architecture, including how you would handle bank account validation, batch processing, and reconciliation. Use Go, PostgreSQL, Kafka, Redis, and gRPC for your design.",
        "scores": {
          "relevance": 7,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core payout batch processing, validation, and reconciliation from role, but mandates specific tech stack (Go, Kafka, etc.) not listed in role description (-2). Clarity: Well-scoped system design with clear components and tech specified, though lacks time/format constraints (-1). Discriminative: Excellent at probing architecture trade-offs, retries, and integration of validation/reconciliation, strongly separates strong candidates.",
          "composite": 8.0
        }
      },
      {
        "role_id": "be-498",
        "role_title": "Senior Backend Engineer - Profiling Infrastructure",
        "question": "\"Explain how you would design a continuous profiling system for a Go application running in Kubernetes, using Pyroscope for data collection, ClickHouse for storage, and Grafana for visualization. Include how you would handle baseline comparison, detect anomalies, and optimize storage for long-term retention.\"",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core role skills (continuous profiling, flame graphs implied, baseline comparison, storage optimization) and specifies relevant tech (Go/K8s aligns with infra, tools match needs); minor ding for not explicitly mentioning flame graphs (-1). Clarity: Crystal clear, well-scoped design with specific components and features, no ambiguity or missing constraints. Discriminative: Tests deep applied knowledge, trade-offs in design/anomaly detection/storage, strong separation of strong vs weak candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-499",
        "role_title": "Principal Engineer - Search Platform",
        "question": "Design a resilient, scalable search platform for an enterprise with 10M+ daily active users and 50M+ daily search queries. The platform must support real-time indexing and querying of unstructured data (e.g., product catalogs, user-generated content). It must handle data consistency, availability, and fault tolerance across distributed systems. Your solution should include high-level architectural decisions, data flow, fault tolerance, and recovery strategies. Consider the trade-offs between performance, cost, and operational complexity. Explain how you would ensure data consistency and availability under network partitions and node failures. Describe how you would monitor and respond to failures.",
        "scores": {
          "relevance": 4,
          "clarity": 5,
          "discriminative": 7,
          "reasoning": "Relevance: Superficially matches search platform strategy but generic distributed systems design; no role-specific tech stack, enterprise adoption focus, or team/ops strategy (-3 generic, -2 no listed tech). Clarity: Understandable but classic 'design a system' without time/format constraints (-2); multiple aspects bundled (-2). Discriminative: Good on trade-offs and deep topics like CAP/consistency under partitions, separates strong architects, but too broad (>10min).",
          "composite": 5.333333333333333
        }
      },
      {
        "role_id": "be-500",
        "role_title": "Staff Engineer - Streaming Architecture",
        "question": "You're designing a real-time data pipeline for a financial trading platform that must deliver market data to thousands of connected clients with zero data loss and sub-100ms latency. The pipeline consumes market data from Kafka, processes it in Rust, and delivers it via WebSocket. Design the event schema, delivery guarantees, and fan-out pattern for this system. Explain how you would ensure zero data loss and sub-100ms latency.",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (event schemas, delivery guarantees, fan-out) using Kafka (streaming infra) and Rust (processing), perfectly aligned. Clarity: Crystal clear intent and scope for screening, though lacks explicit time/format constraints (-1). Discriminative: Requires deep applied knowledge of trade-offs in schemas, guarantees (e.g., at-least-once), fan-out (e.g., pub-sub), and perf/loss mitigations, strongly separates strong architects from weak ones.",
          "composite": 9.333333333333334
        }
      }
    ]
  },
  "gpt-5-mini": {
    "model": "gpt-5-mini",
    "num_samples": 100,
    "avg_relevance": 9.22,
    "avg_clarity": 9.06,
    "avg_discriminative": 9.18,
    "avg_composite": 9.153333333333334,
    "results": [
      {
        "role_id": "be-403",
        "role_title": "Backend Engineer - Inference Optimization",
        "question": "You have a GPU-backed Triton Inference Server serving a ResNet50 model exported as ONNX. Clients send many small requests (batch size 1) with tight p50 latency requirements. Describe a concrete set of changes you would make (at least 3) to reduce tail latency and improve throughput, including how you would implement them in Triton/TensorRT and any trade-offs (accuracy, memory, complexity).",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core role skills (quantization, batching, GPU memory opt) using exact tech stack (Triton, TensorRT, ONNX, ResNet50); minor -1 for not explicitly listing quantization though implied. Clarity: Crystal clear scenario, specific asks (3+ changes, implementation, trade-offs), well-scoped. Discriminative: Requires applied knowledge of optimizations, trade-offs, and Triton/TensorRT specifics, strongly separates experts from generalists.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-401",
        "role_title": "Backend Engineer - Training Infrastructure",
        "question": "Describe how you would design a Kubernetes-native job scheduler for distributed PyTorch training using Ray to ensure fair and efficient GPU allocation across multiple concurrent jobs. In your answer (2\u20133 short paragraphs), include:\n- how the scheduler would track and reserve GPUs per node,\n- how it would handle Ray cluster autoscaling and pod placement to avoid GPU contention,\n- and one concrete policy for prioritizing or preempting jobs when GPUs are scarce.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core role skills (distributed ML training, GPU allocation, scheduling) with exact tech stack (Kubernetes, PyTorch, Ray); minor ding for Ray not explicitly listed but fits infrastructure context (-1 red flag avoided). Clarity: Crystal clear with specific requirements, scoped length, and no ambiguity. Discriminative: Tests deep applied knowledge, trade-offs in autoscaling/pod placement, and policy design, strongly separating experts from superficial knowers.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-402",
        "role_title": "Backend Engineer - Model Deployment",
        "question": "Describe a production deployment plan to roll out a new ML model version using KServe with canary releases and automated rollback on increased error rate. Include the metrics to monitor, how you'd implement the traffic split and promotion/rollback logic (mention KServe features or Kubernetes primitives), and a brief outline of the Python automation components that would perform detection and trigger rollout/rollback.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 10,
          "reasoning": "Relevance: Directly tests core role skills (model deployment, strategies, rollback) with KServe (ML deployment tool); minor ding as KServe not explicitly in role desc but fits perfectly (-1). Clarity: Well-scoped, specific asks with no ambiguity, ideal for screening. Discriminative: Requires deep applied knowledge of KServe/K8s, trade-offs in metrics/traffic/automation, strongly separates experts from juniors.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-406",
        "role_title": "Senior Backend Engineer - LLM Serving",
        "question": "You\u2019re building a high-throughput vLLM-based serving layer on Kubernetes that must support many concurrent chat sessions with low latency. Describe a strategy to manage and optimize the KV cache (key-value attention cache) across requests to minimize memory use and maximize reuse, including:\n- what data you would evict or shard and why,\n- how you\u2019d handle cache consistency across model replicas/pods,\n- how you\u2019d integrate this with request batching and streaming responses,\n- and one metric you\u2019d track to validate the approach.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 10,
          "reasoning": "Relevance: Directly tests core role skills (KV cache management, batching, streaming) with vLLM/K8s from description; minor ding for not explicitly mentioning batching optimization (-1). Clarity: Crystal clear, well-scoped with 4 specific subpoints, no bundling issues. Discriminative: Excellent at probing deep trade-offs, applied reasoning, and metrics; strong separation of experts from juniors.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-405",
        "role_title": "Senior Backend Engineer - Model Monitoring",
        "question": "Describe a production design for monitoring real-time ML model drift and performance using Python, Prometheus, Grafana, and PostgreSQL. In your answer (2\u20133 minutes) include:\n- what metrics you would collect (at prediction and batch levels) and why,\n- how you\u2019d detect concept and data drift (algorithms/approaches) and where that logic runs,\n- how you\u2019d store and aggregate metrics in PostgreSQL for historical analysis and query examples,\n- how you\u2019d expose metrics to Prometheus and build Grafana alerts/dashboards,\n- one tradeoff and one failure mode you would mitigate and how.",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 10,
          "reasoning": "Relevance: Perfectly matches role's core focus on model monitoring, drift detection, performance tracking, and alerting; uses relevant tech stack (Python, Prometheus, Grafana, PostgreSQL) without red flags. Clarity: Crystal clear with specific subtopics and time constraint; minor deduction for no explicit format guidance. Discriminative: Tests deep applied knowledge, trade-offs, and failure modes, strongly separating strong ML engineers from weak ones.",
          "composite": 9.666666666666666
        }
      },
      {
        "role_id": "be-410",
        "role_title": "Backend Engineer - Bulk Operations",
        "question": "Describe how you would design a REST API endpoint in Go to upsert a batch of 10,000 records into PostgreSQL, ensuring:\n- reasonable memory use and throughput,\n- idempotency for retries,\n- partial success reporting to the client,\nand how you would handle coordinating with Kafka for downstream processing and Redis for deduplication. Outline the flow, key data structures, error-handling strategy, and any PostgreSQL features (e.g., transactions, COPY, ON CONFLICT) you would use. Keep the answer to ~6\u201310 bullet points.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core role needs (bulk ops, batch processing, partial success, idempotency) with exact tech stack (Go, PostgreSQL); minor deduction as Kafka/Redis not explicitly in role but support idempotency/deduplication (-1). Clarity: Crystal clear, well-scoped with bullet-point limit, specific constraints, no ambiguity. Discriminative: Tests deep applied knowledge, trade-offs (memory/throughput), integration, and PostgreSQL features, strongly separates strong candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-408",
        "role_title": "Junior Backend Developer - Health Endpoints",
        "question": "Describe how you would implement liveness and readiness HTTP endpoints in a Go web service running in Kubernetes. Include:\n- the minimal behaviors each endpoint should have (what they must check or not check),\n- example HTTP status codes to return for healthy vs unhealthy,\n- how you would expose a Prometheus metrics endpoint alongside them,\n- and how you would configure Kubernetes liveness and readiness probes (path, port, initial delay, period) for a service that depends on an external database connection.",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Directly tests core role skills (liveness/readiness/metrics in Go/K8s) with no red flags. Crystal clear with specific subpoints, only minor vagueness on exact config values. Strong separation via applied knowledge, trade-offs in probe configs, and integration\u2014not pure recall.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-407",
        "role_title": "Staff Backend Engineer - ML Infrastructure",
        "question": "Describe a design for a reproducible, cost-efficient distributed training platform for large PyTorch models on Kubernetes that uses Ray for job orchestration and supports multi-tenant isolation. In 2\u20133 short paragraphs, explain:\n1) how you\u2019d schedule and launch training jobs (Ray + Kubernetes interaction, resource types, autoscaling),\n2) how you\u2019d ensure reproducibility and model versioning (data, code, env, random seeds),\n3) two concrete cost-optimization strategies you would implement (with brief trade-offs).",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's core focus on ML infrastructure, training platforms, cost optimization, and specifies exact tech (PyTorch, K8s, Ray) implied for such infra. No red flags.\nClarity: Crystal clear, well-scoped with specific points, paragraph limit, and structure; minor deduction as 'large models' lacks exact scale but still precise for screening.\nDiscriminative: Excellent at testing deep applied knowledge, trade-offs, and integration of multiple systems, strongly separating experienced ML infra leads from juniors.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-409",
        "role_title": "Junior Backend Engineer - File Upload",
        "question": "Design a small FastAPI endpoint (describe routes and request/response shapes\u2014no full code needed) to handle a client uploading a single file up to 50 MB that should be validated and stored to S3, and metadata recorded in PostgreSQL. Include:\n\n- the HTTP method and path,\n- how you'd accept the file in FastAPI (what parameter/type),\n- what validation you'd perform before upload (list checks),\n- how you'd stream or buffer the file to S3 to avoid high memory use,\n- what minimal metadata you'd write to PostgreSQL and when (what transaction strategy if any),\n- one brief error response you would return if validation fails.\n\nKeep the answer concise (2\u20135 short bullet points or lines).",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role (FastAPI file upload, multipart implied, validation, S3/PostgreSQL integration). Clarity: Crystal clear with specific subpoints and scoping (no full code, concise answer); minor -1 for bundled sub-asks. Discriminative: Tests applied knowledge of streaming, transactions, validation trade-offs for entry-level, strongly separates candidates.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-404",
        "role_title": "Senior Backend Engineer - Feature Platform",
        "question": "Describe how you would design and implement an end-to-end feature pipeline for a new real-time feature used in an online fraud detection model, using Feast (for feature store), Spark (for batch backfill/aggregation), Redis (for low-latency serving), and Python. In your answer, briefly outline:\n- the data sources and ingestion steps,\n- how you would compute and materialize the feature (batch and streaming) and handle backfills/consistency,\n- Feast entities/feature views and serving configuration (online vs. offline),\n- how you'd ensure low-latency reads in Redis and handle staleness/failure modes,\n- one observability or testing approach you would add to validate correctness in production.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core feature platform skills (computation, serving, discovery) with exact tech stack (Feast, Spark, Redis, Python) from role; minor generic penalty avoided (-0). Clarity: Crystal clear, well-scoped with 5 specific bullet points, no bundling issues. Discriminative: Probes deep applied knowledge, trade-offs (staleness, consistency, latency), and production concerns, strongly separating strong ML platform engineers.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-411",
        "role_title": "Backend Engineer - Admin APIs",
        "question": "Design a FastAPI endpoint for an admin-only route that deactivates a user account and records an audit log. In 6\u201310 lines of pseudocode or Python (no full app required), show:\n- the endpoint signature and method,\n- how you would enforce admin/privileged access (check a role in the request or token),\n- the transactional sequence to mark the user as deactivated in PostgreSQL and write an audit entry,\n- how you would handle and return errors if either the user does not exist or the audit write fails.\n\nAssume you have access to a DB session, a Redis cache client, and an Audit model; focus on control flow and error handling, not ORM specifics.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests FastAPI, PostgreSQL, admin auth/roles, audit logging, and transactional workflows\u2014core to role (-0 red flags). Clarity: Crystal clear with precise scope (6-10 lines pseudocode), explicit requirements, and assumptions provided. Discriminative: Requires applied knowledge of auth, transactions, error handling, and control flow trade-offs, strongly separating capable candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-416",
        "role_title": "Staff Backend Engineer - External APIs",
        "question": "Design a short API integration plan (4\u20136 bullet points) for exposing a new partner-facing endpoint that returns aggregated customer spending across multiple internal services. Include: the OpenAPI versioning approach, request/response shape considerations, authentication/authorization pattern (for partners), rate limiting/monetization model, and how you\u2019d deploy and enforce this with Kong on Kubernetes.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core API strategy, versioning, monetization, partner auth, and integration patterns with Kong/K8s (relevant for deployment/enforcement); minor ding as role emphasizes 'lead strategy' over specific tool like Kong (-1). Clarity: Crystal clear, well-scoped to 4-6 bullets with explicit topics, no bundling or ambiguity. Discriminative: Requires applied knowledge of trade-offs in API design, auth, rate limiting, monetization, and infra, strongly separating strategic thinkers from basics.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-415",
        "role_title": "Senior Backend Engineer - Multipart APIs",
        "question": "Design a resumable multipart upload API using Python + FastAPI for large files stored in S3. In 6\u20138 bullet points, describe the key endpoints you would expose, the request/response for each (including headers or parameters needed), how you would track upload state and chunks (data model or storage), how you'd ensure idempotency and handle duplicate/overlapping chunks, and how you\u2019d finalize and verify the assembled object in S3. Focus on concrete implementation details a senior engineer would use (e.g., checksums, chunk numbering, expiration, concurrency control), not high-level prose.",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 10,
          "reasoning": "Relevance: Perfectly matches role's core focus on resumable uploads, chunk management, S3, with Python/FastAPI directly testing required skills (no red flags). Clarity: Crystal clear, well-scoped with bullet point format, specific focus areas, and concrete details requested (minor deduction for no explicit time limit). Discriminative: Requires deep applied knowledge of trade-offs (idempotency, checksums, concurrency, state tracking), distinguishing seniors via implementation specifics vs superficial answers.",
          "composite": 9.666666666666666
        }
      },
      {
        "role_id": "be-412",
        "role_title": "Backend Engineer - Analytics APIs",
        "question": "Design an endpoint for a dashboard that returns per-minute counts of user events for a given 24-hour window, with optional filters by event type and user segment. Outline, in 6\u20138 bullet points, how you would implement it in Go using ClickHouse for storage and Redis for caching. Include (briefly) the ClickHouse query shape for efficient aggregation, cache key strategy and TTL, how to handle partial cache hits, and one safety/consistency consideration.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (aggregation queries, time-series, caching) with exact tech stack (Go, ClickHouse, Redis); minor deduction as role didn't specify Go (-1). Clarity: Crystal clear, well-scoped with bullet count, specific elements required, no ambiguity. Discriminative: Tests applied deep knowledge, trade-offs (partial cache, safety), query efficiency, and implementation specifics to separate strong candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-413",
        "role_title": "Senior Backend Engineer - API Gateway Logic",
        "question": "Describe how you would implement a per-tenant request transformation and routing feature in an Envoy-based API gateway using Go for control-plane logic and Lua for per-request processing. In your answer (2\u20133 short paragraphs), include:\n- where you would store tenant rules and how the proxy fetches them,\n- how you\u2019d apply transformations and routing decisions at request time (Envoy/Lua config and performance considerations),\n- how you\u2019d handle dynamic updates and safety (rollout, validation, failure modes).",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core role skills (API gateway extensions, request transformation, routing) with exact tech stack (Envoy, Go control-plane, Lua); minor ding for assuming Lua without explicit role mention (-1). Clarity: Crystal clear, well-scoped with specific points, paragraph limit, and no bundling/ambiguity. Discriminative: Probes deep applied knowledge, trade-offs (performance, safety, dynamic updates), distinguishing strong Envoy/Go/Lua experts from superficial ones.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-417",
        "role_title": "Junior Backend Developer - Event Sourcing",
        "question": "Given a Java service consuming user-account events from Kafka (events: AccountCreated, MoneyDeposited, MoneyWithdrawn) and storing a projection in PostgreSQL with columns (account_id, balance, version), briefly describe in 6\u20138 lines how you would implement the event handler for MoneyDeposited to ensure correct balances under concurrent delivery and out-of-order events. Mention how you would use the version column and any PostgreSQL feature or transaction pattern you\u2019d rely on.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core event sourcing skills (event handlers, projections, concurrency) for the role; uses exact events and tech stack (Java, Kafka, PostgreSQL); minor ding for not specifying all events but still spot-on (-1). Clarity: Crystal clear, well-scoped (6-8 lines, specific event), precise constraints. Discriminative: Excellent at separating candidates via trade-offs in versioning (optimistic locking), concurrency (idempotency, out-of-order handling), PostgreSQL features (UPSERT, transactions, SERIALIZABLE); requires applied deep understanding.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-414",
        "role_title": "Senior Backend Engineer - Long-Polling",
        "question": "Design a long-polling endpoint in Go for reporting progress of an async job (job IDs stored in PostgreSQL; recent progress updates pushed into Redis). In ~6\u20138 sentences describe:\n\n- the HTTP handler flow for a client that polls for job \"job123\" (how you check current state, decide to wait, and return),\n- how you\u2019d use Redis to avoid busy-waiting and wake waiting pollers when progress arrives,\n- how you\u2019d handle client timeouts and server-side cleanup to avoid leaked goroutines/connections,\n- one fallback strategy if Redis notifications are delayed or unavailable.\n\nBe concise and focus on concrete implementation choices (e.g., Redis pub/sub vs. streams, channels, context cancellation, use of setTimeout-like patterns).",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core role skills (long-polling APIs, connection mgmt, timeouts, fallbacks) with exact tech (Go, PostgreSQL, Redis); no red flags. Clarity: Crystal clear with precise scope (~6-8 sentences), specific subtopics, and concrete guidance; well-constrained for screening. Discriminative: Tests applied deep knowledge, trade-offs (pub/sub vs streams, context cancellation), and implementation choices to strongly separate strong candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-418",
        "role_title": "Junior Backend Engineer - Service Clients",
        "question": "Describe how you would implement a simple retry strategy for a Go gRPC client call that should:\n- retry only on transient errors (e.g., UNAVAILABLE, DEADLINE_EXCEEDED),\n- use exponential backoff with jitter,\n- limit to a maximum of 5 attempts and a total timeout of 10s,\n- avoid retrying non-idempotent RPCs.\n\nIn your answer, outline the key code-level steps or pseudocode (no full program required) and mention which gRPC or Go primitives/packages you would use.",
        "scores": {
          "relevance": 9,
          "clarity": 10,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core retry implementation for service clients in Go gRPC (-1 for not mentioning circuit breakers explicitly). Clarity: Crystal clear with precise constraints, scoped perfectly for screening, specifies pseudocode. Discriminative: Requires applied knowledge of gRPC errors, backoff/jitter, idempotency trade-offs, and Go primitives (e.g., google.golang.org/grpc/backoff), distinguishing strong entry-level candidates.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-420",
        "role_title": "Backend Engineer - Graceful Shutdown",
        "question": "Describe a concrete shutdown sequence for a Go gRPC server running in Kubernetes that ensures zero-downtime deployments. Include: the Kubernetes readiness/liveness signal changes, how you stop accepting new requests, how you handle in-flight RPCs and long-lived streams, how you coordinate with connection tracking (e.g., load balancer or proxy), and how you ensure the Pod terminates only after work is complete. Mention any relevant timeouts, gRPC APIs, and Kubernetes settings you would configure.",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 10,
          "reasoning": "Relevance: Perfectly matches role's core focus on graceful shutdown, zero-downtime deploys, signals, and connection draining in Go/gRPC/K8s context; no red flags. Clarity: Crystal clear, well-scoped with specific elements to cover, minor deduction only for lacking explicit time/format constraints. Discriminative: Requires deep applied knowledge of trade-offs, integrations (gRPC APIs, K8s probes, timeouts), and real-world coordination, strongly separating experts from others.",
          "composite": 9.666666666666666
        }
      },
      {
        "role_id": "be-419",
        "role_title": "Backend Engineer - Retry Logic",
        "question": "Describe, in Go-like pseudocode, a function that schedules retries for a distributed operation using exponential backoff with jitter and enforces a per-operation retry budget (max attempts and total elapsed time). Specify:\n- inputs (initialDelay, maxDelay, multiplier, jitterFraction, maxAttempts, maxElapsed)\n- how jitter is applied (explain exact formula)\n- how you decide to stop retrying (conditions)\n- one safety / distributed-systems concern (e.g., clock skew, duplicate side effects) and how you'd mitigate it.\n\nKeep the answer concise (pseudocode + 3\u20136 short bullets).",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 10,
          "reasoning": "Relevance: Perfectly matches role's core focus on retry infrastructure with exact parameters and concepts (10, no red flags). Clarity: Crystal clear with specific inputs, requirements, format, and scope; minor -1 for lacking strict word limit but well-constrained (9). Discriminative: Tests deep applied knowledge of backoff/jitter formulas, budget logic, pseudocode, and distributed systems trade-offs/safety\u2014strong separation of experts (10, no red flags).",
          "composite": 9.666666666666666
        }
      },
      {
        "role_id": "be-421",
        "role_title": "Senior Backend Engineer - Security Automation",
        "question": "Describe how you would design an automated pipeline that detects and remediates leaked static secrets in a Kubernetes cluster using Vault for secrets management. In your answer, include: the high-level components you would use (tools/services), how you would detect leaks (what signals and scanning approach), how you would validate and rotate affected secrets in Vault safely, how you would apply fixes to workloads in Kubernetes, and how you would ensure the pipeline is secure and minimizes disruption. Keep it high-level (no code), but include sequence/order and one potential failure mode and mitigation.",
        "scores": {
          "relevance": 9,
          "clarity": 10,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core security automation skills for vuln scanning/secrets rotation in cloud/K8s, matching role; minor ding for not explicitly mentioning compliance (-1). Clarity: Crystal clear, well-scoped with explicit requirements, sequence, high-level constraint, no ambiguity. Discriminative: Tests applied design knowledge, trade-offs (safety, disruption), failure modes; strong separation of deep vs shallow candidates.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-423",
        "role_title": "Staff Engineer - Incident Response Platform",
        "question": "Your incident platform receives alerts from Prometheus for a high-severity SLO breach. Describe, step-by-step, what automated actions your system should take within the first 5 minutes to (a) reduce customer impact and (b) ensure effective human response. For each step, name which component/service you'd implement it in (Go service, Kubernetes operator/job, PagerDuty, Slack integration, PostgreSQL, etc.) and one short reason why.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core incident response, SLO handling, alerting (Prometheus), and integration skills from role; minor ding for assuming PagerDuty/Slack not explicitly listed (-1). Clarity: Crystal clear, well-scoped to 5 minutes with parts (a/b), requires specific components/reasons. Discriminative: Forces applied reasoning on automation trade-offs, sequencing, and architecture choices, strongly separates candidates with SRE/incident expertise.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-422",
        "role_title": "Junior Backend Engineer - API Testing",
        "question": "You have a FastAPI endpoint POST /users that accepts JSON { \"email\": str, \"name\": str } and returns 201 with created user { \"id\": int, \"email\": str, \"name\": str }. Using pytest and TestClient, write a concise test that verifies:\n- posting valid data returns 201 and response body contains the same email and name and an integer id,\n- posting without \"email\" returns a 422 (validation error).\n\nYou don't need to implement the API\u2014just show the pytest test functions (including any minimal fixtures/imports) you would write.",
        "scores": {
          "relevance": 9,
          "clarity": 10,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests pytest + TestClient for API testing, core to role's API tests focus (-1 for not hitting contract testing/fixtures explicitly). Clarity: Crystal clear, well-scoped with exact requirements, no ambiguity. Discriminative: Requires writing functional test code covering happy path + validation error, tests applied pytest skills and FastAPI error handling knowledge, distinguishes capable entry-level from weak.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-425",
        "role_title": "Senior Backend Engineer - Graph Analytics",
        "question": "Describe a concrete approach to optimize a Neo4j query that computes personalized PageRank for a single user on a billion-edge social graph, to run within tight latency (e.g., <5s). Include: data/modeling changes, query or algorithm choice (built-in vs. custom), use of caching or precomputation (Redis/Postgres), and how you'd integrate Spark if needed. Be specific about trade-offs.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 10,
          "reasoning": "Relevance: Directly targets core role skills (graph analytics, Neo4j optimization, billion-scale traversal/PageRank) with minor ding for assuming Neo4j unlisted (-1). Clarity: Precise, well-scoped with specific components and example latency, no ambiguity. Discriminative: Forces deep trade-off analysis across modeling, algorithms, caching, and Spark integration, strongly separates experts from pretenders.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-424",
        "role_title": "Backend Engineer - Message Serialization",
        "question": "Describe how you would design an Avro-based message serialization strategy for Kafka that ensures backward and forward compatibility across services that evolve independently. In your answer, include:\n- the schema evolution rules you would enforce,\n- how you would use Schema Registry (including schema registration and compatibility settings),\n- how you would handle consumers that cannot be updated immediately (rolling upgrades),\n- one concrete example of a compatible schema change and one incompatible change and how your system would detect/prevent the incompatible change.",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's core focus on schema evolution, backward/forward compatibility, and validation using Avro/Schema Registry (directly tests listed skills, no red flags). Clarity: Crystal clear, well-scoped with specific subpoints, minor deduction for no explicit time constraint. Discriminative: Tests deep applied knowledge, trade-offs in evolution rules, Schema Registry config, upgrade strategies, and examples, strongly separates experts from juniors.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-426",
        "role_title": "Junior Backend Engineer - DevOps Scripting",
        "question": "Write a short Bash script (6\u201312 lines) that will be used in a GitHub Actions job to: 1) check that Docker is installed and running, 2) build a Docker image from the repository\u2019s Dockerfile with tag myapp:ci, and 3) run the image\u2019s tests by executing pytest inside a container (fail the script if any step fails). Include comments explaining each step.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core DevOps automation skills (Bash scripting, Docker, CI pipelines) for entry-level role; minor ding as GitHub Actions is implied not explicit (-1). Clarity: Precise line limit, clear 3 steps, comments required, well-scoped. Discriminative: Requires applied knowledge of Docker commands, container exec, error handling, and Bash scripting; distinguishes those who can integrate tools vs rote knowledge.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-428",
        "role_title": "Senior Backend Engineer - Payment Orchestration",
        "question": "Design a Go function signature and describe the algorithm (in 6\u201310 short bullet points) for selecting a payment provider for a transaction given: real-time provider health metrics (success rate, latency), per-provider cost, per-provider daily volume limits, and retry/failover constraints. Include how you would incorporate recent success rate decay, avoid flapping between providers, and handle concurrent requests updating usage counts stored in Redis. Keep it focused\u2014no full code, just the signature and the algorithm steps.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (routing, failover, cost/success optimization) with Go and Redis implied in context; minor generic ding (-1). Clarity: Crystal clear scope (signature + 6-10 bullets, focused constraints), no ambiguity. Discriminative: Requires applied trade-offs (decay, flapping, concurrency, metrics weighting), distinguishes deep understanding from superficial knowledge.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-427",
        "role_title": "Backend Engineer - Feature Store",
        "question": "Describe how you would design and implement a Feast feature table for a real-time user churn prediction feature \"days_since_last_activity\" that is computed from an events stream (Kafka) and materialized for low-latency serving from Redis, while keeping historical versions in PostgreSQL for training. In your answer (2\u20133 short bullet points or steps), specify:\n- the Feast entity and feature table schema (fields and types),\n- how you would compute and materialize the feature in real time (mention components: streaming job, Feast ingestion, Redis), and\n- how you would ensure consistent versioning/backfills for training data in PostgreSQL.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests Feast (core to feature stores), real-time streaming (Kafka/Redis), versioning (PostgreSQL), and ML pipeline skills matching role (-0 red flags). Clarity: Crystal clear with explicit specs, scoped to 2-3 bullets, no ambiguity or bundling. Discriminative: Requires applied knowledge of Feast schema/entities, streaming pipelines, and backfill/versioning trade-offs, strongly separates experienced candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-429",
        "role_title": "Backend Engineer - Log Aggregation",
        "question": "You operate a log pipeline in Go that receives JSON log events from Kafka at millions/sec, enriches them (add geo IP, service metadata), and writes them to ClickHouse via batch inserts. After deploying an enrichment change, you observe a small percentage of logs now fail ClickHouse inserts due to type mismatches introduced by the enrichment (e.g., adding nulls where non-nullable columns exist). Describe, step-by-step, how you would detect, mitigate, and permanently fix this problem in production with minimal data loss and downtime. Mention concrete techniques/tools (within the stack: Go, Kafka, ClickHouse, Vector, Kubernetes) and specific short-term vs long-term actions.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 10,
          "reasoning": "Relevance: Directly tests core log pipeline skills (parsing/enrichment/retention at scale) with exact stack (Go, Kafka, ClickHouse); minor -1 for including Vector/K8s not in role desc but highly relevant. Clarity: Crystal clear scenario, well-scoped steps, explicit stack/tools/constraints. Discriminative: Forces trade-offs (minimal loss/downtime), production debugging, short/long-term strategies distinguishing deep ops experience from superficial knowledge.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-431",
        "role_title": "Staff Engineer - Real-time Collaboration",
        "question": "Design a high-level architecture (components and data flow) for a multi-user real-time text editor using CRDTs over WebSocket. Include how you would:\n- ensure causality and convergence between clients,\n- handle offline edits and reconnection,\n- persist document state in PostgreSQL and use Redis for presence/notification,\n- mitigate unbounded metadata growth in the CRDT.\n\nBe concise (3\u20136 bullet points or short paragraphs).",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's focus on real-time collaboration, CRDTs, operational transforms (implied), presence, conflict resolution; uses exact tech (PostgreSQL, Redis); no red flags. Clarity: Crystal clear, well-scoped with bullet points, constraints, and conciseness limit; minor jargon but contextual. Discriminative: Tests deep applied knowledge, trade-offs (causality, growth mitigation), architecture skills; distinguishes strong architects from basics; concise format prevents overlong answers.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-435",
        "role_title": "Junior Backend Engineer - Queue Consumers",
        "question": "You have a Python consumer that reads JSON messages from a RabbitMQ queue and inserts rows into PostgreSQL. Occasionally the same message is delivered twice. Describe a simple, practical design (including any DB schema changes and RabbitMQ acknowledgment strategy) to ensure each message is processed exactly once (idempotent behavior) without requiring distributed transactions. Explain briefly how your design handles duplicate deliveries and what the consumer should do on processing errors.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core idempotency skills for message queue consumers using exact tech stack (RabbitMQ, PostgreSQL, Python); minor deduction as it doesn't explicitly cover dead letter handling. Clarity: Crystal clear, well-scoped with specific constraints (no distributed tx, simple/practical), single focused question. Discriminative: Requires applied knowledge of acks, DB upserts, deduping strategies, error flows, and trade-offs, strongly separating candidates with real understanding.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-430",
        "role_title": "Junior Backend Engineer - Search Indexing",
        "question": "You need to build a periodic job (runs every few minutes) that updates an Elasticsearch index from a PostgreSQL table of products. Describe, in bullet points, a simple, reliable approach to:\n\n- detect which rows changed in PostgreSQL since the last run,\n- transform rows into documents suitable for Elasticsearch,\n- send updates efficiently to Elasticsearch (minimize load and ensure consistency),\n- handle transient failures so you don\u2019t lose updates or create duplicates.\n\nBe concise \u2014 6\u201310 short bullets covering the key steps/techniques and any small decisions (e.g., use of timestamps, bulk API, idempotency).",
        "scores": {
          "relevance": 9,
          "clarity": 10,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core skills (bulk indexing, search indexing jobs) for entry-level role; minor ding as doesn't explicitly cover mapping design or relevance tuning (-1). Clarity: Crystal clear, well-scoped with constraints (periodic, simple/reliable, 6-10 bullets, specific sub-asks). Discriminative: Requires applied knowledge of CDC patterns, ES bulk API, idempotency, failure handling; distinguishes those understanding trade-offs from rote memorizers.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-432",
        "role_title": "Backend Engineer - Data Validation",
        "question": "Describe how you would implement a Great Expectations checkpoint in an Airflow DAG to validate a daily batch of parquet files stored in S3 before loading into Postgres. Include:\n- the key expectations you would define (at least three) for schema, nulls, and distribution/uniqueness;\n- how you would trigger and fail the Airflow task on validation errors;\n- how you would surface validation results and lineage (where you would store reports and metadata).\n\nKeep the answer concise (2\u20135 minutes).",
        "scores": {
          "relevance": 9,
          "clarity": 10,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core data validation, schema checks, and lineage using Great Expectations (ideal for pipeline quality), Airflow, S3, Parquet, Postgres\u2014all highly relevant; minor ding as role doesn't explicitly list GE/Airflow (-1). Clarity: Crystal clear with specific requirements, scoped by time and components, no ambiguity. Discriminative: Requires applied knowledge of integration, trade-offs in expectations, failure handling, and reporting\u2014strong separation of experts from juniors.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-434",
        "role_title": "Principal Engineer - Database Strategy",
        "question": "You\u2019re designing a multi-region database strategy for a customer-facing SaaS with global users and strict RPO/RTO SLAs. Given PostgreSQL, CockroachDB, Redis, Kafka, and Kubernetes, describe (in 3\u20135 bullet points) your recommended architecture for OLTP (primary transactional) and caching/streaming components, explain one major trade-off for your choice, and list two operational controls you\u2019d enforce to meet RPO/RTO across regions.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core multi-region DB strategy, tech selection (PostgreSQL, CockroachDB match distributed needs; Redis/Kafka for caching/streaming; Kubernetes for ops), and migration/ops excellence (-1 for minor techs like Redis not core OLTP but role-appropriate). Clarity: Precise scope (3-5 bullets, components, trade-off, controls), unambiguous. Discriminative: Requires applied architecture knowledge, trade-offs, and RPO/RTO ops, distinguishing strong strategists.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-433",
        "role_title": "Senior Backend Engineer - Platform APIs",
        "question": "Design a small Go-based HTTP/gRPC service interface for a platform \"service catalog\" that lets developers (1) list available services, (2) request provisioning of a service instance with parameters, and (3) get the provisioning status. For each endpoint/method, specify:\n- the endpoint/method signature (HTTP path + verb or gRPC RPC name and request/response messages),\n- key request and response fields (include minimal validation rules),\n- one database table schema (Postgres) to store service instances and their status,\n- and one brief note on how you would ensure idempotent provisioning requests (concurrent-safe).\n\nKeep answers concise (bullet points OK).",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core role skills (platform APIs, service catalog, provisioning) with exact Go/HTTP/gRPC/Postgres match; minor ding for not explicitly mentioning self-service UI. Clarity: Crystal clear, well-scoped with exact requirements and constraints. Discriminative: Tests applied design (signatures, validation, schema, idempotency), trade-offs (concurrency), distinguishes strong API designers from basics.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-437",
        "role_title": "Senior Backend Engineer - Secrets Management",
        "question": "Design, at a high level, an automated secret rotation system for database credentials stored in HashiCorp Vault used by services running in Kubernetes. Explain the Vault components and policies you would use, how rotation would be triggered and performed (including how you would ensure zero-downtime credential swaps), how services authenticate to Vault, and how audit logging and rotation failures would be handled. Be specific about Vault roles/mounts/secret engines, Kubernetes auth, and any coordination with AWS KMS or PostgreSQL. (Answer in 2\u20135 minutes.)",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core secrets management, rotation, Vault, K8s, encryption (KMS), and DB (PostgreSQL) from role; minor ding for assuming AWS/PostgreSQL not explicitly listed (-1). Clarity: Crystal clear, well-scoped with time limit, specific components listed, no bundling or ambiguity. Discriminative: Requires deep applied knowledge of trade-offs (zero-downtime, failure handling), Vault internals, and integrations; strong separation of experts from juniors.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-436",
        "role_title": "Backend Engineer - API Documentation",
        "question": "You\u2019re building a TypeScript-based tool that scans a Node.js codebase to auto-generate OpenAPI specs for multiple API versions (v1, v2). Describe, at a high level and in 6\u20138 brief steps, how you would implement:\n- detection and grouping of endpoints by version,\n- generation of OpenAPI paths/components with example payloads,\n- and a strategy to handle incremental updates (only regenerate changed endpoints) so SDKs can be rebuilt efficiently.\n\nBe specific about file/metadata sources you\u2019d use (route annotations, code comments, separate manifest, tests), how you\u2019d generate examples (static examples, JSON Schema-based fuzzing, using TypeScript types), and how you\u2019d detect changes (hashing, timestamps, AST diffs).",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core role skills (auto-gen specs, versioning, SDK automation) with exact tech stack (TypeScript/Node.js/OpenAPI); minor deduction as role doesn't explicitly list all sub-details like AST diffs (-1). Clarity: Crystal clear, well-scoped (6-8 steps, high-level), specific constraints provided, no bundling. Discriminative: Requires applied knowledge of parsing, example gen strategies, change detection trade-offs; distinguishes deep thinkers via specifics like sources/hash methods.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-439",
        "role_title": "Backend Engineer - Billing Integration",
        "question": "Design a minimal approach (2\u20134 bullet steps or a short code sketch) to handle prorated subscription upgrades in a SaaS app using Stripe, PostgreSQL, and Celery. Include how you would:\n- detect and calculate a prorated charge when a customer upgrades mid-period,\n- create or adjust the Stripe invoice/payment so the customer is billed correctly,\n- update your local PostgreSQL subscription record atomically,\n- and ensure the background processing is idempotent (Celery task considerations).\n\nKeep the answer concise.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core billing/proration skills with exact tech stack (Stripe, PostgreSQL, Celery); no red flags. Clarity: Crystal clear, well-scoped with constraints (2-4 bullets/code sketch, concise), specific subpoints without bundling. Discriminative: Requires applied knowledge of integration, atomicity, idempotency, and trade-offs, strongly separates strong candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-440",
        "role_title": "Junior Backend Engineer - Metrics Collection",
        "question": "Describe how you would instrument a simple HTTP handler in Go to track:\n1) total requests received,\n2) current in-flight requests,\n3) request duration distribution (suitable for latency percentiles in Grafana).\n\nSpecify which Prometheus metric types you would use for each, show the minimal Go code (using the Prometheus Go client) to register and update these metrics inside the handler, and explain any important labeling choices.",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role (instrumenting with counter/gauge/histogram for metrics/dashboards in Go, Prometheus implied for Grafana). No red flags. Clarity: Crystal clear, well-scoped with specifics (types, minimal code, labels); minor deduction as no explicit time constraint. Discriminative: Requires applied knowledge of metric patterns, Go client usage, labeling trade-offs; distinguishes those who can implement from theorists.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-445",
        "role_title": "Junior Backend Engineer - Database Migrations",
        "question": "You need to add a non-nullable column \"status\" (text) to a large PostgreSQL table \"orders\" in production without causing downtime. Describe, step-by-step, how you would implement this change using Alembic migrations and SQL (including any data backfill and how to avoid long locks). Include the commands or SQL snippets you would run in each migration step and explain why each step is needed.",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 10,
          "reasoning": "Relevance: Perfectly targets core role skills (database migrations, zero-downtime, PostgreSQL) with Alembic; no red flags. Clarity: Crystal clear, step-by-step scope, specific constraints; minor deduction for lacking explicit time limit. Discriminative: Tests deep applied knowledge of migration patterns, backfill, locks, and trade-offs, strongly separates capable candidates.",
          "composite": 9.666666666666666
        }
      },
      {
        "role_id": "be-438",
        "role_title": "Staff Engineer - ML Serving Infrastructure",
        "question": "Describe a production design to serve a deep-learning model for real-time (\u226450ms p99) inference at 10,000 QPS using Triton on Kubernetes. In your answer (2\u20133 short paragraphs or bullet points) include: how you would configure model versioning and rollout, batching strategy (static vs dynamic, max batch size, latency tradeoffs), GPU utilization (TensorRT usage, instance sizing), and what Prometheus metrics/alerts you would instrument to detect SLA breaches and model regressions.",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 10,
          "reasoning": "Relevance: Perfectly matches role's core focus on ML serving infra, batching, versioning, and latency opt, directly testing Triton/K8s stack. Clarity: Crystal clear with precise scope (\u226450ms p99, 10k QPS), explicit requirements, and response format; minor jargon assumed for role. Discriminative: Forces deep trade-offs (batching types/sizes, GPU sizing, metrics), distinguishing architects from juniors via production reasoning.",
          "composite": 9.666666666666666
        }
      },
      {
        "role_id": "be-441",
        "role_title": "Senior Backend Engineer - Autocomplete Systems",
        "question": "Describe a complete backend design (components and data flow) for an autocomplete service that supports prefix matching and per-user personalization, must handle 100K QPS with p95 latency <50ms. Include:\n- how you\u2019d store/index suggestions (Elasticsearch/Redis/Postgres roles),\n- how you\u2019d incorporate personalization at query time (ranking, caching, feature sources),\n- how you\u2019d keep results fresh with updates (streaming from Kafka),\n- key scaling and latency optimizations (sharding, caching tiers, read path),\nand one concrete tradeoff you\u2019d make (and why).",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 10,
          "reasoning": "Relevance: Directly targets core role skills (autocomplete, prefix matching, personalization, 100K QPS, <50ms p95); mentions relevant tech (ES/Redis/Postgres/Kafka) without red flags (-0). Clarity: Well-scoped with explicit components, constraints, and structure; no bundling or ambiguity. Discriminative: Tests deep applied knowledge, trade-offs, and optimizations, strongly separating strong candidates who can reason about scale/personalization from weak ones.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-442",
        "role_title": "Backend Engineer - Event Streaming",
        "question": "Design a short architecture and describe the algorithm (no code) for a real-time event delivery component that meets these requirements:\n\n- Receives events published to NATS subjects.\n- Supports per-subscriber filtering by event type and a simple JSON field (e.g., user_id).\n- Delivers events to subscribers over WebSocket with low latency and at-least-once semantics.\n- Allows replay of missed events for up to 1 hour from Redis-backed storage.\n- Minimizes fan-out work when many subscribers share the same filters.\n\nIn your answer (2\u20135 minutes): outline the components, message flow, how you implement filtering and efficient fan-out, how replay is handled, and how at-least-once delivery is achieved. Mention any trade-offs.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core event streaming skills (fan-out, filtering, replay) and exact tech (NATS, WebSocket, Redis) from role; minor deduction as it doesn't specify scale. Clarity: Crystal clear with precise requirements, scoped to 2-5 min, no ambiguity. Discriminative: Requires applied architecture knowledge, trade-offs, and optimizations (efficient fan-out, at-least-once), strongly separating strong candidates who grasp real-time systems from weak ones.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-444",
        "role_title": "Backend Engineer - Service Templates",
        "question": "You\u2019re building a Cookiecutter-based service template for Go microservices that must enforce:\n- a standardized project layout,\n- automated GitHub Actions CI that builds, runs unit tests, and builds a Docker image,\n- Kubernetes manifests and an ArgoCD-friendly overlay,\n- default observability (Prometheus metrics + OpenTelemetry) and security best practices (RBAC least privilege, vulnerability scanning).\n\nDescribe, in 6\u20138 bullet points, the concrete files or template variables you would include in the Cookiecutter template and one CI job from GitHub Actions (name + key steps) to implement those requirements. Be specific about filenames/paths, tools, and any sensible defaults.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (Cookiecutter templates, CI/CD with GitHub Actions, observability, security, K8s/ArgoCD) with exact tech stack; minor deduction for not explicitly mentioning all role aspects like general scaffolding. Clarity: Crystal clear scope (6-8 bullets, specific files/vars/CI job), well-constrained for screening. Discriminative: Requires applied knowledge of tools/files/paths/practices with trade-offs (e.g., sensible defaults), strongly separates candidates familiar with Go microservices tooling from others.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-446",
        "role_title": "Staff Engineer - Distributed Tracing",
        "question": "Describe a complete sampling strategy you would implement for a high-traffic microservices platform (millions of traces/day) that balances cost, fidelity for debugging, and SLO-driven monitoring. Include:\n- how you would combine sampling types (e.g., head-based, tail-based, probabilistic, adaptive) and where they run (client/agent/collector),\n- the signals you would use to decide which traces to keep at higher fidelity,\n- how you would ensure rare but important traces (errors, latency outliers, transactional joins) are retained,\n- how OpenTelemetry/Jaeger components and Kafka/ClickHouse would fit into the pipeline,\n- and how you would measure and validate that the strategy meets both cost and observability goals.",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 10,
          "reasoning": "Relevance: Perfectly matches role's core focus on distributed tracing, sampling strategies, SLO correlation, and specified tech (OpenTelemetry/Jaeger, Kafka/ClickHouse); no red flags. Clarity: Crystal clear, well-scoped with explicit subpoints, minor deduction for lacking explicit time constraint. Discriminative: Tests deep applied knowledge, trade-offs (cost vs fidelity), system design integration, and validation\u2014excellent separation of strong architects from others.",
          "composite": 9.666666666666666
        }
      },
      {
        "role_id": "be-443",
        "role_title": "Senior Backend Engineer - Data Lake Architecture",
        "question": "Describe a concrete approach to implement partition pruning and efficient predicate pushdown for a large Iceberg table on S3 when queried via Spark and Trino. In your answer (briefly, 3\u20135 bullet points) include:\n- how you would design the table layout/partitioning and why,\n- what Iceberg features and metadata you would use to avoid full-file scans,\n- any Spark and Trino settings or query patterns you would apply to ensure pruning works end-to-end,\n- how you would validate performance and detect mis-pruning after deployment.",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 10,
          "reasoning": "Relevance: Perfectly matches role's data lake, Iceberg, schema evolution, partition pruning focus; no red flags. Clarity: Crystal clear with specific scope (3-5 bullets), well-formed components; minor deduction possible for bundled subpoints but highly scoped. Discriminative: Tests deep applied knowledge, trade-offs, end-to-end implementation, validation\u2014strong separation of experts from juniors.",
          "composite": 9.666666666666666
        }
      },
      {
        "role_id": "be-447",
        "role_title": "Backend Engineer - Load Shedding",
        "question": "You run a Go microservice behind Envoy that receives mixed-priority RPCs (high, medium, low). Under overload you must shed low-priority work first, then medium, while preserving high-priority requests. Describe, at a high level, a practical design you would implement to accomplish this using in-process and infrastructure signals (include how Envoy, Redis, and Prometheus metrics could be used). Specifically explain:\n- how requests are classified and queued/throttled in the Go service,\n- what backpressure or throttling signals you consume/emit (from/to Envoy, Redis, Prometheus),\n- how adaptive thresholds are computed/updated,\n- and how you ensure graceful degradation without starving medium/high priority work.\n\nKeep the answer to ~4\u20136 concise bullet points or short paragraphs.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core role skills (load shedding, priority queues, adaptive throttling, backpressure) with exact tech (Go, Envoy, Redis, Prometheus); minor ding for assuming Redis/Prometheus not explicitly listed (-1). Clarity: Crystal clear, well-scoped with specific subpoints and answer format; no bundling or ambiguity. Discriminative: Tests applied design with trade-offs (classification, signals, adaptive logic, non-starvation), strong separation of deep understanding vs superficial knowledge.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-448",
        "role_title": "Senior Backend Engineer - Webhook Infrastructure",
        "question": "Design at a high level the data model and delivery flow for a webhook delivery system that guarantees at-least-once delivery, supports per-recipient exponential backoff with jitter, and records delivery analytics (success/failure, latency, attempts). Use Go services, Kafka for work queuing, PostgreSQL for state, Redis for rate-limiting, and Kubernetes for running workers. In 6\u20138 concise bullet points show:\n- the main tables/keys you\u2019d store in Postgres/Redis (fields and purpose),\n- how Kafka topics and consumer groups are used,\n- how a worker processes a delivery (including signature verification, idempotency/deduplication, and retry scheduling),\n- how you implement exponential backoff with jitter and per-recipient rate limiting,\n- how you capture delivery metrics for analytics and avoid double-counting on retries.\n\n(Keep the answer short \u2014 enough detail to show you can implement this in the given stack.)",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's core needs (webhook delivery, retries, signatures, analytics) and exact tech stack. Clarity: Crystal clear, well-scoped with bullet points, stack, and length limit; minor deduction for no time constraint. Discriminative: Tests deep applied knowledge of distributed systems, trade-offs (backoff/jitter, idempotency), and stack integration, strongly separates strong candidates.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-449",
        "role_title": "Junior Backend Engineer - Auth Integration",
        "question": "You\u2019re implementing an OAuth2 social login flow in a Node.js + TypeScript backend. After exchanging an authorization code for an access token and refresh token from the provider, describe (in 6\u20138 short bullet points or ~4\u20136 sentences) the next backend steps you would take to:\n- securely store or persist tokens in PostgreSQL,\n- associate the external account with an internal user account (new or existing),\n- handle using and refreshing the access token for future API calls,\nand mention one security risk to mitigate and how you would mitigate it.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets OAuth2 flows, token handling, and social login patterns core to the role's Node.js/TS/PostgreSQL stack (-0 red flags). Clarity: Precise scope (6-8 bullets/~4-6 sentences), unambiguous steps requested, no bundling or vagueness. Discriminative: Requires applied knowledge of secure storage, account linking, refresh logic, and security trade-offs, distinguishing strong entry-level candidates without being trivial or overly broad.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-451",
        "role_title": "Backend Engineer - Subscription Billing",
        "question": "Describe how you would design and implement proration when a customer changes from Plan A ($10/month, billed monthly) to Plan B ($30/month, billed monthly) halfway through their billing period. In your answer, include:\n- the data you would store (relevant fields in billing/usage records),\n- how you would calculate the prorated charge/credit,\n- how you would record the invoice/ledger entries,\n- how you would handle edge cases such as negative balances, existing credits, and concurrent plan changes (assume Java + PostgreSQL + Kafka + Spring Boot).",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Directly tests core proration skill from role description with precise scenario and specified stack; clear sub-parts with good scope; probes deep applied knowledge, trade-offs (edges, concurrency), distinguishes strong candidates. Minor ding for assuming concurrent changes without full constraints.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-452",
        "role_title": "Senior Backend Engineer - Faceted Search",
        "question": "Describe a performant approach to compute accurate facet counts for multiple filters in Elasticsearch when users can apply arbitrary combinations of filters (e.g., category, brand, price ranges). Explain how you would:\n1) Structure the aggregations to avoid incorrect counts due to active filters,\n2) Optimize for low latency at scale (millions of docs, high QPS),\n3) Handle expensive facets like ranges or nested fields.\n\nBe concise\u2014outline the aggregation strategy (types and scope), caching or precomputation you\u2019d use (if any), and any trade-offs.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core role skills in faceted search, dynamic filtering, aggregation optimization, and facet accuracy at scale in Elasticsearch (-0 red flags). Clarity: Crystal clear, well-scoped with specific subpoints, constraints (concise, outline), no ambiguity. Discriminative: Tests deep applied knowledge of ES aggs (post_filter, filters agg), optimizations (composite aggs, caching), trade-offs\u2014strong separation of experts from juniors.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-450",
        "role_title": "Principal Engineer - ML Platform Strategy",
        "question": "You\u2019re advising a mid-size company that currently has scattered ML experiments (Jupyter notebooks, ad-hoc scripts), some models in production behind Flask APIs on VMs, and plans to scale from 5 to 50 ML engineers. They already use Kubernetes for services. In 3\u20134 bullet points, outline the top 4 strategic platform decisions you would make in the next 6 months (tooling choices + governance) to enable scalable, reproducible model development and safe productionization \u2014 include one concrete trade-off for each decision.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests ML platform strategy, tooling, governance, and scaling\u2014core to role; leverages Kubernetes from context, no red flags (-0). Clarity: Precise scope (3-4 bullets, top 4 decisions, 6 months, includes trade-offs), unambiguous for screening. Discriminative: Requires applied strategic thinking, trade-offs, and MLops depth to distinguish experts from generalists; structured format ensures depth without being too broad.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-453",
        "role_title": "Backend Engineer - Notification Delivery",
        "question": "Design a simple Go function (pseudocode or explanation + key code snippets) that takes a list of device registrations and a notification payload, then prepares and groups the deliveries for sending to FCM and APNS with batching and de-duplication. Include how you would:\n- determine platform (FCM vs APNS) and group devices into batches (e.g., max 500 for FCM),\n- de-duplicate multiple registrations for the same user/device token,\n- return a structure ready for concurrent workers to send (batch metadata: platform, tokens, user_ids, payload).\n\nKeep the answer short\u2014show the core algorithm and data structures, not full implementation.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests Go, device registration grouping, batching, de-duplication, and delivery prep for FCM/APNS\u2014core to push notification system (-1 minor for pseudocode allowance). Clarity: Well-scoped with constraints (max 500, short answer, core algorithm focus), unambiguous. Discriminative: Requires applied knowledge of grouping, dedup, platform logic, data structures, and concurrency prep\u2014tests trade-offs like batch sizing, strong separation of good candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-454",
        "role_title": "Junior Backend Engineer - ETL Scripts",
        "question": "You have a CSV file with columns: user_id (int), event_time (ISO timestamp), event_type (string), value (float). Write a short Python (pandas) code snippet that:\n- Loads the CSV,\n- Keeps only rows where event_type is \"purchase\" and value > 0,\n- Converts event_time to UTC datetime and sets it as the DataFrame index,\n- Resamples the data to hourly buckets computing the sum of value per hour,\n- Writes the result to a Postgres table named hourly_purchases (assume SQLAlchemy engine variable `engine` exists).\n\nYou can assume standard imports (pandas as pd) and that event_time has timezone info or is UTC.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core ETL skills (load, filter, transform, aggregate, write to DB) with pandas for entry-level data scripting; minor Postgres mention fits data patterns (-1 for not in desc). Clarity: Precise steps, assumptions clear, well-scoped snippet. Discriminative: Requires chaining pandas ops, resampling, datetime handling, DB integration; tests applied ETL knowledge with trade-offs in bucketing/indexing.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-457",
        "role_title": "Senior Backend Engineer - SLO Automation",
        "question": "Design a Prometheus + Go-based service that tracks SLOs and fires burn-rate alerts. Briefly (2\u20135 minutes) describe:\n1) the metrics you would ingest from services to compute error budget and burn rate (names, types, labels),\n2) the algorithm/Prometheus query you\u2019d use to compute burn rate over a sliding window and trigger an alert,\n3) one Go component you would implement for SLO automation (what it does, inputs/outputs), and one key reliability concern and how you\u2019d mitigate it.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets Prometheus, Go, SLO/burn rate/error budget core to role (-0 red flags). Clarity: Well-scoped (2-5 min, numbered parts, specific asks), unambiguous despite multi-part. Discriminative: Probes applied knowledge (metrics, queries, algo, component, trade-offs/concerns) to separate strong role-fit candidates from weak ones.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-455",
        "role_title": "Staff Engineer - Developer Portal",
        "question": "Design a Backstage plugin and data model to onboard a new microservice and expose its API docs and health status in the developer portal.\n\nDescribe, in 3\u20135 bullet points or a short paragraph:\n- the Backstage entities and annotations you would use or extend (what fields/relations matter),\n- the plugin responsibilities (what backend and frontend parts do),\n- how you\u2019d implement an automated onboarding flow (what components run, validations, and how to persist metadata to the catalog),\n- one approach to surface runtime health and API docs (e.g., OpenAPI) in the UI and how you'd keep them up to date.\n\nFocus on concrete technologies/techniques (TypeScript/Node backend, PostgreSQL storage if used, how to validate/ingest metadata, polling vs event-driven updates), not high-level fluff.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests Backstage plugin design, entities, and onboarding flows\u2014core to the role; uses exact tech (TypeScript/Node) with no red flags (-0). Clarity: Precise scope (3-5 bullets/paragraph, specific subtopics), concrete tech requirements, well-constrained (-0). Discriminative: Probes deep applied knowledge of Backstage specifics, trade-offs (polling vs events), automation\u2014strong separation of experts from superficial knowledge.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-458",
        "role_title": "Backend Engineer - API Gateway Plugins",
        "question": "Describe how you would implement a Kong plugin (in Lua) that enforces per-client rate limits stored in Redis and adds an X-RateLimit-Remaining header to responses. In 6\u20138 bullet points, outline the plugin phases you\u2019d use, where you\u2019d interact with Redis, how you\u2019d handle race conditions and Redis failures, and what response/status you\u2019d return when a client is over the limit. Include any Kong or Lua patterns you would use for performance (e.g., timers, shared dictionaries, or nginx lua phases).",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 10,
          "reasoning": "Relevance: Directly tests Kong/Lua plugin development, Redis integration, and API gateway features (rate limiting, headers) core to the role; minor ding as role doesn't explicitly list Redis/Kong but matches plugin/auth/transformation focus (-1 red flag avoided). Clarity: Crystal clear with scoped bullet-point format, specific phases/handling asked, no ambiguity or bundling. Discriminative: Excellent at separating strong candidates via trade-offs (race conditions, failures), applied Kong/Lua patterns, and performance optimizations; not recall, deeply role-specific.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-456",
        "role_title": "Backend Engineer - Query Optimization",
        "question": "You have a PostgreSQL table orders(order_id PK, user_id, product_id, status, created_at TIMESTAMP, total NUMERIC) with millions of rows. Users query recent completed orders for a user like:\n\nSELECT * FROM orders WHERE user_id = $1 AND status = 'completed' AND created_at >= now() - interval '30 days' ORDER BY created_at DESC LIMIT 50;\n\nThe current execution is a sequential scan. Describe (briefly) what index(s) you would create to optimize this query, why, and any trade-offs or additional changes (e.g., vacuuming, stats, partial or covering index) you would consider.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (query optimization, index recommendations, slow query detection) using PostgreSQL and exact query pattern from role (-1 minor for not explicitly mentioning plan analysis). Clarity: Crystal clear, well-scoped with specific table/query/EXPLAIN result, asks for brief response with explicit considerations. Discriminative: Requires applied knowledge of multicolumn/partial/covering indexes, trade-offs (write overhead, storage), and PG-specific maintenance, strongly separates candidates able to reason through real optimization.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-460",
        "role_title": "Backend Engineer - Experiment Tracking",
        "question": "You have an ML experiment pipeline that logs metrics and models to MLflow (tracking server backed by PostgreSQL, artifacts to S3). Developers report that when training many short-lived experiments in parallel (10s\u2013100s concurrently), MLflow\u2019s tracking server slows and some runs fail to log artifacts. Describe the most likely causes at the MLflow / infra layer and list three concrete, prioritized changes you would make to reliably support high-concurrency experiment logging. For each change, include the reason, a brief implementation approach, and one way to validate it worked.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests MLflow, PostgreSQL, S3, and high-concurrency logging core to the experiment tracking role; minor -1 for not explicitly mentioning model comparison. Clarity: Crystal clear, well-scoped with specific scenario, asks for prioritized changes with exact structure. Discriminative: Requires deep applied knowledge of MLflow bottlenecks, trade-offs in infra scaling, and validation\u2014strong separation of experts from superficial knowers.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-459",
        "role_title": "Junior Backend Engineer - Container Security",
        "question": "You need to add automated container image scanning to a CI pipeline using Trivy. Describe, step-by-step, the minimal set of commands or CI steps to (1) scan a built Docker image for CVEs, (2) fail the pipeline if any HIGH or CRITICAL vulnerabilities are found, and (3) output a human-readable report. Include the Trivy command(s) and any Docker commands or flags you would use.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests container scanning with Trivy, core to role's vulnerability detection focus (-1 for assuming Trivy/CI knowledge not explicitly listed). Clarity: Precise, step-by-step with clear tasks 1-2-3, well-scoped for screening. Discriminative: Requires practical applied knowledge of Trivy flags, thresholding, and pipeline integration, distinguishing those who can execute from theorists.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-463",
        "role_title": "Junior Backend Engineer - Full-text Search",
        "question": "You have a PostgreSQL table \"articles\" with columns id (int), title (text), body (text), and a tsvector column search_vector that combines title and body. Write a single SQL query that:\n- searches for the phrase \"open source\" (should match as a phrase),\n- ranks results giving twice the weight to matches in title vs body,\n- returns id, title, snippet (a short excerpt highlighting matches), and a relevance score,\n- orders by score descending and limits to top 10.\n\nYou may assume the search_vector was created using setweight(to_tsvector(title), 'A') || setweight(to_tsvector(body), 'B'). Use plainto_tsquery or phraseto_tsquery as appropriate.",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's PostgreSQL full-text search focus (tsvector, ranking, optimization), uses exact tech from role; no red flags. Clarity: Crystal clear, well-scoped with assumptions and hints provided; minor deduction for not specifying exact ts_rank function. Discriminative: Requires applied knowledge of phrase search, weighting, ranking, snippets, distinguishing strong PostgreSQL candidates; not trivial recall.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-464",
        "role_title": "Staff Engineer - Presence Systems",
        "question": "Design a scalable heartbeat and connection-management scheme for a WebSocket-based presence system used by 10 million concurrent users across multiple datacenters. In 3\u20135 bullet points, describe:\n1) the heartbeat protocol (intervals, payload, client/server behavior) and how it minimizes false disconnects while limiting bandwidth;\n2) how you detect and reconcile stale connections when clients or servers crash (including cross-datacenter cases);\n3) how you store and propagate presence state (online/away/typing) with Redis and Kafka to ensure eventual consistency and low read latency.",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 10,
          "reasoning": "Relevance: Perfectly matches role's core focus on heartbeat protocols, connection management, state synchronization at scale, using specified tech (Redis/Kafka); no red flags. Clarity: Crystal clear with precise scoping (3-5 bullets, numbered parts), minor deduction for lacking exact time constraint. Discriminative: Requires deep applied knowledge of trade-offs (bandwidth vs reliability, crash detection, multi-DC consistency), strongly separates architects from juniors.",
          "composite": 9.666666666666666
        }
      },
      {
        "role_id": "be-461",
        "role_title": "Senior Backend Engineer - Fraud Detection",
        "question": "Design a real-time request flow (no diagrams required, 2\u20133 paragraphs) for scoring an incoming payment for fraud with these constraints: average end-to-end latency \u226450ms, allow synchronous rule engine checks, asynchronous ML model scoring if needed, support fast lookups (user/device history) and rate limits per user, and ensure failed ML service calls do not block approvals. Specify:\n- the components you would use (Kafka, Redis, PostgreSQL, Python services, etc.) and their roles,\n- which checks run synchronously vs asynchronously and how you propagate/merge their results,\n- how you handle state (history, rate limits), retries/fallbacks, and ensuring consistency for manual review queues.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core fraud detection pipeline skills (real-time scoring, rule engines, ML integration, history lookups, manual queues) with role-relevant tech like Kafka/Redis/PostgreSQL; minor deduction as exact stack not predefined in role (-1). Clarity: Crystal clear with precise constraints, scoped to 2-3 paragraphs, specific asks without ambiguity. Discriminative: Excellent at probing trade-offs (sync/async, latency, failure handling, consistency), deep system design understanding separates strong candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-468",
        "role_title": "Junior Backend Engineer - CI Pipelines",
        "question": "You have a Python project that uses pytest and a Docker-based test environment. Tests run slowly because each job builds the Docker image from scratch. Show a short GitHub Actions job snippet (YAML) that caches Docker build layers to speed up subsequent runs, and explain in one sentence how the cache works.\n\nExpect: a valid job using actions/cache or docker/build-push-action with cache-from/cache-to or buildx bake, and a one-sentence explanation.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Directly tests core CI pipeline skill (caching Docker layers) for entry-level role; clear YAML snippet request with precise expectations; requires applied knowledge of GitHub Actions caching options and concise explanation, distinguishing candidates who understand layer caching from those who don't. Minor ding on relevance for assuming pytest/Docker specifics not explicit in role, but highly aligned.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-466",
        "role_title": "Senior Backend Engineer - GitOps Tooling",
        "question": "Describe how you'd design a reconciliation loop for a custom GitOps controller (written in Go) that ensures Helm-released Kubernetes resources declared in Git stay in sync with the cluster, including how you would:\n1) detect and categorize drift (intent drift vs. configuration drift),\n2) avoid flapping and conflicting concurrent reconciliations (e.g., manual edits vs. ongoing syncs),\n3) implement safe automated rollback when a Git update causes failures.\n\nBe concise but include the key components, algorithms, and Kubernetes/ArgoCD/Helm primitives you'd use.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core GitOps skills (reconciliation loops, drift detection, rollback) with exact tech stack (Go, Helm, K8s); minor ding for not mentioning ArgoCD explicitly in role but it's GitOps standard (-1). Clarity: Well-scoped with specific subpoints, constraints (concise, key components/primitives), no bundling issues. Discriminative: Probes deep applied knowledge of trade-offs (flapping, concurrency, drift types, safe rollback), requiring synthesis of K8s/Helm primitives\u2014not rote recall.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-469",
        "role_title": "Senior Backend Engineer - Chaos Engineering",
        "question": "Describe a production-like scenario where a critical microservice in Kubernetes intermittently fails CPU spikes and packet loss. Outline a Chaos Mesh experiment (types of chaos, scope/blast radius, schedule) and a short Go-based health-check approach that detects failures and validates recovery using Prometheus metrics. Be concise: list the Chaos Mesh CRs/actions, blast-radius rules, Prometheus metrics/alerts used, and the Go health-check logic (key steps and thresholds).",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core chaos engineering (Chaos Mesh in K8s), failure injection, blast radius, recovery validation, and Go/Prometheus from role; minor ding for not explicitly naming 'infrastructure' but spot-on (-1 red flag avoidance). Clarity: Crystal clear, concise scoping, specific deliverables (CRs, rules, metrics, logic steps), no ambiguity or bundling. Discriminative: Requires applied knowledge of Chaos Mesh config, blast control, Prometheus integration, and Go health logic with trade-offs/thresholds; strong separation beyond recall.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-465",
        "role_title": "Backend Engineer - CDC Pipelines",
        "question": "Describe how you would design a Debezium-to-Kafka-to-Snowflake CDC pipeline to ensure exactly-once delivery and safe handling of schema changes (e.g., added/renamed columns). Include: (a) how Debezium configuration and Kafka topic/partitioning choices support ordering and deduplication, (b) how you would perform initial snapshots without duplicating data, and (c) how the Snowflake ingestion (or connector) should be configured to apply schema evolution and guarantee idempotent writes. Be concise and list the key settings/components you would use.",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core CDC pipeline skills (Debezium, Kafka, Snowflake) for exactly-once delivery, schema changes, and snapshots from role description; no red flags. Clarity: Well-scoped with clear parts (a-c), concise directive, and specific tech; minor deduction for lacking time constraint. Discriminative: Requires applied knowledge of configurations, trade-offs in ordering/deduplication/schema evolution, and integration specifics to separate strong candidates; not mere recall.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-467",
        "role_title": "Backend Engineer - Connection Pooling",
        "question": "You have a PostgreSQL-backed service running on Kubernetes using PgBouncer in transaction pooling mode. The service uses short-lived transactions but occasionally performs multi-statement transactions (explicit BEGIN/COMMIT). Recently you see intermittent \"server closed the connection unexpectedly\" errors and long tail latency during bursts of requests. Describe the likely cause and outline the minimal configuration/architecture changes (PgBouncer + Kubernetes + app) you would make to fix it while preserving pooling benefits. Be specific about PgBouncer pool_mode, max_client_conn, default_pool_size, and any app-side changes.",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 10,
          "reasoning": "Relevance: Perfectly matches role's core focus on connection pooling, pool sizing, transaction modes, and failover/scaling in PostgreSQL/K8s context\u2014no red flags. Clarity: Crystal clear scenario with specific expected details; minor vagueness on 'minimal' but well-scoped. Discriminative: Forces deep trade-off analysis (transaction vs session mode, config tuning) distinguishing experts from juniors.",
          "composite": 9.666666666666666
        }
      },
      {
        "role_id": "be-470",
        "role_title": "Backend Engineer - GraphQL Federation",
        "question": "You have two Apollo subgraphs: Users (exposes type User @key(fields: \"id\") with id, name, email) and Orders (exposes type Order with id, total, and a field userId). You must enable the gateway to resolve User fields when a client queries orders { id total user { id name email } }.\n\nIn 2\u20133 sentences, describe what key directive and resolver(s) you would add in each subgraph (including resolver signature and what it should return) and any schema changes needed to properly federate the relation.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core GraphQL Federation skills (schema stitching, @key, entity resolution) matching role exactly; minor deduction as role mentions query planning too (-1). Clarity: Crystal clear with specific schemas, query example, scoped to 2-3 sentences and exact artifacts needed. Discriminative: Requires applied knowledge of federation directives, resolver implementation, and trade-offs in entity resolution, strongly separating experts from juniors.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-471",
        "role_title": "Staff Engineer - Zero Trust Architecture",
        "question": "Design a production-ready approach to automate workload identities and mTLS for a Kubernetes-based microservices platform using SPIFFE and Envoy. In your answer (2\u20133 short paragraphs or bullet points), include:\n- how identities are issued and rotated (components and flow),\n- how Envoy sidecars obtain and present identity for mTLS,\n- how you enforce and evolve authorization policies across clusters (briefly mention tooling/integration points and outage/rollout considerations).",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (mTLS automation, workload identities in K8s microservices) with exact tech (SPIFFE/Envoy); minor ding as role mentions identity federation/policy enforcement more broadly (-1). Clarity: Crystal clear, well-scoped with format/depth guidance, no ambiguity. Discriminative: Probes deep applied knowledge, trade-offs (rotation/outages/rollouts), strong separation of experts from superficial knowers.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-475",
        "role_title": "Junior Backend Engineer - Search Analytics",
        "question": "You have logs of search requests stored in PostgreSQL with columns: user_id, query_text, timestamp, results_returned (integer), and click_positions (an integer array of 0-based positions in the results that the user clicked, or empty if no clicks). Write a single SQL query (PostgreSQL) that returns, for each query_text in the last 7 days, the total number of searches, the click-through rate (CTR = searches with \u22651 click / total searches), and the average position of first click (NULL if no clicks). Order results by number of searches descending and limit to top 50 queries.",
        "scores": {
          "relevance": 9,
          "clarity": 10,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests PostgreSQL SQL skills on query logging data central to search analytics role (-1 for entry-level but still core). Clarity: Crystal clear with exact schema, requirements, constraints, and output specs. Discriminative: Requires array handling, conditional aggregation, window functions, and edge cases (NULLs, empty arrays), distinguishing strong SQL thinkers from basic ones.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-462",
        "role_title": "Backend Engineer - Alert Routing",
        "question": "You\u2019re designing an Alertmanager-based routing service in Go that must: (a) group related alerts into a single notification when they share the same service and cluster labels, (b) deduplicate repeated alerts from the same instance within a 5-minute window, and (c) escalate to a PagerDuty team if an alert remains firing for >15 minutes. Briefly outline (in bullet points) the key components and algorithms you would implement (including data stores, key data structures, and how you\u2019d use Alertmanager/webhooks, Redis/Postgres, and PagerDuty APIs) to satisfy these requirements, and note one concurrency or consistency pitfall to watch for.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (grouping, deduplication, escalation) with exact tech (Alertmanager, Go implied, Redis/Postgres, PagerDuty); no red flags. Clarity: Crystal clear, well-scoped with specific requirements, explicit format (bullets), and tech; minor jargon but contextualized. Discriminative: Requires applied architecture knowledge, trade-offs in components/algorithms, and deep insight via pitfall; strong separation without being too broad.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-473",
        "role_title": "Senior Backend Engineer - Refund Processing",
        "question": "Design, at a high level (4\u20136 brief bullet points or a short diagram), how you would implement a partial refund flow in a payments service using Java + Spring Boot, PostgreSQL, Kafka and Redis. Your design should show:\n- how refund requests are recorded and validated,\n- how ledger entries are created/updated to maintain correct balances for partial refunds,\n- how you ensure idempotency and handle provider callback reconciliation (including out-of-order or duplicate callbacks),\n- how you provide an audit trail and reconcile eventual state with the ledger (describe any background job or Kafka usage).\n\nFocus on the key components, data you would store, and the failure/retry behaviors; keep it concise.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core refund processing, ledger reconciliation, partial refunds, callbacks, and audit trails using exact role tech stack (Java/Spring Boot, PostgreSQL, Kafka, Redis); minor deduction as role didn't explicitly list all techs but they align perfectly (-1 avoided). Clarity: Crystal clear with explicit scope (high-level, 4-6 bullets, specific aspects), constraints, and focus; no bundling or ambiguity. Discriminative: Requires applied knowledge of distributed systems, idempotency, trade-offs in failure/retry, reconciliation\u2014strong separation of strong vs weak candidates on real role challenges.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-472",
        "role_title": "Backend Engineer - Vector Search",
        "question": "Design a concise API endpoint (describe inputs, outputs, and key backend steps) for adding a batch of documents to a semantic search system that uses Pinecone for vector indexing, a Redis cache for recent query results, PostgreSQL for document metadata, and a Python-based embedding service. Include how you would:\n1) validate and deduplicate incoming documents,\n2) generate and store embeddings,\n3) upsert vectors into Pinecone with metadata linking to PostgreSQL rows,\n4) invalidate or update Redis cache entries affected by the new documents,\nand\n5) handle partial failures so the system remains consistent.\n\nKeep your answer high-level but specific about the order of operations, error handling strategy, and any needed idempotency mechanisms.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 10,
          "reasoning": "Relevance: Directly tests core vector search skills (embeddings, indexing, hybrid components) with exact tech stack (Pinecone, Redis, PostgreSQL); minor deduction for not explicitly mentioning hybrid search. Clarity: Crystal clear, well-scoped with numbered requirements, constraints on high-level/specific, order, and error handling; no bundling or ambiguity. Discriminative: Excellent at separating candidates via trade-offs in order of ops, partial failures, idempotency, and multi-system consistency\u2014requires deep applied understanding, not recall.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-474",
        "role_title": "Backend Engineer - Dashboards API",
        "question": "Describe how you would design a Go HTTP API endpoint to render a Grafana dashboard template with variable substitution and caching. Include:\n\n- the request/response shape you\u2019d accept (JSON fields for template id, variables, user/context for sharing),\n- how you\u2019d perform variable substitution safely (preventing injection),\n- where/what you would cache (Redis? cache keys/ttl) and invalidation strategy when templates or variables change,\n- how you\u2019d expose errors (template missing, variable mismatch, permission denied).\n\nKeep the answer high-level but specific enough to show practical decisions.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets Go APIs, Grafana templates, variable substitution, and sharing from role desc (-1 for assuming Redis/caching not explicitly listed). Clarity: Well-scoped, specific subtopics listed, high-level directive prevents over-engineering. Discriminative: Probes practical trade-offs (safety, caching strategy, invalidation, errors), separates strong Go/API engineers from juniors.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-477",
        "role_title": "Senior Backend Engineer - Data Catalog",
        "question": "Describe how you would design an automated pipeline that extracts metadata and lineage from running ETL jobs (Airflow tasks producing/consuming Kafka topics and writing to PostgreSQL) and ingests that metadata into Apache Atlas. In your answer, include:\n- what metadata and lineage you would capture (minimum set),\n- how you would capture it from Airflow, Kafka, and PostgreSQL (specific mechanisms/instrumentation),\n- how you would model and represent lineage in Atlas (entities/relationships),\n- how you would ensure correctness and handle schema drift and job failures.\n\nKeep the answer high-level but concrete; 4\u20136 bullet points or ~150\u2013250 words.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (automated metadata extraction, lineage tracking) using exact tech stack (Airflow, Kafka, PostgreSQL, implied Atlas for governance); minor ding as Atlas not explicitly listed (-1). Clarity: Crystal clear, well-scoped with specifics, word limit, and exact subtopics; no bundling or ambiguity. Discriminative: Requires applied knowledge of multiple systems, trade-offs in instrumentation/error handling, and Atlas modeling; distinguishes strong candidates via depth over recall.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-480",
        "role_title": "Junior Backend Engineer - Deployment Automation",
        "question": "You have an Ansible playbook that deploys a Python web app in a Docker container on an EC2 instance. During deployment you must:\n- ensure the required Python dependencies (from requirements.txt) are installed inside the container,\n- guarantee the container is restarted only if the image changed,\n- and provide a rollback task that runs if the deployment fails to restore the previous container image.\n\nWrite the minimal Ansible tasks (YAML snippets) that accomplish these three requirements. Assume variables: image_name, new_image_tag, container_name, requirements_path, and previous_image_tag.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests Ansible deployment scripting core to role (9; minor -1 for Docker/EC2 not explicitly listed but configuration management aligned). Clarity: Precise scope, clear requirements, well-defined variables and constraints (9). Discriminative: Requires applied Ansible knowledge (docker modules, conditions, handlers, error handling), tests trade-offs like idempotency/rollback, strong separation (9).",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-479",
        "role_title": "Principal Engineer - Data Architecture",
        "question": "Design a high-level data architecture for a product that currently uses PostgreSQL for transactional data but needs sub-second analytics queries on event streams (high ingest via Kafka) and occasional large-scale time-series queries. Using PostgreSQL, ClickHouse, Kafka, Redis, and Kubernetes, outline the components you would introduce or change, how data would flow between them, where OLTP vs OLAP responsibilities would live, and how you would ensure low-latency reads, data consistency, and operational simplicity. Call out one key trade-off and one important operational risk and how you'd mitigate it.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 10,
          "reasoning": "Relevance: Directly tests core data architecture strategy, tech selection (matches exact stack: PostgreSQL, Kafka + implied others), OLTP/OLAP split for role (-0 red flags). Clarity: Crystal clear, well-scoped with specific tech, flows, responsibilities, and explicit asks for trade-off/risk; no ambiguity or bundling. Discriminative: Requires deep applied knowledge of systems integration, trade-offs (e.g., consistency vs latency), and mitigation strategies, strongly separating architects from juniors.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-476",
        "role_title": "Backend Engineer - Live Updates",
        "question": "Design, in TypeScript, the Socket.io event handlers and Redis usage (high-level, pseudocode is fine) for a dashboard live-updates service that must:\n- let clients subscribe to a dashboard \"room\" to receive only that dashboard's updates,\n- publish updates from backend workers to all active room members across a multi-node Socket.io cluster,\n- ensure a client that disconnects and reconnects within 30 seconds receives missed updates (only for that dashboard),\n- avoid sending updates to clients viewing other dashboards.\n\nInclude:\n- the Socket.io events and room join/leave logic,\n- how you'd use Redis (or Redis Pub/Sub) to broadcast updates across nodes,\n- how you'd implement the 30-second missed-update reconnection behavior (briefly explain state storage and reconnection flow).",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (Socket.io rooms, Redis broadcasting, reconnection logic) in TypeScript; minor ding as role doesn't explicitly list Socket.io/Redis but matches 'live update system' and multi-node needs (-1). Clarity: Well-scoped with specific requirements, allows pseudocode, no bundling or ambiguity. Discriminative: Requires applied knowledge of Socket.io clustering, Redis Pub/Sub, state management, and trade-offs (e.g., TTL storage), strongly separates candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-478",
        "role_title": "Backend Engineer - Cost Attribution",
        "question": "You need to design a simple approach to attribute cloud VM costs to teams for chargeback reporting.\n\nGiven:\n- Each VM has a set of tags: {\"team\": string, \"env\": string, ...} but some VMs are missing the \"team\" tag.\n- You have Prometheus metrics of resource usage (CPU seconds, memory bytes) per VM and cloud billing line items with cost per VM per hour.\n- Requirement: allocate total cost for each VM-hour to teams when \"team\" tag is present; when missing, allocate that VM-hour proportionally across teams based on that hour\u2019s observed CPU-seconds by team (using only VMs that have a \"team\" tag). Describe, at a high level, the algorithm and data pipeline you would implement to compute hourly chargeback amounts per team. Include:\n  - the data sources and key joins/aggregations,\n  - how you handle missing/late data and small/noisy usage,\n  - complexity or performance considerations for running this nightly for thousands of VMs,\n  - one concrete Go data structure or function signature you would use to represent and compute the per-hour allocation.\n\n(Answer in 2\u20135 minutes; be concise.)",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (cost attribution, tagging, chargeback) with exact tech (Prometheus, cloud billing, VMs); minor ding for not specifying Go in role but it's fitting (-1). Clarity: Crystal clear with precise scope, constraints, and explicit subpoints; time-bound perfectly. Discriminative: Requires applied knowledge, trade-offs (missing data, noise, perf), and concrete implementation; strong separation of strong vs weak candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-481",
        "role_title": "Backend Engineer - Canary Deployments",
        "question": "You\u2019re implementing an automated canary pipeline for a Go microservice running on Kubernetes with Istio, Prometheus metrics, and ArgoCD for deployments. Describe, at a high level, the sequence of steps (including the Istio and Prometheus actions) your controller should perform to safely promote a canary from 0% to 100% traffic and automatically rollback on degradation. For each step, name the key checks or metrics you would evaluate and the thresholds or comparison logic you would use to decide continue/promote/rollback. (Answer in 2\u20135 minutes.)",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core canary deployment skills (traffic shifting, metrics, rollback) with exact tech stack (Go, K8s, Istio, Prometheus, ArgoCD) from role; no red flags (-0). Clarity: Unambiguous, well-scoped with time limit, clear structure requested, no bundling or vagueness (-0). Discriminative: Requires applied knowledge of integration, trade-offs in metrics/thresholds/steps, distinguishes deep understanding from superficial recall; time-bound for screening.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-483",
        "role_title": "Backend Engineer - WAF Integration",
        "question": "Describe how you would design and implement, in Go, a ModSecurity-based request flow that (1) receives an incoming HTTP request in Nginx, (2) consults a Redis-backed custom rule store to decide whether to block, challenge, or allow the request, and (3) logs attack patterns to PostgreSQL for later analysis. In your answer include:\n\n- the integration points between Nginx, ModSecurity, and a Go service (brief sequence of calls/events),\n- how the Go service would query/update Redis atomically for rate-limiting and bot-detection decisions,\n- how you would send decisions back to ModSecurity/Nginx (block/challenge/allow) with minimal latency,\n- one schema idea for PostgreSQL to store attack patterns and one example query to retrieve top attack sources in the last 24 hours.\n\nKeep the answer concise (2\u20135 minutes).",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core WAF integration, rate limiting, bot detection, attack analysis with Go/Redis/PostgreSQL; minor ding for Nginx/ModSecurity not explicitly listed (-1). Clarity: Crystal clear, well-scoped with numbered points, constraints, and time limit. Discriminative: Tests deep applied knowledge of integrations, atomic ops, latency, schemas/queries, forcing trade-offs and specifics to separate strong candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-484",
        "role_title": "Staff Engineer - Model Registry",
        "question": "Describe a production-ready design for a model registry using MLflow that supports versioning, staged promotion (e.g., staging \u2192 production), deployment automation to Kubernetes (pulling artifacts from S3), and audit/governance (who approved what and why). Include:\n- how you would structure MLflow model/version metadata and tags,\n- how promotion is implemented (automation and safeguards),\n- how deployments to Kubernetes are triggered and how you ensure deployed code + model are reproducible,\n- what audit trails and access controls you would enforce (and where you store them),\n- one failure scenario (e.g., bad model promoted) and how your design detects and remediates it.",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 10,
          "reasoning": "Relevance: Perfectly matches role's core needs (MLflow registry, versioning, promotion, K8s deployment, governance); no red flags. Clarity: Crystal clear with specific subpoints and scope; minor deduction as 'production-ready' could imply varying depths but well-constrained overall. Discriminative: Tests deep applied knowledge, trade-offs, failure handling; excellent separation of strong MLOps architects from weaker candidates.",
          "composite": 9.666666666666666
        }
      },
      {
        "role_id": "be-485",
        "role_title": "Junior Backend Engineer - Payment Webhooks",
        "question": "You receive POST webhook requests from a payment provider to your FastAPI endpoint /webhook. Each request includes a unique event ID in the JSON body and must be processed exactly once (idempotent). Describe, step-by-step and at a high level, how you would implement the webhook handler to:\n- verify and reject duplicate events,\n- ensure processing is safe under concurrent delivery (multiple identical requests arriving at the same time),\n- and persist the event outcome in PostgreSQL.\n\nMention any Redis or DB primitives you would use and where you would check or write the event record. (Keep the answer concise \u2014 2\u20135 short steps.)",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (idempotency, event processing, PostgreSQL) with relevant tech (FastAPI); minor ding for assuming Redis (-1). Clarity: Crystal clear, well-scoped with step-by-step, primitives specified, and length constraint. Discriminative: Requires applied knowledge of concurrency, DB primitives (e.g., UPSERT, locks), trade-offs in webhook handling, distinguishing strong entry-level candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-486",
        "role_title": "Backend Engineer - Span Processing",
        "question": "Design a tail-sampling component (in Go) for an OpenTelemetry-based span pipeline that reads completed spans from Kafka, performs policy-based tail sampling, enriches selected spans with service metadata, and writes them to ClickHouse. In 5\u20137 bullets, outline the processing flow and specify:\n- how you would ensure sampling decisions are consistent for traces spanning multiple partitions/hosts,\n- what data you would store in Kafka messages to enable sampling and enrichment,\n- one efficient approach to deduplicate or compress span data before writing to ClickHouse,\n- two failure/retry considerations for correctness.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (tail sampling, attribute enrichment, span pipeline) with exact tech stack (Go, OpenTelemetry, Kafka, ClickHouse); no red flags (-0). Clarity: Crystal clear, well-scoped with bullet format, specific sub-questions, and constraints; minor jargon is role-appropriate (-0). Discriminative: Probes deep applied knowledge, trade-offs (consistency, efficiency, failures), distinguishes strong distributed systems thinkers; not recall or trivial (-0).",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-489",
        "role_title": "Backend Engineer - Data Quality",
        "question": "You have a daily Airflow DAG that runs dbt models to populate tables in Snowflake. Recent incidents show (a) occasional late upstream feeds that make tables missing for a day, (b) sporadic schema drift where a column type changes from VARCHAR to NUMBER, and (c) sudden drops in row counts. Describe a concise, practical monitoring design (checks, thresholds, tooling, and actions) you would implement to detect and respond to these three issues. Be specific about where you would implement checks (Airflow, dbt, Great Expectations, or Snowflake), what logic/metrics you\u2019d use (e.g., freshness window, percentage change, schema diff), and the automated actions or alerts you would trigger for each failure type.",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Directly targets core role skills (freshness, volume anomalies, schema drift) using exact tech stack (Airflow, dbt, Snowflake). Crystal clear with specific issues, tools, metrics, and actions requested; minor vagueness on exact thresholds but well-scoped. Tests applied design with trade-offs (tool choice, logic, automation), strongly separates candidates with warehouse monitoring experience.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-487",
        "role_title": "Senior Backend Engineer - Search Ranking",
        "question": "You have a production search that returns results ranked by a BM25 score from Elasticsearch. Users often prefer newer items even when BM25 relevance is slightly lower. You need to implement a simple learning-to-rank adjustment in Python that boosts newer items while preserving relevance for clearly better matches.\n\nDescribe, in pseudocode or short Python, how you would:\n1) compute a final score combining BM25 (bm25_score) and item age in days (age_days) using a smooth, monotonic function that gives diminishing boost for very new items and negligible boost for old items; \n2) ensure that a difference of 0.3 BM25 points still outweighs maximal age boost (i.e., rank stability); and \n3) how you would validate this change via a small offline test using click/impression logs.\n\nKeep the answer concise and show the formula/logic and the offline validation steps.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core LTR pipeline skills (feature engineering, scoring, validation) matching role's BM25/Elasticsearch focus; minor ding for not mentioning A/B but covers offline eval (-1). Clarity: Precise scope, explicit constraints, clear numbering; well-formed for screening. Discriminative: Requires applied math (smooth monotonic combo with stability), formula design, and validation process; tests trade-offs deeply without being too broad.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-488",
        "role_title": "Backend Engineer - Gaming Backend",
        "question": "Design a WebSocket-based message flow (sequence of events and data structures) for a 4-player real-time game room using Go where:\n- players can join/leave, send input events (e.g., move/ability), and receive authoritative state updates;\n- the server must minimize bandwidth and handle transient packet loss;\n- matchmaking must ensure players are placed into rooms of similar latency.\n\nDescribe (in 4\u20138 short bullet points or a small diagram):\n1. the client\u2192server and server\u2192client messages (names and key fields, e.g., seq, timestamp, proto buffer types);\n2. how you handle ordering, deduplication, and lost messages with minimal bandwidth (no full snapshot every tick);\n3. how the server produces authoritative state updates (tick approach, interpolation/extrapolation hints to clients);\n4. one simple matchmaking rule that uses latency to form rooms.\n\nKeep the answer concise \u2014 2\u20135 minutes to explain.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core role skills (real-time sync, matchmaking, anti-cheat via authoritative state) and WebSocket/Go; minor ding for assuming Go/proto without explicit role mention (-1). Clarity: Crystal clear with precise scope (4-8 bullets, 2-5 min), numbered parts, constraints; no bundling issues. Discriminative: Tests applied trade-offs (bandwidth, loss, ordering, latency matchmaking, auth state), deep understanding over recall; strong separation of strong/weak candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-493",
        "role_title": "Staff Engineer - Reliability Standards",
        "question": "You're designing a production readiness checklist for a new Go service running on Kubernetes that will be critical to customer transactions. List the top 8 checklist items you would require before marking the service \"production-ready.\" For each item, give one concrete, measurable acceptance criterion (e.g., specific metric threshold, test result, or configuration) and briefly (1 sentence) explain why it matters for reliability.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Highly relevant to core SRE duties like production readiness reviews, directly tests Go/K8s knowledge in context; crystal clear with precise scoping (top 8 items, measurable criteria, 1-sentence explanation); strong differentiation via applied SRE trade-offs and concrete metrics, not mere recall.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-491",
        "role_title": "Junior Backend Engineer - Read Replicas",
        "question": "You have a web application using PostgreSQL with one primary (write) and two read replicas. In Python (SQLAlchemy), describe in 3\u20135 bullet points how you would route queries so that:\n- all INSERT/UPDATE/DELETE statements always go to the primary, and\n- SELECTs go to replicas, but if the most recent write might not yet be visible on replicas (e.g., immediately after creating a record), the app reads from the primary.\n\nInclude:\n- how you'd detect query type,\n- how you'd decide when to force a primary read after a recent write,\n- one simple implementation approach or pattern (no full code required).",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (read replica routing, replication lag handling) with exact tech stack (PostgreSQL, Python/SQLAlchemy); minor deduct for entry-level but no red flags. Clarity: Crystal clear, well-scoped with bullet constraints, specific requirements, no ambiguity. Discriminative: Requires applied knowledge of query routing, lag detection (e.g., timestamps/sticky sessions), and patterns (e.g., write-follows-reads), distinguishing those understanding trade-offs from rote memorizers.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-492",
        "role_title": "Backend Engineer - CD Pipelines",
        "question": "Describe a GitOps-based CD pipeline for deploying a Go microservice to Kubernetes across three environments (dev \u2192 staging \u2192 prod) using ArgoCD and GitHub Actions. Include:\n- the repo layout (what goes in app config vs. environment overlays),\n- how promotion between environments is implemented (automation vs. manual approval),\n- how you would implement a rollback triggered by a failed health check in prod,\n- and one concrete ArgoCD/GitHub Actions setting or pattern you\u2019d use to prevent accidental prod deployments.\n\nKeep the answer brief (2\u20135 minutes).",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core GitOps, ArgoCD, multi-env promotion, approvals, and rollback\u2014exact role focus (-1 for minor GitHub Actions inclusion, not core but relevant). Clarity: Crystal clear with specific components, scoped by time limit. Discriminative: Requires applied knowledge of repo patterns, automation trade-offs, failure handling, and safety measures\u2014strong separation of experts from juniors.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-494",
        "role_title": "Backend Engineer - API Mocking",
        "question": "You have an existing Node.js/TypeScript test suite that spins up a WireMock server in Docker to mock downstream HTTP services. Sometimes tests fail because WireMock returns a default 404 instead of the expected stubbed response. Describe three concrete, actionable reasons this can happen (related to request matching, templating, lifecycle/timing, or Docker/networking) and for each give one specific fix you would implement.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core API mocking skills (request matching, templating) in Node.js/Docker context matching role; minor deduction as WireMock is specific tool not explicitly listed (-1). Clarity: Crystal clear, well-scoped to 3 reasons/fixes with explicit categories, no ambiguity. Discriminative: Requires applied debugging knowledge of real-world failure modes and trade-offs in fixes, strongly separates experienced candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-482",
        "role_title": "Senior Backend Engineer - API Monetization",
        "question": "Design a high-level approach (3\u20136 concise bullet points) for implementing per-API-key usage tracking and quota enforcement in a Go-based API gateway using Kong, PostgreSQL, and Redis. Your answer should cover:\n- where and how usage is recorded in the request path (low-latency path),\n- how Redis and PostgreSQL are used (what data each stores and why),\n- an approach to enforce quotas atomically under high concurrency,\n- how to handle eventual billing integration with Stripe for overages or tier changes.\n\nFocus on concrete mechanisms (e.g., Redis ops, Kong plugin placement, schema ideas, consistency trade-offs), not on boilerplate code.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (usage tracking, quotas) with exact tech stack (Go, Kong, PostgreSQL, Redis); minor deduction as Stripe is specified but not in role desc (-1). Clarity: Crystal clear with precise scope (3-6 bullets, specific topics), well-constrained for screening. Discriminative: Requires applied knowledge of distributed systems, trade-offs (latency vs consistency), and integrations, strongly separates strong candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-495",
        "role_title": "Senior Backend Engineer - Audit Logging",
        "question": "Design a tamper-evident, queryable audit logging pipeline using Go, Kafka, ClickHouse (for analytics) and PostgreSQL (for metadata) running on Kubernetes. In 6\u20138 bullet points, describe:\n- How you would ensure logs are tamper-evident from ingestion through storage (include any cryptographic techniques, where hashes/signatures are stored, and who has the keys).\n- How you would route/partition events between ClickHouse and PostgreSQL and what each stores.\n- How you would implement retention and legal-hold policies without breaking tamper-evidence.\n- One Kubernetes operational concern (e.g., scaling, backups, rolling upgrades) and how you would address it.\n\nKeep answers practical and specific to the tech stack.",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's audit logging focus with tamper-proofing, querying, retention, using exact tech stack (Go, Kafka, ClickHouse, PostgreSQL, K8s). No red flags. Clarity: Crystal clear, well-scoped with bullet points, specific tech, minor deduction for lacking exact time constraint. Discriminative: Tests deep applied knowledge, trade-offs (crypto, partitioning, retention with tamper-evidence, ops), separates strong candidates effectively. Minor deduction as very strong candidates might finish under 10min.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-496",
        "role_title": "Junior Backend Engineer - Model Serving",
        "question": "You need to serve a pretrained scikit-learn classification model with FastAPI. Describe (in 6\u20138 short bullet points) how you would implement an endpoint that:\n- loads the model on startup,\n- accepts JSON with a list of feature vectors,\n- performs batched prediction,\n- returns predictions as JSON,\nand mention one simple way to handle concurrent requests safely when using the model object.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 8,
          "reasoning": "Relevance: Directly tests core skills (model serving as API with scikit-learn/FastAPI, batching, loading) matching entry-level role; minor ding for not mentioning monitoring (-1). Clarity: Crystal clear, well-scoped with bullet point limit, specific requirements, no ambiguity. Discriminative: Tests applied knowledge of FastAPI startup, batch prediction, concurrency (e.g., locks), distinguishes practical candidates from theorists; not perfect depth but strong for screening.",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-499",
        "role_title": "Principal Engineer - Search Platform",
        "question": "Design, at a high level, the architecture for an enterprise search platform that must serve multi-tenant web and API clients with low latency and near-real-time indexing. Your design should name and justify choices for data ingestion (including Kafka), indexing (Elasticsearch), caching (Redis), deployment/operations (Kubernetes), and how to handle schema evolution, tenant isolation, and scaling (both read and write). Also state one key operational metric to track and one runbook action for when query latency SLOs are breached. (You have 2\u20135 minutes to answer.)",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets enterprise search platform architecture/strategy, explicitly names key components (Kafka/ES/Redis/K8s) central to role's tech leadership focus (-0 red flags). Clarity: Crystal clear, well-scoped with time limit, specific components/justifications/areas required, no ambiguity. Discriminative: Tests applied system design, trade-offs (isolation/scaling/schema), and ops excellence (metrics/runbooks), strongly separates strategic thinkers from basic engineers.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-498",
        "role_title": "Senior Backend Engineer - Profiling Infrastructure",
        "question": "Describe a design for a continuous CPU profiling pipeline for a Kubernetes microservices environment (Go services). Include:\n- where and how profiles are collected (tools/agents, sampling frequency, security/overhead tradeoffs),\n- how profiles are stored and indexed for efficient baseline comparisons (consider ClickHouse or object storage),\n- how you would generate and serve flame graphs and diff comparisons (Pyroscope or other),\n- one strategy to reduce storage cost while preserving useful historical comparison capability.\n\nKeep the answer to a brief bullet-list or short paragraphs (2\u20135 minutes).",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core role skills (continuous profiling, flame graphs, baseline comparison, storage optimization) in exact context (Kubernetes/Go); minor ding for not explicitly naming all tools but aligns perfectly (-0). Clarity: Crystal clear with explicit subtopics, scoped to 2-5 min bullet/short paras; no bundling issues. Discriminative: Requires applied design knowledge with tradeoffs (security/overhead, storage cost), distinguishes deep expertise from superficial recall; excellent separation for role.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-497",
        "role_title": "Backend Engineer - Payout Systems",
        "question": "Design a short-outline answer (2\u20133 bullet points each) for how you would implement a daily batch payout job in Go that reads settlement records from PostgreSQL, groups payments by bank account to minimize transfers, validates bank details via a (rate-limited) external bank-validation service, and publishes finalized payout instructions to Kafka for execution. Include:\n- key data model fields you\u2019d query from Postgres,\n- how you\u2019d implement grouping and deduplication to minimize transfers,\n- how you\u2019d handle bank-validation with rate limits and transient failures,\n- what reconciliation events you\u2019d publish to Kafka and what minimal schema/metadata each event should include.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core role skills (batch processing, bank validation, reconciliation) in Go/PostgreSQL/Kafka; minor deduction as exact tech stack not in description but perfectly matches domain (-1). Clarity: Precise scope (2-3 bullets per section), unambiguous requirements, well-constrained for screening. Discriminative: Tests applied architecture, trade-offs (grouping/rate-limits/failures), data modeling, and schemas\u2014strong separation of strong vs weak candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-490",
        "role_title": "Senior Backend Engineer - Environment Management",
        "question": "Design at a high level (2\u20133 short bullet points or a small pseudo-code snippet) a Go-based controller that ensures each preview deployment gets:\n- its own Kubernetes namespace with a unique name,\n- a ResourceQuota limiting CPU/memory and pod count,\n- an owner label and a TTL annotation so a cleanup job can remove namespaces after expiry.\n\nDescribe how your controller would:\n1) create/ensure the namespace and ResourceQuota when a new preview request arrives,\n2) ensure idempotency and handle reconciliation if kube-api objects are modified outside the controller,\n3) surface or persist the TTL so a separate cleanup process (or the controller) can reliably find and delete expired namespaces.\n\nKeep the answer concise and focus on practical implementation hooks (client-go usage, reconcile loop behavior, labels/annotations, retries/optimistic concurrency), not full code.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (namespace isolation, quotas, TTL cleanup) in Go/Kubernetes context (-0 red flags). Clarity: Well-scoped with explicit format (2-3 bullets/pseudo-code), numbered sub-questions, practical focus, and constraints. Discriminative: Probes high-level design, idempotency, reconciliation, trade-offs in client-go/reconcile loops\u2014separates strong K8s controller devs from basics.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-500",
        "role_title": "Staff Engineer - Streaming Architecture",
        "question": "Design a Kafka-based streaming pipeline to deliver real-time user presence updates (connect/disconnect/status) to 10k concurrent WebSocket-connected clients per user device, with these constraints:\n- End-to-end latency target <200ms\n- At-least-once delivery but avoid duplicate state flashes to clients\n- Clients should only receive updates for users they subscribe to\n- Must scale horizontally on Kubernetes; use Redis as needed\n\nIn 2\u20135 minutes, describe:\n1) the topic/schema design and partitioning strategy,\n2) how you'd implement fan-out to WebSocket servers (including Redis usage) to meet latency and delivery guarantees while minimizing duplicate messages,\n3) one failure mode and how your design handles it.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core streaming architecture, Kafka (implied in role's event delivery), schemas, fan-out, guarantees (-1 for not explicitly listing Kafka/Redis/K8s). Clarity: Crystal clear with precise constraints, scoped to 2-5 min, structured subparts. Discriminative: Probes deep trade-offs in partitioning, fan-out, dedup, scaling, failure handling; distinguishes architects from basic Kafka users.",
          "composite": 9.0
        }
      }
    ]
  }
}