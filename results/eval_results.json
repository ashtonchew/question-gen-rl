{
  "baseline": {
    "model": "baseline",
    "num_samples": 100,
    "avg_relevance": 8.59,
    "avg_clarity": 8.09,
    "avg_discriminative": 8.55,
    "avg_composite": 8.410000000000004,
    "results": [
      {
        "role_id": "be-401",
        "role_title": "Backend Engineer - Training Infrastructure",
        "question": "\"Design a scalable and fault-tolerant system to manage distributed machine learning training jobs using Ray and Kubernetes. Your solution should handle job scheduling, GPU resource allocation, and recovery from failures. Provide a high-level architecture, including how Ray clusters are managed, how jobs are scheduled, and how failures are detected and recovered. Explain how you would ensure scalability and fault tolerance across a growing number of training jobs and GPUs.\"",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core role skills (job scheduling, GPU allocation, training orchestration) using Ray and K8s, which align perfectly with distributed ML infra; no red flags. Clarity: Well-scoped high-level design with specific components listed, minor deduction for lacking explicit time/format constraints. Discriminative: Tests deep applied knowledge, trade-offs in scalability/fault-tolerance, and integration of Ray/K8s, strongly separating strong candidates who can architect vs weak ones who can't.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-402",
        "role_title": "Backend Engineer - Model Deployment",
        "question": "\"When deploying a machine learning model using KServe, how would you design a deployment strategy that includes automated rollback in case of a failed inference request, and what role does Redis play in this process?\"",
        "scores": {
          "relevance": 4,
          "clarity": 7,
          "discriminative": 7,
          "reasoning": "Relevance: Low due to KServe and Redis not mentioned in role (unlisted tech -2, generic deployment -3), tests tangential ML-specific skills vs core packaging/rollback automation. Clarity: Clear intent but lacks constraints on scope/depth (-1 for jargon without role context). Discriminative: Good for applied knowledge/trade-offs in niche stack, separates experienced users.",
          "composite": 6.0
        }
      },
      {
        "role_id": "be-403",
        "role_title": "Backend Engineer - Inference Optimization",
        "question": "\"Design a Python script that uses TensorRT to optimize a model for inference latency. The script should:\n- Load a PyTorch model (e.g., ResNet50) and convert it to a TensorRT engine.\n- Apply dynamic batching to reduce GPU memory usage.\n- Include a simple benchmark to measure inference latency before and after optimization.\n- Output a report showing the latency improvement and GPU memory per batch.\"",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core inference optimization (latency, batching, GPU memory) with TensorRT/PyTorch, core to role (-1 for not explicitly mentioning quantization). Clarity: Precise specs, well-scoped tasks, no ambiguity. Discriminative: Requires applied optimization, benchmarking, and trade-offs (batching vs memory/latency), strong separation of skill levels.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-404",
        "role_title": "Senior Backend Engineer - Feature Platform",
        "question": "\"Design a feature pipeline for a real-time feature serving system using Feast and Redis. The pipeline should support both online and offline feature computation. Explain how you would structure the feature store, how you would handle feature versioning, and how you would ensure consistency between online and offline feature values. Include considerations for feature discovery and how you would monitor system health.\"",
        "scores": {
          "relevance": 9,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core role skills (feature computation, online serving, discovery) with Feast (feature store standard); minor ding for specifying Redis (not in role desc, -2) and Feast (tangential but fits). Clarity: Clear and well-scoped, but 'design' lacks explicit time/format constraints (-2). Discriminative: Excellent at probing trade-offs, architecture, consistency challenges, versioning, monitoring\u2014strong separation of deep vs shallow knowledge.",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-405",
        "role_title": "Senior Backend Engineer - Model Monitoring",
        "question": "\"Design a drift detection system for a production ML model using Python and Prometheus/Grafana. The system should detect data drift, model drift, and concept drift. Explain how you would collect, store, and visualize the metrics. Include a high-level architecture and at least one concrete example of how you'd implement a drift detection algorithm in Python (e.g., Kullback-Leibler divergence, Kolmogorov-Smirnov test, or a statistical test).\"",
        "scores": {
          "relevance": 9,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core drift detection for ML monitoring role using Python (core skill) and Prometheus/Grafana (monitoring stack); minor deduction as role doesn't explicitly list these tools (-1). Clarity: Well-scoped with specific drifts, components, and example required; lacks minor constraints like time complexity (-1, -1 for design scope). Discriminative: Requires architecture, implementation, trade-offs in drift methods, and visualization\u2014strong separation of deep vs shallow knowledge.",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-406",
        "role_title": "Senior Backend Engineer - LLM Serving",
        "question": "\"Design and implement a system to optimize token-level batching in vLLM for a high-throughput LLM serving environment. The system should handle dynamic request arrivals, manage KV cache efficiently, and support streaming responses. Provide a high-level design including key components, and describe how you would evaluate its performance and scalability.\"",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core role responsibilities (batching optimization, KV cache, streaming) and specifies vLLM from LLM serving context\u2014no red flags. Clarity: Well-scoped high-level design with clear requirements, minor deduction for lacking explicit time/format constraints. Discriminative: Tests applied system design, trade-offs, and evaluation\u2014strong separation of deep expertise from superficial knowledge, appropriately scoped for screening (<10min outline).",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-407",
        "role_title": "Staff Backend Engineer - ML Infrastructure",
        "question": "\"Design a scalable and fault-tolerant ML training pipeline using Ray, Kubernetes, and Spark. Your design should include:  \n- A high-level architecture diagram (text-based or ASCII)  \n- How you would handle data preprocessing and feature engineering  \n- How you would manage training jobs and distributed execution  \n- How you would ensure fault tolerance and recovery  \n- How you would monitor and optimize training jobs for cost and performance\"",
        "scores": {
          "relevance": 7,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests ML infrastructure skills (pipelines, scaling, fault tolerance, optimization) core to the lead ML infra role, but penalizes -2 for Spark (not listed in role) and -1 for generic aspects despite mentioning Ray/K8s. Clarity: Crystal clear with specific components listed, well-scoped for screening; no red flags. Discriminative: Excellent at probing deep applied knowledge, trade-offs in distributed systems, monitoring, and optimization, strongly separating strong candidates.",
          "composite": 8.333333333333334
        }
      },
      {
        "role_id": "be-408",
        "role_title": "Junior Backend Developer - Health Endpoints",
        "question": "\"Design and implement a health check endpoint in Go that returns a JSON response indicating the status of liveness, readiness, and metrics. The endpoint should:\n- Return a 200 OK status with a JSON body when healthy\n- Return a 503 Service Unavailable status when unhealthy\n- Include a `status` field (value: 'healthy' or 'unhealthy')\n- Include a `liveness` field (value: 'healthy' or 'unhealthy') \n- Include a `readiness` field (value: 'healthy' or 'unhealthy')\n- Include a `metrics` field (value: 'available' or 'unavailable') \n- Be implemented in a minimal Go HTTP server (no external dependencies)\n- Include error handling for unexpected issues\n- Return 503 when the system is unhealthy (e.g., due to a failed internal check)",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core role skills (liveness/readiness/metrics endpoints in Go), minor deduct for assuming Go not explicitly listed (-1). Clarity: Precise specs, well-scoped for screening, unambiguous. Discriminative: Requires applied Go/web skills, error handling, and health logic trade-offs, strongly separates candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-409",
        "role_title": "Junior Backend Engineer - File Upload",
        "question": "Design and implement a FastAPI endpoint that allows users to upload a file. The endpoint should:\n1. Accept a multipart form with `file` and `metadata` fields.\n2. Validate the file (ensure it's not empty and has a valid MIME type).\n3. Store the file in AWS S3 using a unique key (e.g., `user/{user_id}/file_{timestamp}.ext`).\n4. Store metadata in a PostgreSQL database.\n5. Return a success response with the file's URL and stored metadata.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (multipart uploads, validation, S3/PostgreSQL integration); minor ding for assuming user_id not specified. Clarity: Precise requirements with clear fields, validation, storage, and response; well-scoped for screening. Discriminative: Requires applied knowledge of FastAPI, multipart handling, validation, AWS S3, PostgreSQL, error handling, and trade-offs (e.g., key generation, MIME checks), strongly separating capable entry-level candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-410",
        "role_title": "Backend Engineer - Bulk Operations",
        "question": "\"Design a Go backend API endpoint to handle bulk data imports for a system that manages user profiles. The endpoint should support:\n- Accepting a batch of user profile updates via a JSON array\n- Ensuring idempotency (no duplicate processing of the same user updates)\n- Handling partial success (some updates may succeed, others may fail)\n- Processing the data in a background job via Kafka\n- Using Redis to track processed user IDs to ensure idempotency\n- Returning a detailed response with success/failure counts and error details for each update",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (bulk ops, partial success, idempotency) with exact tech (Go, Kafka, Redis) and API focus; minor ding for assuming 'user profiles' not explicit (-1). Clarity: Crystal clear, well-scoped with specific requirements, no ambiguity. Discriminative: Tests deep applied knowledge of trade-offs in async batch processing, idempotency, and error handling, strongly separates candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-411",
        "role_title": "Backend Engineer - Admin APIs",
        "question": "\"Design and implement a secure admin API endpoint in Python using FastAPI that allows an admin user to create a new user account. The endpoint must:\n- Require a valid admin token (JWT) for access\n- Validate the admin token using a secret key\n- Accept a user\u2019s email and password (hashed using bcrypt)\n- Store the user in PostgreSQL with a unique constraint on email\n- Prevent duplicate email creation\n- Log all admin actions (user creation) to a Redis cache with a structured log entry (timestamp, user email, admin token ID, action type), and persist the log to a PostgreSQL audit table\n- Include error handling for invalid tokens, duplicate emails, and other common issues",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (secure admin APIs, JWT auth, PostgreSQL, audit logging) with exact tech stack; minor ding for not specifying Redis in role but fits internal ops (-1). Clarity: Crystal clear, well-scoped requirements, no ambiguity or missing constraints. Discriminative: Requires applied knowledge of auth, DB ops, hashing, logging, error handling, and trade-offs (e.g., Redis vs DB logging), strongly separates skilled candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-412",
        "role_title": "Backend Engineer - Analytics APIs",
        "question": "Design and implement a Go-based analytics API that serves time-series data from ClickHouse with caching using Redis. Your solution should support efficient aggregation queries (e.g., daily, hourly) and handle data freshness and cache invalidation. Describe your design decisions, including how you handle cache invalidation, query performance, and data consistency.",
        "scores": {
          "relevance": 9,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core role skills (analytics APIs, time-series, aggregation, caching) and specifies Go/ClickHouse/Redis matching role focus (-0 red flags). Clarity: Well-scoped with specific requirements, but lacks explicit constraints like time limit or response format. Discriminative: Tests deep applied knowledge, trade-offs (invalidation, consistency, performance), distinguishing strong candidates via design decisions.",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-413",
        "role_title": "Senior Backend Engineer - API Gateway Logic",
        "question": "Design and implement a Lua script in Envoy that validates incoming HTTP requests and transforms the request headers based on a custom business rule. The rule is:  \n- If the `X-Client-Id` header is present and starts with `PROD-`, then:\n  - Add a `X-Environment: production` header.\n  - Strip the `X-Client-Id` header and set it to `PROD-<client-id>` (e.g., `PROD-123`).\n- If the `X-Client-Id` header is present and starts with `TEST-`, then:\n  - Add a `X-Environment: staging` header.\n  - Strip the `X-Client-Id` header and set it to `TEST-<client-id>` (e.g., `TEST-123`).\n- If the `X-Client-Id` header is missing, do nothing.\n- All other headers must be preserved.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core Envoy/Lua plugin skills for API gateway extensions, request transformation, and routing rules; minor nitpick on example (seems like no real change) but matches role perfectly (-1 avoided). Clarity: Crystal clear with precise rules, unambiguous logic, well-scoped for screening. Discriminative: Requires applied Envoy/Lua knowledge, header manipulation, conditionals, and edge cases, distinguishing strong candidates via trade-offs in script structure and robustness.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-414",
        "role_title": "Senior Backend Engineer - Long-Polling",
        "question": "Design and implement a long-polling endpoint in Go that efficiently handles concurrent clients, manages connection timeouts, and gracefully degrades when Redis is unavailable. The endpoint should support:\n1. A simple `POST /poll` that accepts a `pollId` and returns a message or `204 No Content` if no message is available.\n2. Connection timeout handling (e.g., 30 seconds) with automatic reconnection on timeout.\n3. Timeout cleanup after 30 seconds of inactivity.\n4. Fallback to polling every 10 seconds if Redis is unreachable (use a simple retry mechanism).\n5. Connection management using Redis to track active clients and avoid duplicate polling.\n6. Use Redis as a message store (store messages in Redis with TTL of 300 seconds).\n7. Use PostgreSQL to store client session metadata (e.g., `poll_id`, `client_id`, `last_active`, `status`).\n8. Implement a simple health check at `/health` that returns 200 if both Redis and PostgreSQL are reachable.",
        "scores": {
          "relevance": 3,
          "clarity": 4,
          "discriminative": 5,
          "reasoning": "Relevance: Superficially mentions Go and role focus (long-polling, timeouts, Redis) but generic design task; bundles too many extras (PostgreSQL, health check) not core to role (-3 generic, -2 extras beyond main focus). Clarity: Multiple bundled requirements (8 items) make it ambiguous in scope/expectations for screening (-2); lacks time/format constraints (-2). Discriminative: Tests applied knowledge but too broad (>10min, full system design) with weak separation as weak candidates fail early on volume.",
          "composite": 4.0
        }
      },
      {
        "role_id": "be-415",
        "role_title": "Senior Backend Engineer - Multipart APIs",
        "question": "Design and implement a resumable upload system using FastAPI, Python, and S3. The system should support chunked uploads, store upload metadata in S3, and allow resuming from any point. Include a simple example of how a client would initiate and resume an upload.",
        "scores": {
          "relevance": 10,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's core focus on resumable uploads, chunk management, and S3 (main tech stack). Clarity: Clear intent and scope, but lacks explicit constraints like chunk size limits or time expectations (-2). Discriminative: Tests deep applied knowledge of APIs, state management, S3 integration, and trade-offs (e.g., metadata durability), strongly separates candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-416",
        "role_title": "Staff Backend Engineer - External APIs",
        "question": "\"Design a scalable and secure external API using Go and OpenAPI, with Kong as the gateway, deployed on Kubernetes. Your design should include key components, security considerations, rate limiting, logging, and observability. Provide a high-level architectural overview, and explain how you would implement API monetization for partners. Include how you'd structure the API to support partner enablement and integration patterns.\"",
        "scores": {
          "relevance": 9,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets API strategy, monetization, partner enablement, and integration patterns; specifies relevant tech (Go, OpenAPI, Kong, K8s) with minor ding for assuming unlisted specifics (-1). Clarity: Well-formed with clear components listed, but lacks time/format constraints for screening (-2). Discriminative: Tests deep applied knowledge, trade-offs in security/scalability/monetization, strongly separates candidates.",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-417",
        "role_title": "Junior Backend Developer - Event Sourcing",
        "question": "\"Design a simple event handler for a `UserCreated` event in an event-sourced system using Kafka and PostgreSQL. The event should be consumed by a handler that persists the user's state in a PostgreSQL database. Implement the handler class, describe how it would handle state transitions (e.g., from `UNKNOWN` to `ACTIVE`), and explain how you\u2019d ensure data consistency between Kafka and PostgreSQL.\"",
        "scores": {
          "relevance": 9,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core event sourcing skills (event handlers, state transitions) with role-relevant tech (Kafka, PostgreSQL for projections); minor ding as entry-level but still spot-on (-1 for generic 'design'). Clarity: Clear intent and scope, but lacks precise constraints like schema or error handling (-2). Discriminative: Requires applied knowledge of event handling, state management, and consistency (e.g., idempotency, transactions), distinguishing strong candidates via trade-offs.",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-418",
        "role_title": "Junior Backend Engineer - Service Clients",
        "question": "> \"Design and implement a gRPC client in Go that supports automatic retry with backoff and circuit breaker pattern. The client should handle transient errors (e.g., connection timeout, network errors) and gracefully degrade when the service is unavailable. Use Protobuf for the service interface and Docker to containerize the client. Provide a minimal working example with a simple service interface and a client that demonstrates retry and circuit breaker behavior.\"",
        "scores": {
          "relevance": 3,
          "clarity": 5,
          "discriminative": 7,
          "reasoning": "Relevance: Superficially mentions tech stack (Go, gRPC) but tests generic resilience patterns core to role; heavy red flags for generic design (-3), ignores entry-level focus by bundling too many unrelated tasks (Docker, Protobuf service impl -2), tests beyond core client-side retries/circuit breakers. Clarity: Understandable but vague on depth/scope (e.g., backoff params, circuit thresholds -2 for missing constraints), bundles multiple tasks (design+impl+Docker -2). Discriminative: Good for applied resilience knowledge but entry-level scope too broad (>10min, -2).",
          "composite": 5.0
        }
      },
      {
        "role_id": "be-419",
        "role_title": "Backend Engineer - Retry Logic",
        "question": "Imagine you're implementing a retry mechanism for a distributed service that handles order processing. The service may fail due to transient issues like network latency or database timeouts. You need to implement a retry strategy that uses exponential backoff with jitter, and includes a retry budget to prevent infinite retries on persistent failures.",
        "scores": {
          "relevance": 10,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's core focus on retry infrastructure, backoff, jitter, budgets\u2014no red flags. Clarity: Clear scenario and requirements, but lacks explicit constraints (e.g., max retries, time limit, code/pseudocode format). Discriminative: Excellent at testing applied knowledge of trade-offs in retry design; distinguishes those who understand implementation nuances from rote memorizers.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-420",
        "role_title": "Backend Engineer - Graceful Shutdown",
        "question": "*In a Kubernetes environment, how would you implement a graceful shutdown for a Go gRPC server that handles in-flight requests and supports connection draining, especially when receiving a SIGTERM signal?*",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core role requirements (graceful shutdown, connection draining, in-flight requests, SIGTERM) with exact tech stack (Kubernetes, Go, gRPC). No red flags. Clarity: Crystal clear, well-scoped for screening; minor deduction only for unspecified answer format/depth. Discriminative: Tests applied knowledge of signal handling, timeouts, K8s lifecycle (preStop), and gRPC specifics, requiring trade-offs for strong separation.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-421",
        "role_title": "Senior Backend Engineer - Security Automation",
        "question": "*You're tasked with creating a Python script that automates the rotation of database secrets stored in HashiCorp Vault. The script should:*\n1. *Authenticate to Vault using a Kubernetes service account (Kubernetes `ServiceAccount` with `vault` role bound via `RoleBinding`)*\n2. *Read a list of database secrets from a configuration file (e.g., JSON or YAML)*\n3. *For each secret, generate a new random password (12 characters, lowercase, alphanumeric) and rotate it in Vault*\n4. *Log the operation with timestamps and success/failure status*\n5. *Fail fast if any step fails, and output a human-readable error message*",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests Python automation for secrets rotation in Vault with K8s auth, core to security pipelines (-1 for no explicit role tech list match but perfect fit). Clarity: Precise requirements, well-scoped steps, no ambiguity. Discriminative: Requires integrating auth, config parsing, crypto, error handling, and logging; tests applied Vault/K8s knowledge with trade-offs in failure modes.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-422",
        "role_title": "Junior Backend Engineer - API Testing",
        "question": "Write a pytest test for a FastAPI endpoint that returns a list of users. The endpoint should accept a query parameter `page` and `limit`, and return a JSON response with a `users` array and `total` count. Your test should:\n- Use `test_client` to make a request\n- Test the response structure and data\n- Include a fixture for the test database\n- Verify that the query parameters are correctly applied (e.g., page=1, limit=10)\n- Handle edge cases like invalid page or limit values (e.g., negative numbers, non-numeric)",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests pytest, FastAPI testing (core for API tests role), fixtures (explicitly mentioned), and query param handling; minor ding as contract testing not covered but fits entry-level. Clarity: Precise scope, clear requirements, well-formed for screening. Discriminative: Requires applied knowledge of test_client, fixtures, assertions, and edge cases with trade-offs (e.g., error responses), strongly separates candidates able to write functional tests from those with superficial knowledge.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-423",
        "role_title": "Staff Engineer - Incident Response Platform",
        "question": "> \"Design a system to manage on-call rotations for a team of 10 engineers, where each engineer is on-call for 5 days, then off for 3 days. The system must handle automatic rotation, provide real-time visibility into on-call schedules, and support manual overrides. It should be implemented in Go, with a PostgreSQL database to store schedules and a Slack API to notify engineers when their shift begins and ends. Explain your approach, including data model, how you'd handle edge cases (e.g., engineers on leave, shift overlaps), and how you'd implement the rotation logic.\"",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core on-call optimization skills from role; specifies Go/PostgreSQL/Slack (relevant tooling), minor deduction for not explicitly covering alerting/runbooks/SLOs (-1). Clarity: Well-scoped design question with clear constraints, tech stack, and required elements; no bundling or vagueness. Discriminative: Probes deep applied knowledge (data model, rotation logic, edge cases, trade-offs), strongly separates candidates able to reason through implementation details.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-424",
        "role_title": "Backend Engineer - Message Serialization",
        "question": "\"Design a message serialization system for a distributed system that uses Kafka as the messaging backbone. The system must support schema evolution with backward and forward compatibility, using Avro with Schema Registry. Handle schema validation at both producer and consumer sides. Provide a concrete example of how a schema change would be handled when a new field is added to a message, and explain how the system ensures backward compatibility. Also, describe how you would validate schemas at runtime and what monitoring or alerting strategies you would implement to detect schema mismatches.\"",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfect match to role's core focus on message serialization, schema evolution, compatibility, and validation; directly tests Avro/Schema Registry implied by infrastructure needs, no red flags. Clarity: Crystal clear and well-scoped with specific requirements and example, minor deduction for lacking explicit time/format constraints. Discriminative: Excellent at testing applied knowledge, trade-offs in compatibility/runtime validation/monitoring; strong separation of strong vs weak candidates, not pure recall.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-425",
        "role_title": "Senior Backend Engineer - Graph Analytics",
        "question": "Design a scalable graph analytics pipeline to compute user-based recommendations using Neo4j and Apache Spark. The pipeline should handle a billion-edge dataset and support real-time updates. Describe how you would structure the pipeline, the data flow, and how you would optimize traversal queries for performance and scalability. Include considerations for handling real-time updates and potential bottlenecks.",
        "scores": {
          "relevance": 9,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets graph analytics, recommendations, billion-edge scale, and traversal optimization from role; minor ding for assuming Neo4j/Spark not explicitly listed (-1). Clarity: Well-scoped with clear asks (structure, flow, optimization, updates, bottlenecks), but 'design a pipeline' slightly open-ended without time/format constraints (-2). Discriminative: Excellent at probing trade-offs, scalability, real-time challenges, and optimizations to separate strong graph engineers from weak ones.",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-426",
        "role_title": "Junior Backend Engineer - DevOps Scripting",
        "question": "Write a Bash script that builds and pushes a Docker image to a private Docker registry (e.g., Docker Hub or AWS ECR). The script should:\n- Accept a Docker image name (e.g., \"myapp:latest\") as a command-line argument\n- Validate that the image name is provided and has a valid format (e.g., contains a tag)\n- Use `docker build` to build the image from a Dockerfile in the current directory\n- Push the built image to a private Docker registry using `docker push`\n- Include error handling for common issues (e.g., missing Dockerfile, failed build, failed push)\n- Output a success or failure message at the end",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core DevOps automation skills (Bash scripting, Docker build/push) essential for deployment scripts/CI pipelines; minor ding as registry login isn't specified (-1). Clarity: Precise requirements, well-scoped with validation/error handling, no bundling/ambiguity. Discriminative: Requires applied knowledge of Bash args/parsing, Docker commands, validation, and error handling; distinguishes those who can script practically from theorists.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-427",
        "role_title": "Backend Engineer - Feature Store",
        "question": "\"Design a feature store pipeline that ingests streaming data from Kafka, computes features using a Python function, stores them in Redis for real-time serving, and persists them to PostgreSQL for historical tracking. The pipeline should support feature versioning and handle data drift detection. Explain how you would implement feature versioning and data drift detection in this system.\"",
        "scores": {
          "relevance": 9,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core feature store skills (computation, versioning, serving, drift) with relevant tech (Kafka, Redis, PostgreSQL, Python); minor ding for not explicitly mentioning ML pipelines. Clarity: Well-scoped design with specific components, but lacks explicit constraints like scale or time (-1 for missing constraints, -1 bundled sub-questions). Discriminative: Excellent at testing applied architecture, trade-offs in versioning/drift, distinguishing strong ML infra candidates.",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-428",
        "role_title": "Senior Backend Engineer - Payment Orchestration",
        "question": "*Design a failover strategy for a payment orchestration system that routes transactions to multiple payment providers (e.g., Stripe, PayPal, Braintree). The system must ensure transaction success, minimize cost, and maintain low latency. Consider provider availability, transaction cost, and success rates. Provide a step-by-step plan including how you would evaluate provider health, dynamically route transactions, and handle failures. Include considerations for cost optimization and transaction latency.*",
        "scores": {
          "relevance": 9,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core role skills (failover, routing, cost optimization, success rates) with relevant providers; minor deduction for generic examples not explicitly listed (-1). Clarity: Well-formed and unambiguous, but 'design' lacks explicit time/format constraints (-1) and slightly broad. Discriminative: Excellent at probing trade-offs, dynamic decision-making, and deep system design understanding to separate strong candidates.",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-429",
        "role_title": "Backend Engineer - Log Aggregation",
        "question": "**\"Design a scalable log aggregation pipeline using Go and Kafka to ingest, parse, and store logs in ClickHouse. Include key considerations for performance, reliability, and observability.\"**",
        "scores": {
          "relevance": 10,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core role skills (log pipelines, parsing, high-volume processing) with relevant tech (Go, Kafka, ClickHouse implied for storage); no red flags. Clarity: Clear and well-scoped for screening, but lacks explicit constraints like throughput targets or time limits (-2). Discriminative: Excellent at testing applied knowledge, trade-offs in performance/reliability/observability; distinguishes strong architects from juniors.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-430",
        "role_title": "Junior Backend Engineer - Search Indexing",
        "question": "You're building a search index for a product catalog with 100,000 products. Each product has a title, description, and price. You need to index these records into Elasticsearch using Python. How would you design the indexing pipeline to ensure efficient, reliable, and scalable performance?",
        "scores": {
          "relevance": 7,
          "clarity": 6,
          "discriminative": 8,
          "reasoning": "Relevance: Tests core indexing/mapping skills with ES/Python directly matching role, but generic catalog lacks role-specific focus like bulk jobs (-1); no red flags. Clarity: Clear intent but 'design pipeline' lacks constraints (batch size, error handling scope, time limits) (-2 red flag). Discriminative: Probes applied trade-offs (bulk indexing, reliability, scaling), separates good from weak candidates.",
          "composite": 7.0
        }
      },
      {
        "role_id": "be-431",
        "role_title": "Staff Engineer - Real-time Collaboration",
        "question": "Design a real-time collaboration system that supports multiple users editing a shared document simultaneously. The system must handle concurrent edits, resolve conflicts when users edit overlapping regions, and ensure that all users see the same content in real time. Use CRDTs to manage conflict resolution. You must support a simple document structure (e.g., a text document with line breaks and text segments). Describe your design choices, including how you would store the document state, how you would handle concurrent edits, and how you would resolve conflicts using a CRDT.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (real-time collab, conflict resolution, operational transforms via CRDTs); minor deduction as role mentions presence systems (untested) but hits main focus (-1). No red flags. Clarity: Crystal clear, well-scoped to simple doc structure with specific requirements; no bundling or ambiguity. Discriminative: Requires deep applied knowledge of CRDTs, trade-offs in state storage/concurrency, excellent separation of strong vs weak candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-432",
        "role_title": "Backend Engineer - Data Validation",
        "question": "\"Design and implement a data validation framework using Great Expectations to validate data from a PostgreSQL table (e.g., `sales` table) before loading it into S3. The validation should check for missing values, data type correctness, and statistical outliers (e.g., sales > 1000000). Include a minimal example of how this would be used in an Airflow DAG to trigger validation and fail the pipeline if any validation fails.\"",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core data validation, schema checks, statistical validation, and pipeline integration; Great Expectations, PostgreSQL, S3, Airflow align perfectly (-1 minor for assuming unlisted tools). Clarity: Crystal clear with specific table, checks, thresholds, and Airflow usage; well-scoped. Discriminative: Requires design, implementation, integration, error handling, and trade-offs (e.g., outlier detection), strongly separates skilled candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-433",
        "role_title": "Senior Backend Engineer - Platform APIs",
        "question": "\"Design a scalable, secure, and consistent service catalog API in Go using gRPC that allows developers to discover, provision, and manage platform services (e.g., databases, storage, compute). The API must support versioned service definitions, support both synchronous and asynchronous provisioning, and provide a way to list available services with filtering by category, region, and tags. Additionally, the API must support rate limiting and authentication via JWT tokens. Describe your design decisions, including how you would handle versioning, asynchronous provisioning, and security.\"",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's core focus on service catalog and provisioning APIs, directly tests Go/gRPC from implied stack, no red flags. Clarity: Extremely well-scoped with specific requirements, minor deduction for lacking explicit time/format constraints. Discriminative: Excellent at probing trade-offs in versioning, async handling, security, and scalability; distinguishes deep thinkers from superficial ones, though slightly broad.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-434",
        "role_title": "Principal Engineer - Database Strategy",
        "question": "\"Design a database strategy for a multi-region, globally distributed application using PostgreSQL, CockroachDB, Redis, and Kafka. Your strategy must include:  \n- A clear rationale for selecting each database technology (PostgreSQL, CockroachDB, Redis, Kafka)  \n- A detailed architecture for data replication, consistency, and availability across regions  \n- A plan for handling data migration from a monolithic PostgreSQL database to this distributed setup  \n- A discussion of operational excellence and monitoring for database performance and health  \n- A brief mention of how you would mentor junior engineers in database strategy and architecture\"",
        "scores": {
          "relevance": 4,
          "clarity": 7,
          "discriminative": 3,
          "reasoning": "Relevance: Directly matches multi-region database strategy but generic (-3), mandates unmentioned tech (CockroachDB, Redis, Kafka; -2), adds irrelevant mentoring. Clarity: Clear structure and intent but bundled multiple sub-questions (-2) and overly broad design scope. Discriminative: Too broad (>10min, multiple topics; -2), tests high-level discussion rather than deep trade-offs, weak separation.",
          "composite": 4.666666666666667
        }
      },
      {
        "role_id": "be-435",
        "role_title": "Junior Backend Engineer - Queue Consumers",
        "question": "\"Design and implement a Python consumer for a RabbitMQ queue that processes messages with the following requirements:  \n1. Acknowledge messages only after successful processing (with a 5-second timeout for processing).  \n2. Implement idempotency by using a PostgreSQL database to track processed message IDs.  \n3. Handle message failures gracefully by moving failed messages to a dead-letter queue (DLQ).  \n4. Ensure the consumer restarts automatically after a crash (using Docker and a health check).  \n5. Include basic logging and error handling.",
        "scores": {
          "relevance": 9,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core skills (acks, DLQ, idempotency) and entry-level tech (Python, RabbitMQ, Postgres) from role; minor ding for Docker not mentioned. Clarity: Well-scoped requirements, but #4 Docker/healthcheck slightly underspecified. Discriminative: Requires integrating multiple real-world concepts with trade-offs (e.g., ack timing, DB transactions, restarts), strongly separates capable candidates.",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-436",
        "role_title": "Backend Engineer - API Documentation",
        "question": "\"Design and implement a function in TypeScript that takes an OpenAPI 3.0 schema object and generates a human-readable, markdown-formatted documentation block for a given endpoint. The function should include:  \n- Path parameters, query parameters, request body, and response schema  \n- Example values for all parameters and responses  \n- Versioning support (e.g., `/v1/users`)  \n- Proper handling of nested schemas  \n- Markdown formatting with headers and code blocks  \n- Error handling for invalid schema structures\"",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Directly tests core role skills (OpenAPI schema handling, auto-generated docs, versioning) in TypeScript with precise requirements. Crystal clear scope for screening, tests applied knowledge of schemas/nesting/examples with trade-offs in implementation, strong differentiation without being overly broad.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-437",
        "role_title": "Senior Backend Engineer - Secrets Management",
        "question": "\"Design a secure secrets management solution using HashiCorp Vault and Kubernetes, including automatic secret rotation for database credentials, encryption-at-rest for stored secrets, and audit logging. How would you configure Vault to ensure that Kubernetes pods can securely access secrets without exposing them in logs or configuration files? Explain your approach to managing access policies, rotating database credentials automatically, and handling audit logs.\"",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core role skills (secrets mgmt, rotation, encryption-at-rest, access policies, audit logging) using Vault/K8s implied by infrastructure focus. Clarity: Precise and well-scoped, minor deduction for lacking explicit time/format constraints. Discriminative: Tests deep applied knowledge, trade-offs in config/policies/rotation, distinguishes strong Vault/K8s experts from superficial knowers.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-438",
        "role_title": "Staff Engineer - ML Serving Infrastructure",
        "question": "\"Design a scalable and fault-tolerant ML serving solution using Triton Inference Server with Kubernetes. Your design should include model versioning, dynamic batching, and latency optimization strategies. Include a high-level architecture diagram and explain how you would implement dynamic batching and model versioning. Also, describe how you would monitor system health and detect model drift.\"",
        "scores": {
          "relevance": 10,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's core needs (ML serving, batching, versioning, latency) using relevant Triton/K8s stack. Clarity: Clear and well-scoped for screening but lacks explicit time/format constraints (-2). Discriminative: Tests deep applied knowledge, trade-offs, and system design, strongly separating strong candidates; slightly broad but focused (-1).",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-439",
        "role_title": "Backend Engineer - Billing Integration",
        "question": "\"Design and implement a Python function that handles the proration of a subscription price change in a billing system using Stripe. The function should:\n- Accept the old and new subscription prices, the subscription start date, and the current date.\n- Calculate the prorated amount for the current period based on the time elapsed between the start date and the current date.\n- Account for the fact that proration only applies to the current billing period, not future periods.\n- Return the prorated amount to be applied to the invoice.\"",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core proration skill for billing/subscription role using Stripe (mentioned); minor ding for not providing full role tech stack context (-1). Clarity: Precise inputs, clear requirements, well-scoped for function implementation. Discriminative: Requires applied math, date handling, and Stripe proration logic with trade-offs (current period only), distinguishing strong candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-440",
        "role_title": "Junior Backend Engineer - Metrics Collection",
        "question": "You're adding metrics to a Go service using Prometheus. The service has a health check endpoint that returns a 200 status code when healthy and a 500 status code when unhealthy. You want to expose the health status as a metric, so you decide to use a Gauge. You set up the metric with a constant value of 1 for healthy and 0 for unhealthy. However, you notice that the metric doesn't update when the service becomes unhealthy \u2014 it stays at 1 even when the service fails.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core metrics skills (Gauge pattern) and Go/Prometheus for entry-level instrumentation role (-0 red flags). Clarity: Crystal clear scenario with precise setup and issue described, well-scoped. Discriminative: Tests deep Prometheus understanding (Gauge must be explicitly Set each scrape), reveals trade-offs in metric patterns, strong separation of candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-441",
        "role_title": "Senior Backend Engineer - Autocomplete Systems",
        "question": "**\"Design a distributed autocomplete system that supports real-time personalization and achieves sub-50ms latency at 100K QPS. How would you structure the data pipeline from ingestion to user query processing, and what specific optimizations would you apply to ensure low latency and high throughput? Please describe how you'd handle personalization (e.g., user-specific recommendations) and how you\u2019d balance consistency and performance in a distributed environment.\"**",
        "scores": {
          "relevance": 10,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's core requirements (autocomplete, personalization, exact latency/QPS targets). Clarity: Clear and well-formed but lacks explicit screening constraints like time/format (7-8 range). Discriminative: Tests deep system design, trade-offs, and optimizations, strongly separating strong candidates (-0 red flags).",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-442",
        "role_title": "Backend Engineer - Event Streaming",
        "question": "Design a system to fan out real-time updates from a PostgreSQL database to multiple downstream services using NATS and Redis. The system must support filtering by event type and allow replay of events from a specific point in time. Describe how you would structure the event ingestion pipeline, handle filtering, and ensure durability and replayability.",
        "scores": {
          "relevance": 9,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (event streaming, fan-out, filtering, replay) with PostgreSQL (common DB); NATS/Redis are reasonable for streaming/infra though not explicitly listed (-1). Clarity: Well-scoped design question with clear requirements, but lacks minor constraints like scale (-1 from 9-10) and bundles multiple aspects (-1). Discriminative: Excellent at probing trade-offs in pipelines, durability, filtering, and replay, distinguishing strong architects from weak ones.",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-443",
        "role_title": "Senior Backend Engineer - Data Lake Architecture",
        "question": "\"Design a data pipeline for ingesting and processing daily sales data into a data lake using Apache Iceberg. The data comes from a variety of sources (e.g., point-of-sale systems, web analytics) and is stored in S3. The pipeline must support schema evolution, allow efficient partition pruning for performance, and enable time travel queries for auditability. Describe how you would structure the pipeline, including the data flow, table format configuration, partitioning strategy, and how you would handle schema evolution and time travel.\"",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's core skills (data lake, Iceberg, schema evolution, partition pruning, time travel) with exact tech stack (S3 implied). Clarity: Well-scoped design question with clear requirements, minor deduction for lacking explicit time/format constraints. Discriminative: Tests applied architecture knowledge, trade-offs in partitioning/processing, and Iceberg specifics to separate strong candidates.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-444",
        "role_title": "Backend Engineer - Service Templates",
        "question": "\"Design a service template using Cookiecutter that generates a Go-based microservice with best practices, including proper directory structure, configuration management, logging, and CI/CD setup via GitHub Actions. The template should also include a minimal observability layer (e.g., logging with structured format and metrics via Prometheus) and enforce security best practices (e.g., environment-specific configuration, secure secrets handling, and use of default TLS settings). Describe how you would structure the template, what files would be included, and how GitHub Actions would validate and deploy the service to Kubernetes with ArgoCD.\"",
        "scores": {
          "relevance": 9,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (service scaffolding with Cookiecutter, CI/CD/GitHub Actions, observability, security) and exact tech stack (Go microservice, Prometheus, Kubernetes/ArgoCD); minor ding for not explicitly mentioning 'templates' but covers it (-1). Clarity: Well-scoped with specific components listed, but lacks time/format constraints for screening (-2). Discriminative: Requires applied knowledge of template design, best practices, and integration trade-offs, strongly separates capable candidates.",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-445",
        "role_title": "Junior Backend Engineer - Database Migrations",
        "question": "You're working on a Python application using SQLAlchemy and Alembic for database migrations. You need to create a migration that adds a new column `email` to the `users` table, but you want to ensure that the migration handles the case where some users may already have an email in the database.",
        "scores": {
          "relevance": 8,
          "clarity": 5,
          "discriminative": 6,
          "reasoning": "Relevance: Directly tests Alembic/SQLAlchemy migrations (core to role) but misses zero-downtime/rollback/versioning depth (-1, not 9-10 specific). Clarity: Vague scenario ('handles the case') lacks constraints on approach, backfill, nullability, or downtime (-3 for missing constraints, -1 ambiguous jargon). Discriminative: Tests basic migration scripting but weak on trade-offs like online schema change or safety (-3 recall-ish).",
          "composite": 6.333333333333333
        }
      },
      {
        "role_id": "be-446",
        "role_title": "Staff Engineer - Distributed Tracing",
        "question": "\"Design a sampling strategy for a high-throughput, distributed system using OpenTelemetry and Jaeger, where traces are generated at 10,000 transactions per second (TPS) and must be stored in ClickHouse. Consider the trade-offs between different sampling strategies (e.g., rate-based, probabilistic, deterministic) and the impact on observability, performance, and cost. Propose a hybrid sampling strategy that balances trace visibility, performance, and cost, and explain how you would implement and validate this strategy in production.\"",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core distributed tracing skills and sampling strategies from role; uses relevant tech (OpenTelemetry, Jaeger, ClickHouse) without extras (-0 red flags). Clarity: Crystal clear, well-scoped with TPS constraint, specific trade-offs, and implementation/validation; no bundling or vagueness. Discriminative: Excellent at probing trade-offs, hybrid design, and production validation for strong separation of deep expertise from basics.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-447",
        "role_title": "Backend Engineer - Load Shedding",
        "question": "*Design a load shedding mechanism for a high-traffic API endpoint that uses Envoy as a proxy and Redis for rate limiting. The endpoint experiences random spikes in traffic, causing service degradation. When the system detects a spike, it should automatically trigger load shedding to prioritize critical requests (e.g., user authentication) over non-critical ones (e.g., analytics reporting).*",
        "scores": {
          "relevance": 9,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core load shedding, prioritization, and adaptive mechanisms; minor deduction for specifying Envoy/Redis not in role desc (-2 red flag adjusted). Clarity: Clear scenario and goals, but lacks explicit constraints like time or format (-1 from perfect). Discriminative: Requires trade-offs in detection, prioritization (queues), and shedding strategies, strongly separating deep understanding from superficial knowledge.",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-448",
        "role_title": "Senior Backend Engineer - Webhook Infrastructure",
        "question": "\"Design a resilient webhook delivery system in Go using Kafka and PostgreSQL/Redis for delivery guarantees, retry logic, and analytics. Specifically, how would you ensure message delivery is guaranteed, handle failures, and track delivery status with analytics?\"",
        "scores": {
          "relevance": 9,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core role skills (guaranteed delivery, retry logic, analytics) with relevant stack; minor ding for assuming Kafka/Redis not explicitly in role. Clarity: Clear and well-scoped for design but lacks explicit constraints like scale/time. Discriminative: Excellent at testing applied knowledge, trade-offs in retries/failures/guarantees, distinguishing strong architects.",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-449",
        "role_title": "Junior Backend Engineer - Auth Integration",
        "question": "*Design a secure OAuth2 flow for a social login (e.g., Google) integrated into a Node.js + TypeScript application using PostgreSQL. Include how you would handle token storage, refresh, and prevent replay attacks.*",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets OAuth2 flows, token handling, refresh, and social login\u2014core to role; matches Node.js/TS stack, minor ding for PostgreSQL not specified but storage-relevant (-1). Clarity: Precise scope, unambiguous, well-formed for screening. Discriminative: Probes security (replay attacks), applied knowledge, trade-offs in storage/refresh\u2014strong separation of strong vs weak candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-450",
        "role_title": "Principal Engineer - ML Platform Strategy",
        "question": "\"Design a scalable and secure ML platform strategy for a large enterprise with distributed teams across multiple geographies, including considerations for data governance, model lifecycle management, and team enablement. Your design must address how to ensure consistent model quality, compliance with regulatory requirements (e.g., GDPR, HIPAA), and integration with existing CI/CD pipelines. Please describe your approach to tooling selection, governance models, and how you would onboard new ML engineers to the platform.\"",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's core responsibilities (strategy, tooling, governance, enablement); no red flags. Clarity: Crystal clear and well-scoped for screening, minor deduction for lacking explicit time/format constraints. Discriminative: Tests deep applied knowledge, trade-offs in enterprise ML (quality, compliance, integration), distinguishes strategic thinkers from tactical ones; appropriately broad but focused.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-451",
        "role_title": "Backend Engineer - Subscription Billing",
        "question": "\"Design a system to handle proration for a subscription billing model where users can change plans mid-month. Your design should include how usage metering is integrated, how proration is calculated, and how it's stored and updated in the database. Use the following constraints:  \n- All calculations must be precise to the second (e.g., 10.5 seconds of usage = 10.5).  \n- The system must support plan changes at any time, not just at the start of a billing period.  \n- You must use the provided tech stack: Java, PostgreSQL, Kafka, Spring Boot, Redis.  \n- Consider edge cases like partial billing periods and overlapping changes.  \n- Avoid using external libraries for financial calculations.\"",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core role skills (proration, usage metering, plan changes) with exact tech stack (-0 red flags). Clarity: Well-scoped with explicit constraints, tech requirements, and edge cases; no ambiguity. Discriminative: Probes deep applied knowledge, trade-offs, integration, and edge cases to separate strong candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-452",
        "role_title": "Senior Backend Engineer - Faceted Search",
        "question": "\"Design and implement a faceted search system that supports dynamic filtering and accurate facet counts at scale. Consider performance, correctness, and scalability when designing your solution. Focus on the challenges of maintaining facet count accuracy when dealing with large datasets and high query loads. How would you ensure accurate facet counts without sacrificing performance?\"",
        "scores": {
          "relevance": 10,
          "clarity": 4,
          "discriminative": 8,
          "reasoning": "Relevance: Perfectly matches role's core focus on faceted search, dynamic filtering, and facet count accuracy at scale (+10, no red flags). Clarity: Clear intent but 'design and implement' is overly broad for screening without constraints like time, scope, or tech stack; bundles design+implementation (-2 for no constraints). Discriminative: Strong on trade-offs (accuracy vs performance at scale), tests deep understanding but risks lengthy answers (-0).",
          "composite": 7.333333333333333
        }
      },
      {
        "role_id": "be-453",
        "role_title": "Backend Engineer - Notification Delivery",
        "question": "\"Design a system to deliver push notifications in real-time to mobile devices using Go, Redis, and FCM/APNS. Your solution should handle device registration, batching, and delivery tracking. Explain how you\u2019d ensure reliability, scalability, and performance, and how you\u2019d handle failure scenarios.\"",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfect match to role (device registration, batching, delivery tracking) with exact tech (Go, Redis, FCM/APNS). Clarity: Crystal clear and well-scoped for screening, minor deduction for lacking time/format constraints. Discriminative: Tests deep system design, trade-offs (reliability/scalability/performance), and failure handling, strongly separates strong candidates.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-454",
        "role_title": "Junior Backend Engineer - ETL Scripts",
        "question": "Write a Python script using pandas and PostgreSQL that reads a CSV file, performs a basic data transformation (e.g., filtering, aggregating), and writes the result back to a PostgreSQL table. The script should include error handling for common issues like missing files, invalid data types, and database connection failures. Use Airflow to schedule the script to run daily at 2 AM.",
        "scores": {
          "relevance": 3,
          "clarity": 4,
          "discriminative": 5,
          "reasoning": "Relevance: Directly mentions pandas/PostgreSQL (relevant) but Airflow scheduling is advanced for entry-level ETL role focused on learning basics; generic ETL task (-3 generic). Clarity: Bundles script writing + error handling + Airflow DAG into one question (-2); unclear scope/depth for screening. Discriminative: Tests applied ETL skills but too broad (>10min, multiple components) for weak/strong separation; weak for entry-level.",
          "composite": 4.0
        }
      },
      {
        "role_id": "be-455",
        "role_title": "Staff Engineer - Developer Portal",
        "question": "*Design a scalable plugin architecture for a developer portal built with Backstage using React and Node.js. Your design should support dynamic service discovery and documentation generation, and enable plug-in teams to onboard new services with minimal friction. Include considerations for plugin lifecycle, configuration, and extensibility. Describe how you would structure the core plugin system to support modular development and ensure maintainability across a growing team.*",
        "scores": {
          "relevance": 7,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (plugin architecture, service discovery, documentation, onboarding) and mentions Backstage/React/Node.js from role, but generic across architect roles (-3 red flag). Clarity: Well-scoped with specific considerations, minor vagueness on depth/format (-1 for design scope). Discriminative: Excellent at probing trade-offs, extensibility, and deep architectural thinking for strong separation.",
          "composite": 8.0
        }
      },
      {
        "role_id": "be-456",
        "role_title": "Backend Engineer - Query Optimization",
        "question": "\"Explain how you would instrument and analyze a PostgreSQL database to detect and diagnose slow queries using pganalyze, and walk through a real-world scenario where you used this approach to improve performance. Include specific SQL queries, indexes, and plan analysis steps.\"",
        "scores": {
          "relevance": 7,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests PostgreSQL query analysis core to role but penalizes -2 for pganalyze (not in role desc) and -1 for requiring undocumented real-world experience. Clarity: Well-scoped with specifics requested, minor vagueness on scenario depth. Discriminative: Strong on applied knowledge, trade-offs, and depth via specifics and scenario, distinguishes experts.",
          "composite": 8.0
        }
      },
      {
        "role_id": "be-457",
        "role_title": "Senior Backend Engineer - SLO Automation",
        "question": "\"Design a system that automatically detects and alerts on SLO burn rate violations in a Kubernetes environment using Go, Prometheus, and PostgreSQL. Include how you would track error budgets, handle alerting, and ensure reliability in production. Be specific about how you'd use Sloth for SLO definitions and how you'd integrate with Kubernetes monitoring (e.g., via Prometheus).\"",
        "scores": {
          "relevance": 7,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core SLO/burn rate skills and key tech (Go, Prometheus, K8s), but penalizes -2 for unmentioned Sloth and -1 for generic PostgreSQL not in role desc. Clarity: Well-scoped for screening despite lacking time/format constraints; minor jargon issue with Sloth. Discriminative: Excellent at testing system design, trade-offs, integrations, and production reliability to separate strong candidates.",
          "composite": 8.0
        }
      },
      {
        "role_id": "be-458",
        "role_title": "Backend Engineer - API Gateway Plugins",
        "question": "What are the key differences between Kong's `on_pre_balance` and `on_post_balance` lifecycle events in a plugin, and how would you use them to implement a custom authentication flow that validates user session state and enriches the response with user metadata?",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests Kong plugin development, lifecycle events, auth, and response enrichment\u2014core to API gateway plugin role (no red flags). Clarity: Precise and well-scoped, minor deduction for lacking explicit constraints but unambiguous. Discriminative: Requires understanding trade-offs in lifecycle timing and applied Kong plugin design, strongly separates candidates with practical experience.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-459",
        "role_title": "Junior Backend Engineer - Container Security",
        "question": "\"Walk me through how you would set up a CI/CD pipeline to scan container images for vulnerabilities using Trivy, and explain how you would ensure these scans are both effective and non-disruptive to the development workflow.\"",
        "scores": {
          "relevance": 7,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Tests core container scanning/vulnerability detection skills but assumes Trivy familiarity (not explicitly listed, -2) and is CI/CD heavy for entry-level. Clarity: Well-scoped with clear intent, though minor ambiguity on 'non-disruptive' details (-1 for missing precise constraints). Discriminative: Excellent at probing applied knowledge, trade-offs (effectiveness vs. workflow), and reasoning for strong separation.",
          "composite": 8.0
        }
      },
      {
        "role_id": "be-460",
        "role_title": "Backend Engineer - Experiment Tracking",
        "question": "\"Using MLflow, design and implement a Python script that tracks a simple machine learning experiment. The script should:  \n1. Initialize an MLflow experiment with a unique name (e.g., 'experiment_123').  \n2. Log hyperparameters (e.g., learning rate, batch size) and metrics (e.g., accuracy, loss).  \n3. Save a model artifact (e.g., a trained scikit-learn model) to MLflow's artifact store.  \n4. Ensure the experiment is properly tracked and closed.  \n5. Use Docker to containerize the script so it can be run in a production-like environment.  \n6. Provide instructions on how to run the script locally and in Docker.\"",
        "scores": {
          "relevance": 5,
          "clarity": 6,
          "discriminative": 6,
          "reasoning": "Relevance: Directly tests MLflow (relevant for experiment tracking), but Docker containerization is tangential/not core to ML infra role; generic scripting (-3 red flag). Clarity: Clear steps but vague on expected depth/code detail; multiple bundled tasks including Docker/instructions (-2). Discriminative: Tests applied MLflow knowledge well but Docker adds unnecessary complexity; basic implementation, not deep trade-offs.",
          "composite": 5.666666666666667
        }
      },
      {
        "role_id": "be-461",
        "role_title": "Senior Backend Engineer - Fraud Detection",
        "question": "\"Design a real-time fraud scoring pipeline for a payment system that must handle 10K transactions per second. The pipeline should integrate a rule engine with a machine learning model and support manual review queues. Describe how you would structure the data flow, key components, and how you'd balance real-time performance with model accuracy and reliability.\"",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's core skills (fraud pipelines, rule engines, ML integration, manual queues) with specific tech focus. Clarity: Crystal clear and well-scoped with TPS constraint, though minor vagueness on exact output format. Discriminative: Tests deep applied knowledge, trade-offs (latency vs accuracy), and system design thinking to separate strong candidates.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-462",
        "role_title": "Backend Engineer - Alert Routing",
        "question": "\"Design a system to route alerts from a distributed system to the appropriate on-call team using Alertmanager, with support for dynamic escalation policies, silence management, and deduplication. Explain how you would structure the routing logic, manage silences, and ensure alerts are not duplicated during high-volume events.\"",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's core needs (routing, escalation, silence, deduplication) and specifies Alertmanager, directly testing listed skills. Clarity: Crystal clear and well-scoped for screening, minor deduction for lacking explicit time/format constraints. Discriminative: Tests applied system design, trade-offs in high-volume handling, and deep Alertmanager knowledge, strongly separating candidates.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-463",
        "role_title": "Junior Backend Engineer - Full-text Search",
        "question": "You are tasked with implementing a simple full-text search feature in a Python application using PostgreSQL. The application has a table `products` with columns `id`, `name`, and `description`. Users can search for products by entering a query string. When a query is submitted, return a list of products matching the search term, ranked by relevance.",
        "scores": {
          "relevance": 9,
          "clarity": 8,
          "discriminative": 7,
          "reasoning": "Relevance: Directly tests PostgreSQL full-text search (tsvector/ranking core to role), minor -1 for not explicitly naming tsvector but implies it. Clarity: Clear task and intent, but lacks constraints on output format, query handling, or depth (-2 red flag). Discriminative: Good applied knowledge test distinguishing basic SQL from FTS experts, but open-ended scope risks variable answers.",
          "composite": 8.0
        }
      },
      {
        "role_id": "be-464",
        "role_title": "Staff Engineer - Presence Systems",
        "question": "Design a presence system that tracks real-time user presence and typing indicators using Go, Redis, and WebSockets. The system must support millions of concurrent users. Describe your architecture, data model, and how you would handle scale and reliability.",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core role skills (presence/typing indicators, scale, WebSockets, connection mgmt/state sync) with specified tech (Go, Redis); no red flags. Clarity: Well-scoped for screening with clear components requested, minor deduction for no explicit time constraint. Discriminative: Tests deep applied knowledge, trade-offs in architecture/scaling/reliability for millions of users, strong separation of strong vs weak candidates.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-465",
        "role_title": "Backend Engineer - CDC Pipelines",
        "question": "*Design a CDC pipeline using Debezium and Kafka to replicate data from a PostgreSQL database to Snowflake. Include the configuration of Debezium's connector, handling of schema changes, and an approach to ensure exactly-once delivery. Explain how you would handle initial data synchronization (snapshot) and ensure data consistency during schema changes.*",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's core needs (CDC pipelines, schema changes, snapshots, exactly-once) with exact tech stack. Clarity: Crystal clear, well-scoped for screening, minor deduction for lacking strict time/format constraints. Discriminative: Tests deep applied knowledge, trade-offs in config/handling, strong separation of experts from juniors; not pure recall.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-466",
        "role_title": "Senior Backend Engineer - GitOps Tooling",
        "question": "\"Design a drift detection mechanism in a GitOps pipeline using ArgoCD and Helm. Your solution should detect when a deployed Kubernetes manifest diverges from its Git source, and automatically trigger a rollback to the last known good state if drift exceeds a configurable threshold. Explain your approach, including how you would implement reconciliation, detect drift, and handle rollback. Consider edge cases such as partial drift, temporary mismatches, and network issues.\"",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's core focus on GitOps tooling, reconciliation, drift detection, and rollback using exact tech (ArgoCD, Helm, K8s manifests). No red flags. Clarity: Crystal clear, well-scoped design task with specific requirements and edge cases; minor deduction for lacking explicit time/format constraints. Discriminative: Excellent test of applied knowledge, trade-offs (thresholds, partial drift, temporariness), and deep GitOps understanding to separate strong candidates.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-467",
        "role_title": "Backend Engineer - Connection Pooling",
        "question": "\"Design and implement a Go-based connection pool manager that uses PgBouncer as a proxy to manage PostgreSQL connections. The manager should support dynamic pool sizing based on load, automatic failover to a backup PostgreSQL instance when primary fails, and monitor connection health using a health check endpoint. How would you structure the configuration, handle failover, and ensure connection health is maintained in a Kubernetes environment with horizontal pod autoscaling (HPA)?\"",
        "scores": {
          "relevance": 4,
          "clarity": 5,
          "discriminative": 7,
          "reasoning": "Relevance: Superficially mentions Go and PostgreSQL but heavily focuses on PgBouncer/Kubernetes/HPA not listed in role (connection pooling infra, sizing, transactions, failover); generic design (-3), wrong tech focus (-2). Clarity: Understandable but vague scope/depth for screening, multiple bundled asks (-2), no constraints. Discriminative: Tests applied knowledge/trade-offs well but too broad for screening (>10min, -2).",
          "composite": 5.333333333333333
        }
      },
      {
        "role_id": "be-468",
        "role_title": "Junior Backend Engineer - CI Pipelines",
        "question": "\"Design a GitHub Actions workflow that builds and tests a Python project using Docker. The workflow should include caching for Python dependencies, parallelize tests across multiple CPU cores, and run tests in a containerized environment. Provide a clear explanation of your choices for each step, including caching strategy and parallelization method.\"",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core CI pipeline skills (workflow syntax, caching, test parallelization) for GitHub Actions role, minor ding as Docker not explicitly listed (-1). Clarity: Crystal clear scope, well-formed with specific requirements and explanation request. Discriminative: Requires applied knowledge of caching strategies and parallelization trade-offs with explanation, strongly separates candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-469",
        "role_title": "Senior Backend Engineer - Chaos Engineering",
        "question": "*Design a failure injection experiment using Chaos Mesh to simulate a node failure in a Kubernetes cluster, and implement a recovery validation mechanism that ensures the application remains available and consistent after the failure. Include details on how you would configure the experiment, monitor the impact, and validate recovery using metrics and logs.*",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets Chaos Mesh (core chaos engineering tool for K8s), failure injection, blast radius (via config), and recovery validation\u2014perfect match for role (-0 red flags). Clarity: Precise scope with Chaos Mesh, K8s node failure, monitoring, and validation; well-constrained for screening. Discriminative: Requires applied knowledge of tool config, monitoring/metrics/logs integration, and trade-offs in validation\u2014distinguishes deep expertise from superficial knowledge.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-470",
        "role_title": "Backend Engineer - GraphQL Federation",
        "question": "*Design a schema stitching strategy for a federated GraphQL gateway that connects a user subgraph and a product subgraph. The user subgraph defines a `User` type with fields `id`, `name`, and `email`, while the product subgraph defines a `Product` type with fields `id`, `name`, and `field`. The user subgraph also contains a field `products` of type `[Product!]!` which references the product subgraph. Implement a solution that correctly resolves the `products` field on a `User` object when queried via the gateway. Provide a clear explanation of how the query planning and entity resolution work in this scenario, including how the gateway handles the cross-subgraph resolution.*",
        "scores": {
          "relevance": 9,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core federated GraphQL skills (schema stitching, query planning, entity resolution) matching role; minor deduction for not explicitly naming all role aspects (-1). Clarity: Well-scoped with specific types/fields, clear intent, but lacks explicit constraints on solution format/depth (-1, -1). Discriminative: Requires applied knowledge of trade-offs in stitching/resolution, strong separation of deep vs shallow understanding.",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-471",
        "role_title": "Staff Engineer - Zero Trust Architecture",
        "question": "*Design a solution using SPIFFE and mTLS to secure inter-service communication in a Kubernetes cluster where services need to be authenticated and authorized using identity-based policies. Include a flow from service startup to actual communication. Explain how SPIFFE ensures zero trust, and describe how you would integrate with HashiCorp Vault for identity management and policy enforcement.*",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Directly tests core role skills (mTLS automation, zero trust, policy enforcement) with exact tech (SPIFFE, Kubernetes) from description; crystal clear with well-defined flow and integration scope; strong differentiation via trade-offs in zero trust explanation, Vault integration, and full lifecycle, though minor deduction for no explicit time constraint.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-472",
        "role_title": "Backend Engineer - Vector Search",
        "question": "Design a system to handle semantic search with hybrid retrieval using Pinecone and PostgreSQL. The system should support embedding generation, index management, and retrieval with a fast, scalable, and reliable pipeline.",
        "scores": {
          "relevance": 8,
          "clarity": 5,
          "discriminative": 6,
          "reasoning": "Relevance: Directly tests core skills (embeddings, index mgmt, hybrid search) and mentions Pinecone/PG (relevant to vector infra), but generic across roles (-1 generic). Clarity: Clear intent but 'design a system' lacks scope/constraints like scale/size (-2 red flag), vague depth. Discriminative: Tests applied design knowledge with trade-offs (hybrid, scalable pipeline), but too open-ended (>10min, weak separation).",
          "composite": 6.333333333333333
        }
      },
      {
        "role_id": "be-473",
        "role_title": "Senior Backend Engineer - Refund Processing",
        "question": "Design a system to process partial refunds for a payment platform, ensuring ledger reconciliation and audit trails. The system must handle asynchronous provider callbacks and support rollback on failure. How would you structure the refund processing pipeline in a distributed, fault-tolerant environment using Java, Spring Boot, Kafka, and PostgreSQL? Include considerations for state management, error handling, and audit logging.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Directly tests core role skills (partial refunds, ledger reconciliation, audit trails, provider callbacks) with exact tech stack (Java, Spring Boot, Kafka, PostgreSQL). Crystal clear, well-scoped for screening with specific components and distributed context; no bundling or vagueness. Strong separation via trade-offs in state management, error handling, fault-tolerance, and async processing in distributed env\u2014tests deep applied knowledge, not recall.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-474",
        "role_title": "Backend Engineer - Dashboards API",
        "question": "Write a Go function to render a Grafana dashboard JSON template with dynamic variables. The function should:\n- Accept a dashboard JSON as input\n- Accept a map of variable values (e.g., `map[string]string{\"instance\": \"db1\", \"region\": \"us-east\"}`)\n- Replace all variable references in the dashboard JSON (e.g., `{{instance}}` or `{{region}}`) with their values\n- Output the rendered JSON as a string\n- Handle edge cases like missing variables, invalid JSON, and malformed variable references",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests Go + JSON templating/variable substitution, core to dashboard APIs in observability role (-1 minor for no sharing aspect). Clarity: Precise inputs/outputs, explicit edge cases, well-scoped. Discriminative: Requires applied Go skills (JSON parsing/string replacement), error handling, trade-offs in edge cases for strong separation.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-475",
        "role_title": "Junior Backend Engineer - Search Analytics",
        "question": "\"Imagine you're building a query logging system for a search engine. Users submit search queries, and we want to record the query, the user's session ID, and the timestamp. After processing, we want to store these logs in Elasticsearch. However, we also need to ensure that the logs are not duplicated due to network issues or retries.",
        "scores": {
          "relevance": 9,
          "clarity": 8,
          "discriminative": 8,
          "reasoning": "Relevance: Directly tests query logging (core to role) with Elasticsearch storage and deduplication, matching search analytics focus (-0 generic red flags). Clarity: Well-scoped scenario, clear requirements, but lacks explicit constraints like format or scale (-2 for missing constraints). Discriminative: Probes applied knowledge of logging, idempotency, retries, and ES integration, revealing trade-offs in data pipelines vs pure recall.",
          "composite": 8.333333333333334
        }
      },
      {
        "role_id": "be-476",
        "role_title": "Backend Engineer - Live Updates",
        "question": "Design a scalable real-time dashboard update system using Socket.io and Redis. The system must support room-based selective broadcasting, automatic reconnection, and handle concurrent connections efficiently. Provide a high-level architecture and explain how you would implement the following:",
        "scores": {
          "relevance": 9,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (live updates, rooms, selective broadcasting, reconnection) with exact tech (Socket.io, Redis implied for pub/sub); minor -1 for assuming Redis specificity. Clarity: Clear and well-scoped for high-level design, but lacks explicit constraints like scale targets (-1 red flag partial). Discriminative: Requires architecture, trade-offs, and implementation explanation, strongly separating candidates with real-time systems depth from superficial knowledge.",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-477",
        "role_title": "Senior Backend Engineer - Data Catalog",
        "question": "\"Design a system to automatically extract metadata from a data pipeline using Apache Atlas, and ensure lineage is properly tracked through the pipeline. Describe how you would integrate Kafka for real-time event streaming, Airflow for orchestration, and PostgreSQL for storing metadata. Include specific examples of how you would define entities, relationships, and attributes in Apache Atlas, and how you would trigger metadata updates when data is transformed or moved through the pipeline.\"",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Directly tests core role skills (metadata extraction, lineage tracking) with exact tech stack (Atlas, Kafka, Airflow, PostgreSQL). Crystal clear, well-scoped design with specific examples requested. Strong separation via trade-offs in integration, entity modeling, and real-time triggers; no red flags.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-478",
        "role_title": "Backend Engineer - Cost Attribution",
        "question": "Explain how you would design a system to track and attribute cloud costs to individual teams or projects, using resource tagging and a database. Consider the following constraints:\n- Each cloud resource (e.g., EC2 instance, S3 bucket) has a set of tags (like `team`, `project`, `environment`)\n- Costs are billed at the monthly level, and you need to generate monthly chargeback reports\n- The system must support real-time cost tracking and monthly reporting\n- You must store cost data efficiently and avoid overwriting or losing data\n- You must handle edge cases like missing tags or inconsistent tagging\n- You should use Go, PostgreSQL, and Prometheus for monitoring",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Directly tests core role skills (cost attribution, tagging, chargeback reports) with exact tech stack (Go, PostgreSQL, Prometheus). Crystal clear with specific constraints scoping design discussion. Strong differentiation via trade-offs in real-time vs monthly, edge cases, efficiency, and data integrity; well-scoped for screening (<10min outline). Minor ding for mandating exact stack but aligns perfectly with role.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-479",
        "role_title": "Principal Engineer - Data Architecture",
        "question": "> \"You're designing a data architecture for a company that processes 10M+ daily transactions and runs complex analytical queries on aggregates. The transactional system is currently a PostgreSQL database with high write throughput. You need to build a scalable, cost-efficient data warehouse for analytical queries.  \n>  \n> Describe how you would design the architecture, including choices for data ingestion, storage, and query processing. Justify each decision with clear trade-offs. Consider performance, cost, scalability, and data consistency.\"",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core data architecture strategy, tech selection (builds on PostgreSQL), and analytics/transactional workloads from role; no red flags. Clarity: Crystal clear scenario with specific scale and requirements; minor deduction for no explicit time/format constraints. Discriminative: Excellent at probing applied knowledge, trade-offs, and deep understanding across key dimensions, strongly separating candidates.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-480",
        "role_title": "Junior Backend Engineer - Deployment Automation",
        "question": "\"Write a simple Ansible playbook that deploys a Python application using Docker to AWS EC2. The playbook should:\n- Launch an EC2 instance (using a specified AMI and instance type)\n- Install Docker on the instance\n- Build and run a Docker container from a local Dockerfile\n- Ensure the container starts automatically on boot\"",
        "scores": {
          "relevance": 7,
          "clarity": 9,
          "discriminative": 8,
          "reasoning": "Relevance: Tests configuration management (Ansible) core to role, but overemphasizes advanced AWS/Docker deployment beyond entry-level script-building focus; minor ding for not matching 'will learn' scope exactly (-1) and partial generic scripting (-1). Clarity: Crystal clear with specific, sequential requirements; well-scoped for screening. Discriminative: Requires applied Ansible/EC2/Docker knowledge with practical integration, distinguishing those who can execute from theorists.",
          "composite": 8.0
        }
      },
      {
        "role_id": "be-481",
        "role_title": "Backend Engineer - Canary Deployments",
        "question": "Design a canary deployment pipeline using Istio and ArgoCD that automatically rolls back a service if the canary traffic metrics exceed a predefined threshold (e.g., error rate > 1% or latency > 500ms) over a 5-minute window. Include details on how traffic shifting, metric monitoring, and rollback automation are implemented.",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core canary deployment skills (traffic shifting, metrics, rollback) with exact tech stack (Istio, ArgoCD) from role. Clarity: Crystal clear, well-scoped with specific thresholds/window/example, minor deduction for lacking exact format/output constraints. Discriminative: Requires applied knowledge of integration, trade-offs in monitoring/automation, distinguishes strong candidates able to design end-to-end pipeline from weak ones.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-482",
        "role_title": "Senior Backend Engineer - API Monetization",
        "question": "\"Design a system to track API usage and enforce quotas for different pricing tiers. Describe how you would structure the data model in PostgreSQL, implement quota enforcement in Go, and integrate with Stripe for billing. Include how you would handle edge cases like quota overages and billing disputes.\"",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's core needs (API usage tracking, quotas, pricing tiers, billing). No red flags. Clarity: Crystal clear and well-scoped for screening, minor deduction for no explicit time/format constraints. Discriminative: Tests applied design, trade-offs (edge cases), and role-specific stack (PostgreSQL, Go, Stripe), strongly separates candidates.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-483",
        "role_title": "Backend Engineer - WAF Integration",
        "question": "\"Design a Go service that integrates with ModSecurity to detect and log suspicious HTTP requests, including rate limiting and bot detection. The service should use Redis for rate limiting, PostgreSQL for persistent logging, and Nginx as the proxy. Explain how you would structure the service, handle the ModSecurity events, and ensure accurate bot detection using attack pattern analysis.\"",
        "scores": {
          "relevance": 7,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Tests core WAF, rate limiting, bot detection, and attack analysis skills with relevant tech (Redis fits rate limiting), but heavily specifies unmentioned ModSecurity/Nginx/PostgreSQL/Go (-2 for unlisted tech, -1 generic design). Clarity: Clear intent and components, but lacks constraints like scale/performance (-1, -1 for design without scope). Discriminative: Excellent for probing architecture, event handling, trade-offs in integration and analysis.",
          "composite": 8.0
        }
      },
      {
        "role_id": "be-484",
        "role_title": "Staff Engineer - Model Registry",
        "question": "\"Design a model registry system using MLflow and S3 that supports model versioning, automated deployment to Kubernetes, and governance through access control. Walk through your design decisions, including how you would structure the data model, how you'd manage model versions, how you'd automate deployment, and how you'd implement access control. Be specific about how these components integrate with MLflow, SML, and Kubernetes.\"",
        "scores": {
          "relevance": 9,
          "clarity": 7,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core role skills (model registry, versioning, deployment, governance) and key tech (MLflow, S3, Kubernetes); minor -1 for undefined 'SML'. Clarity: Clear intent and specific components, but vague scope/constraints for screening (-1), minor jargon ambiguity (-1). Discriminative: Excellent at probing trade-offs, integration, and deep applied knowledge for strong separation.",
          "composite": 8.333333333333334
        }
      },
      {
        "role_id": "be-485",
        "role_title": "Junior Backend Engineer - Payment Webhooks",
        "question": "*You're processing a payment webhook from Stripe. The event contains the `id` and `data.object.payment_intent.id`. You need to ensure the webhook is processed only once even if it's delivered multiple times. How would you implement idempotency at the webhook receiver level using Python and FastAPI?*",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests idempotency for payment webhooks (core role skill) with Stripe/FastAPI specifics (-0 red flags). Clarity: Precise scenario, unambiguous implementation ask, well-scoped for screening. Discriminative: Requires applied knowledge of idempotency (e.g., id storage/checks, race conditions), distinguishes strong entry-level candidates via trade-offs like DB choice.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-486",
        "role_title": "Backend Engineer - Span Processing",
        "question": "Design a tail sampling strategy for OpenTelemetry spans in a high-throughput Kafka-based tracing pipeline. The system must handle 100K+ spans per second, with 10% of spans being high-value (e.g., user login, payment processing), and 90% being low-value (e.g., internal service calls). The pipeline processes spans via a Go service that consumes from Kafka, applies sampling logic, and writes to ClickHouse. Tail sampling must ensure that high-value spans are retained with 95% accuracy, while low-value spans are dropped with a configurable threshold. Implement a sampling decision logic that avoids data loss for critical operations and uses minimal CPU overhead. Describe your approach, including how you would validate its effectiveness.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core role requirement (tail sampling in distributed tracing pipeline) with exact tech stack (OpenTelemetry, Kafka, Go, ClickHouse); minor ding for not covering attribute enrichment/storage fully (-1). Clarity: Well-scoped with clear constraints (throughput, value distribution, accuracy targets), unambiguous intent for screening. Discriminative: Tests applied knowledge, trade-offs (accuracy vs CPU, decision logic), validation\u2014strong separation of strong vs weak candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-487",
        "role_title": "Senior Backend Engineer - Search Ranking",
        "question": "Design a system to evaluate the performance of a learning-to-rank (LTR) model in a production search environment. The system should:",
        "scores": {
          "relevance": 7,
          "clarity": 5,
          "discriminative": 8,
          "reasoning": "Relevance: Tests core LTR evaluation skills relevant to role but generic (no specific tech stack, -1); misses feature engineering/model training focus. Clarity: Clear intent but 'design a system' lacks scope/constraints like time, components, or metrics (-2 for no constraints, 7-2=5). Discriminative: Strong for trade-offs in production eval (offline/online metrics, A/B, monitoring), separates good candidates.",
          "composite": 6.666666666666667
        }
      },
      {
        "role_id": "be-488",
        "role_title": "Backend Engineer - Gaming Backend",
        "question": "Design a real-time state synchronization mechanism for a multiplayer game where clients connect via WebSocket and need to keep their game state in sync. The state includes player positions, health, and score. Describe how you would structure the state, handle network latency, and ensure consistency across clients. Specifically, consider the impact of network latency and how you would prevent desynchronization or \"stale\" states.",
        "scores": {
          "relevance": 9,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (real-time state sync for multiplayer game backend) with WebSocket matching real-time needs; minor deduct for no explicit tech stack match but perfectly aligned (-1). Clarity: Clear and well-scoped to key aspects (structure, latency, consistency), but lacks explicit constraints like scale or message format (-1, -1 for design without full constraints). Discriminative: Excellent at probing trade-offs (latency handling, desync prevention), deep understanding required for strong separation.",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-489",
        "role_title": "Backend Engineer - Data Quality",
        "question": "\"Design a data quality monitoring system using dbt, Great Expectations, and Airflow to detect freshness, volume anomalies, and schema drift in a Snowflake warehouse. Walk through your approach, including how you\u2019d structure the data quality checks, define metrics, and schedule the checks in Airflow. Explain how you\u2019d detect schema drift and handle volume anomalies using statistical methods.\"",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfect match to role (dbt, Great Expectations, Airflow align with pipelines/warehouse; directly tests freshness/volume/schema drift). Clarity: Crystal clear, well-scoped design with specific components, minor deduction for no explicit time constraint. Discriminative: Strong on applied knowledge, trade-offs in stats/schema detection, structures checks/scheduling; not trivial recall.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-490",
        "role_title": "Senior Backend Engineer - Environment Management",
        "question": "\"Design and implement a simple Go service that manages a preview environment for a microservice. The service should:",
        "scores": {
          "relevance": 4,
          "clarity": 2,
          "discriminative": 3,
          "reasoning": "Relevance: Superficially mentions Go (assuming in role) but tests generic service design, misses core role needs like namespace isolation, quotas, TTL (-3 generic, -2 misses specifics). Clarity: Incomplete/broken question (cuts off), 'design and implement' bundles multiple tasks without scope (-2 multiple, -2 no constraints). Discriminative: Too open-ended/broad for screening (>10min), weak separation (-2 broad).",
          "composite": 3.0
        }
      },
      {
        "role_id": "be-491",
        "role_title": "Junior Backend Engineer - Read Replicas",
        "question": "You're implementing a read replica routing system using Python and PostgreSQL with SQLAlchemy. Your system needs to route read queries to the appropriate replica based on a consistent, deterministic rule. The primary database is always at `primary.db.example.com:5432`. Read replicas are at `replica1.db.example.com:5432`, `replica2.db.example.com:5432`, and `replica3.db.example.com:5432`.",
        "scores": {
          "relevance": 9,
          "clarity": 7,
          "discriminative": 8,
          "reasoning": "Relevance: Directly tests core read replica routing skills with PostgreSQL/SQLAlchemy, matching role focus (-1 for entry-level, no explicit lag handling mention). Clarity: Clear setup and intent, but lacks explicit constraints on rule type, depth, or output format (-1 red flag, -2 for missing constraints). Discriminative: Requires applied knowledge of routing logic and trade-offs (e.g., consistency vs. load), distinguishes strong candidates.",
          "composite": 8.0
        }
      },
      {
        "role_id": "be-492",
        "role_title": "Backend Engineer - CD Pipelines",
        "question": "\"Design a GitOps-based continuous deployment pipeline using ArgoCD and GitHub Actions that supports multi-environment promotion with approval gates and rollback automation. Explain how you would structure the pipeline, the role of each tool, and how you ensure safety and reliability.\"",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's core requirements (GitOps, multi-env promotion, approvals, rollbacks) using relevant tools; no red flags. Clarity: Crystal clear and well-scoped for screening, minor deduction for lacking explicit time/format constraints. Discriminative: Tests applied design knowledge, trade-offs in safety/reliability, and tool integration, strongly separating strong candidates.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-493",
        "role_title": "Staff Engineer - Reliability Standards",
        "question": "\"Design a production readiness review (PRR) checklist for a new Go service deployed to Kubernetes, with monitoring and alerting via Prometheus and PagerDuty. The checklist should include at least one reliability-focused item (e.g., circuit breakers, timeouts), one observability item (e.g., metrics, logs), and one incident management item (e.g., escalation path). Explain your rationale for including each category.\"",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role responsibilities (PRR design, reliability standards) with specific tech (Go, K8s, Prometheus, PagerDuty) matching SRE focus; minor ding for assuming these exact tools. Clarity: Crystal clear with explicit requirements, categories, and rationale request; well-scoped. Discriminative: Requires design thinking, trade-offs, and justification, strongly separating candidates with SRE depth from superficial ones.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-494",
        "role_title": "Backend Engineer - API Mocking",
        "question": "\"Design a WireMock stub configuration in TypeScript that handles a GET request to `/api/v1/users/{id}` with the following requirements:\n- Match the path and query parameters (e.g., `?active=true`)\n- Match the request headers, specifically `Authorization: Bearer <token>` and `X-Client-ID: 123`\n- Return a JSON response with user data for a specific user ID (e.g., `id: 42`)\n- Include a 200 status code and a `Content-Type: application/json` header\n- Handle a 404 if the user ID is not found (use a 404 stub with a custom error message)\n- Ensure the stub is reusable and can be easily configured with dynamic values (e.g., via environment variables or configuration files)\"",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 8,
          "reasoning": "Relevance: Directly tests WireMock (core to API mocking), TypeScript config, request matching, templating, and conditional responses\u2014matches role perfectly (-0 red flags). Clarity: Precise, well-scoped requirements with examples, no ambiguity or bundling. Discriminative: Requires applied knowledge of WireMock matchers/priority, templating for dynamic IDs, and conditional stubs\u2014distinguishes strong candidates but not extreme trade-offs.",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-495",
        "role_title": "Senior Backend Engineer - Audit Logging",
        "question": "\"Design a Go service that receives audit events from Kafka and writes them to ClickHouse with immutable storage and a time-based retention policy. The service should ensure data integrity and prevent tampering. Explain how you would implement tamper-proof storage and handle retention. Include considerations for high availability, scalability, and performance.\"",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (audit logging, tamper-proof storage, retention) with relevant tech (Go, Kafka, ClickHouse); minor ding for assuming unlisted tech (-1). Clarity: Crystal clear, well-scoped design question with specific components and considerations. Discriminative: Probes deep trade-offs in integrity, HA, scalability, and performance, strongly separating strong candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-496",
        "role_title": "Junior Backend Engineer - Model Serving",
        "question": "\"Design and implement a FastAPI-based model serving endpoint that loads a pre-trained scikit-learn model (e.g., Random Forest Classifier) from disk and serves predictions via a REST API. The endpoint should support batch inference on a list of input data (a list of dictionaries), handle model loading and caching via Redis for performance, and include basic error handling and logging.\"",
        "scores": {
          "relevance": 4,
          "clarity": 6,
          "discriminative": 8,
          "reasoning": "Relevance: Generic FastAPI/scikit-learn task superficially matches ML serving but adds unmentioned Redis (red flag -2), missing role focus on model loading/batching/monitoring; feels like generic programming (-3). Clarity: Clear intent but vague on model file path/format, Redis setup, input schema, logging details (missing constraints). Discriminative: Strong on applied FastAPI/ML serving with batching/caching trade-offs, differentiates skilled candidates well.",
          "composite": 6.0
        }
      },
      {
        "role_id": "be-497",
        "role_title": "Backend Engineer - Payout Systems",
        "question": "Design a system to process payout batches for a marketplace platform. Each batch contains multiple user payouts, and payouts must be validated against bank account details before being processed. The system must support batch processing, retry mechanisms, and reconciliation of processed payouts. Describe your architecture, including how you would handle bank account validation, batch processing, and reconciliation. Use Go, PostgreSQL, Kafka, Redis, and gRPC for your design.",
        "scores": {
          "relevance": 8,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core payout batch processing, validation, and reconciliation from role; uses exact tech stack but generic (-1 for not deeply role-specific). Clarity: Well-scoped system design with specific tech and components; minor deduction for lacking time/format constraints (-1). Discriminative: Strong on trade-offs in retries, distributed processing, and integration; distinguishes deep architects from superficial ones.",
          "composite": 8.333333333333334
        }
      },
      {
        "role_id": "be-498",
        "role_title": "Senior Backend Engineer - Profiling Infrastructure",
        "question": "\"Explain how you would design a continuous profiling system for a Go application running in Kubernetes, using Pyroscope for data collection, ClickHouse for storage, and Grafana for visualization. Include how you would handle baseline comparison, detect anomalies, and optimize storage for long-term retention.\"",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's core focus on continuous profiling, flame graphs (implied), baseline comparison, and storage optimization, using relevant tech (Go/K8s common for infra, tools align with profiling stack). No red flags. Clarity: Crystal clear and well-scoped for screening, minor deduction as no explicit time/format constraints. Discriminative: Tests deep applied knowledge, trade-offs (e.g., storage opt, anomaly detection), distinguishes strong architects from weak ones; appropriately scoped.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-499",
        "role_title": "Principal Engineer - Search Platform",
        "question": "Design a resilient, scalable search platform for an enterprise with 10M+ daily active users and 50M+ daily search queries. The platform must support real-time indexing and querying of unstructured data (e.g., product catalogs, user-generated content). It must handle data consistency, availability, and fault tolerance across distributed systems. Your solution should include high-level architectural decisions, data flow, fault tolerance, and recovery strategies. Consider the trade-offs between performance, cost, and operational complexity. Explain how you would ensure data consistency and availability under network partitions and node failures. Describe how you would monitor and respond to failures.",
        "scores": {
          "relevance": 7,
          "clarity": 6,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core search platform architecture/strategy skills for the role but generic (no specific tech stack), minor generic penalty (-1). Clarity: Clear intent but 'design a system' lacks explicit screening constraints like time/depth (-2). Discriminative: Excellent at probing trade-offs, deep distributed systems understanding, fault tolerance, and ops\u2014strong separation of strong candidates.",
          "composite": 7.333333333333333
        }
      },
      {
        "role_id": "be-500",
        "role_title": "Staff Engineer - Streaming Architecture",
        "question": "You're designing a real-time data pipeline for a financial trading platform that must deliver market data to thousands of connected clients with zero data loss and sub-100ms latency. The pipeline consumes market data from Kafka, processes it in Rust, and delivers it via WebSocket. Design the event schema, delivery guarantees, and fan-out pattern for this system. Explain how you would ensure zero data loss and sub-100ms latency.",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's core focus on streaming infrastructure, event schemas, delivery guarantees, and fan-out; uses Kafka (implied streaming) and specifies Rust processing. Clarity: Crystal clear and well-scoped for screening, directly tied to role skills; minor deduction possible for no explicit time/format constraints but highly precise. Discriminative: Excellent at testing applied architecture knowledge, trade-offs (e.g., at-least-once vs exactly-once, fan-out scalability), and deep understanding to separate strong architects from weak ones.",
          "composite": 9.333333333333334
        }
      }
    ]
  },
  "grok-4-1": {
    "model": "grok-4-1",
    "num_samples": 100,
    "avg_relevance": 9.08,
    "avg_clarity": 8.97,
    "avg_discriminative": 9.0,
    "avg_composite": 9.016666666666666,
    "results": [
      {
        "role_id": "be-406",
        "role_title": "Senior Backend Engineer - LLM Serving",
        "question": "**Question:**  \nIn vLLM, explain how continuous batching works for LLM inference and describe one key optimization you've implemented (or would implement) related to KV cache management in a production serving setup using Python and vLLM. (2-3 sentences)",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Directly tests core role skills (batching, KV cache) using vLLM (key for LLM serving infra); clear 2-3 sentence scope avoids bundling/multiple questions; distinguishes via explanation + applied optimization (trade-offs/experience), not mere recall. Minor ding for assuming vLLM familiarity but it's spot-on for role.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-404",
        "role_title": "Senior Backend Engineer - Feature Platform",
        "question": "**Question:**  \nIn Feast, describe a practical scenario where you'd use a push source versus a pull source for feature ingestion, and outline the key code differences in Python when defining the feature view. (e.g., for online serving in a feature platform).",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests Feast (core to feature platforms for ML teams, including online serving); minor deduction as Feast not explicitly listed but perfectly matches role focus (-1 red flag avoided). Clarity: Precise scenario request with code focus and example context; well-scoped. Discriminative: Requires applied Feast knowledge, trade-offs (push vs pull), and practical Python implementation, distinguishing strong candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-403",
        "role_title": "Backend Engineer - Inference Optimization",
        "question": "**Question:**  \nIn TensorRT, when optimizing a latency-sensitive inference model for deployment on Triton Inference Server, walk me through your step-by-step approach to implementing INT8 quantization. What key considerations would you have for GPU memory usage and accuracy validation? (Feel free to mention any Python tools or Kubernetes aspects if relevant.)",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Directly targets core role skills (quantization for latency-sensitive models, GPU memory optimization) with exact tech stack (TensorRT, Triton). Clear step-by-step structure with specific focus on key considerations; optional mentions don't confuse. Tests applied deep knowledge, trade-offs (accuracy vs. memory/latency), distinguishes experts from juniors. Minor ding for optional tangents but no red flags hit.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-402",
        "role_title": "Backend Engineer - Model Deployment",
        "question": "**Question:**  \nYou're deploying a machine learning model to production using KServe on Kubernetes. Walk me through the key steps you'd take in Python to package the model (e.g., using a framework like PyTorch), create a KServe InferenceService YAML, apply it via kubectl, and set up a simple health check with Redis for caching predictions. What would you do if the deployment fails rollout? (Feel free to sketch code snippets or commands.)",
        "scores": {
          "relevance": 4,
          "clarity": 4,
          "discriminative": 6,
          "reasoning": "Relevance: Superficially mentions ML deployment but focuses heavily on unmentioned KServe/Kubernetes/Redis (-2 minor tech, -2 not in role); generic steps could apply broadly (-3). Clarity: Multiple bundled tasks (packaging, YAML, apply, health check, failure) make it sprawling (-2); vague scope/depth. Discriminative: Tests applied sequence but recall-heavy on specific unrequired tools; weak separation for role.",
          "composite": 4.666666666666667
        }
      },
      {
        "role_id": "be-401",
        "role_title": "Backend Engineer - Training Infrastructure",
        "question": "**Question:**  \nIn a Ray cluster running on Kubernetes with multiple GPU nodes, you've submitted a distributed training job using Ray Train. One worker pod crashes due to an out-of-memory (OOM) error on its GPU. Walk me through your step-by-step debugging process and how you'd resolve it to prevent future failures. (Focus on practical Ray/K8s commands or configs you'd use.)\n\n*(Expected answer: Check Ray dashboard/logs (`ray status`, pod logs via `kubectl`), scale resources in RayCluster YAML (e.g., GPU requests/limits), enable fault tolerance with `TrainConfig(fault_tolerance=True)`, adjust batch size or use gradient checkpointing in training script; demonstrates hands-on distributed ML infra skills.)*",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's core focus on distributed ML infra (Ray, K8s, GPU allocation, job scheduling/orchestration); no red flags. Clarity: Crystal clear scenario with specific focus on practical commands/configs; minor deduction as it doesn't specify time/depth constraints but well-scoped. Discriminative: Tests applied debugging, trade-offs (e.g., scaling vs. batch size), and deep Ray/K8s knowledge; expected answer shows strong separation between candidates with hands-on experience vs. theory-only.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-405",
        "role_title": "Senior Backend Engineer - Model Monitoring",
        "question": "**Question:**  \nIn Python, describe a practical approach to implement data drift detection for a production ML model (e.g., using a statistical test like Kolmogorov-Smirnov on feature distributions between training and live inference data). Include key code snippets for computing the test statistic and divergence metric, and explain how you'd integrate it into a Prometheus exporter for alerting via Grafana if drift exceeds a threshold like p-value < 0.01. What considerations would you have for PostgreSQL storage of historical drift metrics?",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core ML monitoring skills (drift detection) and production aspects (alerting, metrics storage) from role; minor ding for Prometheus/Grafana/PostgreSQL not explicitly listed (-1). Clarity: Well-scoped, unambiguous with specific example, constraints, and integration path. Discriminative: Requires applied Python knowledge, statistical understanding, system integration, and trade-offs (e.g., storage considerations), strongly separating strong candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-409",
        "role_title": "Junior Backend Engineer - File Upload",
        "question": "**Question:**\n\nIn a FastAPI endpoint for file uploads, how would you handle a multipart file upload from the client? Write a simple code snippet showing the endpoint that receives a single file, validates its size (max 10MB), and returns a success message if valid. (No need to implement S3 storage\u2014just focus on receiving and validating the file.)\n\n*Expected answer outline (for recruiter reference):*\n```python\nfrom fastapi import FastAPI, File, UploadFile, HTTPException\nfrom fastapi.responses import JSONResponse\n\napp = FastAPI()\n\n@app.post(\"/upload/\")\nasync def upload_file(file: UploadFile = File(...)):\n    # Validate size (10MB = 10 * 1024 * 1024 bytes)\n    if file.size > 10 * 1024 * 1024:\n        raise HTTPException(status_code=413, detail=\"File too large\")\n    \n    # Optional: Read/process file content\n    contents = await file.read()\n    \n    return JSONResponse({\"message\": \"File uploaded successfully\", \"filename\": file.filename})\n```\n\n*Tests: FastAPI `UploadFile`, async handling, basic validation, junior-level practicality.*",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 8,
          "reasoning": "Relevance: Directly tests FastAPI file uploads, validation, and multipart handling\u2014core to role (-1 minor for not testing storage integration). Clarity: Crystal clear, well-scoped with specific constraints, single focused task. Discriminative: Good separation via applied FastAPI knowledge, async handling, and validation logic; junior-appropriate but not trivial.",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-408",
        "role_title": "Junior Backend Developer - Health Endpoints",
        "question": "**Question:**\n\nIn Go, implement a simple HTTP handler for a `/healthz` endpoint that performs a basic liveness check (e.g., verifies a database connection is alive or a simple computation succeeds). The handler should return HTTP 200 OK with JSON `{\"status\": \"healthy\"}` if successful, or HTTP 500 with `{\"status\": \"unhealthy\", \"error\": \"brief error message\"}` if it fails. Include the necessary imports and a basic example of calling it from `main()` using Go's `net/http` package.\n\n*(Expected: ~10-15 lines of code demonstrating handler setup, error handling, and JSON response. Tests understanding of Go HTTP servers and practical health checks for Kubernetes probes.)*",
        "scores": {
          "relevance": 10,
          "clarity": 10,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (health check endpoints, liveness probes) in Go, matching exact requirements\u2014no red flags. Clarity: Crystal clear with precise specs on endpoint, responses, imports, and scope (~10-15 lines)\u2014perfectly scoped. Discriminative: Strong test of applied Go HTTP/JSON skills and error handling; distinguishes practical knowledge from trivia (slight deduction as strong candidates could template it, but excellent separation).",
          "composite": 9.666666666666666
        }
      },
      {
        "role_id": "be-407",
        "role_title": "Staff Backend Engineer - ML Infrastructure",
        "question": "**Question:**  \nYou're leading the ML infrastructure team and need to scale a distributed training job using Ray on Kubernetes. The job is hitting memory pressure during data loading on a 10-node cluster, causing frequent OOM kills and restarts. Walk me through your step-by-step approach to diagnose and resolve this, including specific Ray/K8s configurations you'd adjust and why. (Aim for 2-5 min response.)",
        "scores": {
          "relevance": 9,
          "clarity": 10,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core ML infra skills (distributed training, scaling, Ray/K8s) central to leading ML platforms; minor ding as Ray not explicitly listed but fits infrastructure focus (-1). Clarity: Crystal clear scenario, specific problem, scoped with time limit and step-by-step expectation. Discriminative: Requires applied knowledge of Ray/K8s diagnostics, configs, trade-offs (e.g., memory tuning, sharding), distinguishing strong ML infra leaders from juniors.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-415",
        "role_title": "Senior Backend Engineer - Multipart APIs",
        "question": "**Question:**  \nIn a FastAPI application handling resumable multipart uploads to S3 (e.g., using `boto3`), a client reports that after a network interruption, their upload resumes from the wrong chunk offset, causing data corruption. Walk me through your debugging approach and how you'd fix it to ensure reliable resumption. What key FastAPI and S3 features would you leverage?",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 10,
          "reasoning": "Relevance: Directly targets core role skills (resumable uploads, chunk management, S3) with FastAPI/boto3; minor ding for not explicitly mentioning multipart. Clarity: Well-scoped debugging scenario with clear intent, no ambiguity. Discriminative: Requires deep applied knowledge of resumption logic, trade-offs in FastAPI state/S3 multipart APIs, distinguishing strong debugging skills.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-416",
        "role_title": "Staff Backend Engineer - External APIs",
        "question": "**Question:**  \nYou're leading the design of an external API for partner integrations using Go and OpenAPI specs, deployed via Kong on Kubernetes. A key partner needs to integrate with rate limiting and usage-based monetization (e.g., charge per 1K API calls).  \n\nWalk me through your approach to:  \n1. Defining the rate limiting and monetization logic in the OpenAPI spec.  \n2. Implementing this in Go (high-level code structure).  \n3. Configuring Kong plugins for enforcement.  \n\nWhat trade-offs would you consider for partner enablement vs. operational overhead?",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Directly tests core API strategy, monetization, partner enablement, and integration patterns with specific tech (Go, OpenAPI, Kong, K8s) matching role focus. Crystal clear with numbered parts and scoped depth for screening. Strong separation via applied design, implementation, config, and trade-offs; minor ding for bundling but well-structured (-0).",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-411",
        "role_title": "Backend Engineer - Admin APIs",
        "question": "**Question:**  \nIn a FastAPI application using PostgreSQL, you need to implement an admin API endpoint that allows updating a user's role (e.g., from 'user' to 'admin'). This endpoint requires privileged access checks and must log the action for audit purposes, including who made the change, what changed, and when.\n\nProvide a concise code snippet (or pseudocode) showing:  \n1. The FastAPI endpoint with dependency injection for auth (assume a `get_current_admin` dependency).  \n2. The database update query (using SQLAlchemy or raw SQL).  \n3. Audit logging to a separate table or Redis.\n\nWhat key considerations would you add for security and reliability? (Limit response to 300 words.)",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests FastAPI, PostgreSQL, auth/audit core to admin APIs (-0 red flags). Clarity: Precise scope, clear components, word limit, assumes standard dep (-0 red flags). Discriminative: Requires applied integration of auth/DB/logging + trade-offs/security insights, strong separation without being too broad.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-410",
        "role_title": "Backend Engineer - Bulk Operations",
        "question": "**Question:**\n\nYou're building a Go API endpoint that accepts a bulk operation to update up to 1,000 user records in PostgreSQL (e.g., via a JSON array of user IDs and new email addresses). The operation should be idempotent, support partial success (e.g., log successes/failures and return a summary), and use Kafka for async batch processing of failures.\n\nSketch the key parts of your Go handler function, including:\n- How you'd ensure idempotency (e.g., via a unique request ID).\n- Database interaction strategy for efficiency.\n- Response structure for partial success.\n\nProvide pseudocode or concise Go snippets (no full implementation needed). Why this approach?",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core role skills (bulk ops, idempotency, partial success) with exact tech stack (Go, PostgreSQL, Kafka); minor deduction as Kafka is implied but not explicit in role. Clarity: Precise scope, clear requirements, well-constrained for screening. Discriminative: Requires applied knowledge of trade-offs (idempotency, DB efficiency, async failures), strong separation via reasoning/justification.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-413",
        "role_title": "Senior Backend Engineer - API Gateway Logic",
        "question": "**Question:**  \nIn Envoy, you're building a custom Lua filter for an API gateway to transform incoming requests by adding a custom `x-tenant-id` header based on the `Host` header (e.g., `api.acme.com` \u2192 `tenant: acme`). Provide a concise Lua script snippet for the `onRequest` phase that inspects the Host header, extracts the tenant subdomain, and sets the new header. Also, briefly explain how you'd configure this filter in Envoy's listener config (1-2 lines).\n\n*(Expected: ~10-15 lines of Lua + short YAML snippet; tests practical Envoy/Lua integration for request transformation at senior level.)*",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core API gateway extension skills (request transformation via Envoy/Lua), matches role focus perfectly (-0 red flags). Clarity: Crystal clear, well-scoped with phase, expected output, and constraints. Discriminative: Requires practical applied knowledge of Envoy/Lua integration, header parsing, and config\u2014strong separation of senior-level candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-414",
        "role_title": "Senior Backend Engineer - Long-Polling",
        "question": "**Question:**  \nYou're implementing a long-polling API endpoint in Go for tracking the status of async background jobs (e.g., using Redis for job state and PostgreSQL for persistence). The endpoint should block client requests up to 30 seconds while waiting for job completion or updates.\n\nDescribe your approach to handling this in Go, including:  \n1. How you'd structure the HTTP handler to implement the long poll (without blocking the entire server).  \n2. How you'd manage timeouts and prevent resource exhaustion from many concurrent connections.  \n3. A fallback strategy if the client disconnects early or the long poll times out.\n\n*(Expected response: ~2-5 min; senior candidates should mention goroutines/channels/select for non-blocking waits, Redis pub/sub or polling with context timeouts, graceful connection cleanup via ctx.Done(), and exponential backoff or WebSocket fallback.)*",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (long-polling APIs, connection mgmt, timeouts, fallbacks) with exact tech stack (Go implied, Redis/PostgreSQL); minor deduction as Go not explicitly in role desc (-1). Clarity: Crystal clear, well-scoped with numbered parts, explicit time expectation, no bundling issues. Discriminative: Requires applied Go concurrency knowledge (goroutines/channels), trade-offs in timeouts/cleanup/fallbacks, separates seniors via depth; expected response guides strong separation.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-419",
        "role_title": "Backend Engineer - Retry Logic",
        "question": "**Question:**  \nIn Go, implement a simple retry function for a distributed operation (e.g., publishing to Kafka) that uses exponential backoff with jitter and respects a maximum retry budget of 5 attempts. The function should take a callback `fn func() error` and return the final error if all retries fail. Assume a base delay of 100ms and max delay of 5s.\n\n*Follow-up (if time): How would you integrate this with Redis to track per-operation retry budgets across distributed nodes?*",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core retry infrastructure skills (exponential backoff, jitter, budgets) in Go for distributed ops, matching role; minor deduction as Kafka is example only (-1). Clarity: Precise constraints (delays, budget, signature), unambiguous for screening. Discriminative: Requires applied knowledge of backoff/jitter math and implementation; follow-up tests distributed scaling with Redis, probing deeper trade-offs.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-412",
        "role_title": "Backend Engineer - Analytics APIs",
        "question": "**Question:**  \nYou're building a Go-based analytics API endpoint that aggregates daily active users (DAU) from a ClickHouse table with billions of event rows (e.g., `SELECT date, COUNT(DISTINCT user_id) FROM events WHERE date >= ? GROUP BY date`). The query takes 5+ seconds on hot data. Outline your step-by-step approach to optimize this for sub-200ms response times, including specific caching strategies with Redis and any relevant ClickHouse techniques. (Focus on trade-offs for freshness vs. performance.)\n\n*(Expected answer: Materialized views or aggregating tables in ClickHouse for pre-aggregated DAU; Redis for TTL-cached results with cache-aside or write-through patterns (e.g., 5-15min TTL); Go handler pseudocode showing cache check/miss \u2192 query \u2192 store; trade-offs like eventual consistency.)*",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 10,
          "reasoning": "Relevance: Perfectly matches role's core needs (analytics APIs, aggregation queries, time-series, caching) with exact tech (Go, ClickHouse, Redis implied by strategies). No red flags. Clarity: Crystal clear, well-scoped with constraints (sub-200ms, trade-offs), specific query example; minor -1 for no explicit time limit but ideal for screening. Discriminative: Requires deep applied knowledge of optimizations, caching patterns, trade-offs, and integration\u2014strong separation of experts from basics.",
          "composite": 9.666666666666666
        }
      },
      {
        "role_id": "be-417",
        "role_title": "Junior Backend Developer - Event Sourcing",
        "question": "**Question:**  \nIn an event-sourced system using Kafka and Java, you have an `Order` aggregate that tracks its state (e.g., `CREATED`, `SHIPPED`, `DELIVERED`) via events like `OrderCreated` and `OrderShipped`. Describe in 3-5 sentences how you would implement a simple event handler in Java to load and rebuild the current state of an `Order` from its event stream (assume events are stored in Kafka with an offset). Include key steps like reading events and applying them to the aggregate. \n\n*(Follow-up probe if needed: What happens if a new event arrives mid-rebuild?)*",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core event sourcing skills (event handlers, aggregate state rebuilding) for the role; Kafka/Java match implied stack, minor offset detail fits (-1 for not explicitly in desc). Clarity: Crystal clear, well-scoped to 3-5 sentences with specific steps, follow-up adds precision without bundling. Discriminative: Requires applied understanding of event replay and concurrency (follow-up tests trade-offs like optimistic locking), strong separation beyond recall.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-420",
        "role_title": "Backend Engineer - Graceful Shutdown",
        "question": "**Question:**  \nIn a Go gRPC server running in Kubernetes, explain how you would implement graceful shutdown to handle SIGTERM signals, drain existing connections, and complete in-flight requests without dropping them. Outline the key Go code changes (e.g., server config, signal handling) and any relevant Kubernetes annotations you'd use. (2-3 sentences + pseudocode snippet)",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Directly targets core role requirements (graceful shutdown, SIGTERM, connection draining, in-flight requests) using exact tech stack (Go, gRPC, Kubernetes); crystal clear with scoped response format (2-3 sentences + pseudocode) and no bundling/ambiguity; tests applied knowledge of signal handling, server config, and K8s integration with trade-offs in real-world deployment, strongly differentiating experienced candidates (-0 red flags).",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-418",
        "role_title": "Junior Backend Engineer - Service Clients",
        "question": "**Question:**\n\nIn Go, when implementing a gRPC service client, how would you add a simple retry mechanism for transient errors (e.g., connection failures)? Provide a short code snippet showing the key parts using the standard gRPC retry package or interceptor, and explain one potential pitfall for juniors to watch out for.\n\n*(Expected answer: Use `grpc.WithRetry()` in dial options or a retry interceptor; import \"google.golang.org/grpc/retry\"; pitfall like infinite retries without backoff or handling non-retryable errors.)*",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core Go/gRPC client skills with retries, matching role's retry/error handling focus (-0 red flags). Clarity: Precise scope (simple retry, short snippet, one pitfall), unambiguous with expected depth. Discriminative: Requires applied knowledge of gRPC retry API, code writing, and trade-off awareness (pitfalls like backoff/non-retryable errors), strong separation of junior levels.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-421",
        "role_title": "Senior Backend Engineer - Security Automation",
        "question": "**Question:**  \nYou're automating secrets rotation for a Kubernetes cluster using HashiCorp Vault and Python. Walk me through how you would implement a Python script that dynamically fetches a database credential from Vault, tests its validity by connecting to the DB (without committing changes), rotates it if valid, and updates the new secret as a Kubernetes Secret. What key security practices would you include, and how would you handle potential failures like network issues or Vault downtime? (High-level steps and 1-2 code snippets are fine.)",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (secrets rotation automation) with exact tech stack (Vault, Kubernetes, Python, DB); no red flags (-0). Clarity: Crystal clear, well-scoped for screening (high-level steps + snippets), specific constraints given; no red flags (-0). Discriminative: Tests applied knowledge, trade-offs (security practices, failure handling), distinguishes strong automation/security engineers; not recall or trivial.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-423",
        "role_title": "Staff Engineer - Incident Response Platform",
        "question": "**Question:**  \nYou're designing an incident response platform in Go that integrates with PagerDuty and Slack. Walk us through how you'd implement a service that detects when an on-call engineer's MTTR (mean time to resolution) for critical incidents exceeds an SLO target of 30 minutes, then automatically notifies the team via Slack and escalates in PagerDuty. Include key Go constructs you'd use and any reliability considerations (e.g., retries, idempotency).",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core incident response tooling, SLO tracking, Go (inferred as key for tooling), PagerDuty/Slack integrations (-1 for no explicit Go mention in role, but fits tooling ownership). Clarity: Crystal clear, well-scoped with specific MTTR/SLO trigger, integrations, Go focus, and reliability asks. Discriminative: Requires applied knowledge of Go constructs, integrations, detection logic, trade-offs in retries/idempotency\u2014strong separation of strong vs weak candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-422",
        "role_title": "Junior Backend Engineer - API Testing",
        "question": "**Question:**\n\nUsing pytest and the `requests` library in Python, write a simple test function to verify that a FastAPI GET endpoint `/users/{user_id}` returns a 200 status code and valid JSON data when the user exists (assume a valid `user_id=1`). Include a basic assertion for the response containing a `'name'` field.\n\n*Follow-up (if time allows): How would you parameterize this test to check multiple user IDs using pytest fixtures or parametrization?*",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 8,
          "reasoning": "Relevance: Directly tests pytest, requests, and FastAPI\u2014core to API testing role (-1 for not covering fixtures/contract testing explicitly). Clarity: Precise scope, clear expectations, single focused task with optional follow-up. Discriminative: Requires writing functional code with assertions (good separation); follow-up tests deeper patterns like parametrization.",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-424",
        "role_title": "Backend Engineer - Message Serialization",
        "question": "**Question:**  \nIn a Kafka-based system using Avro and Schema Registry, you've just deployed a new version of your message schema that adds an optional field `userPreferences` (union of null and a string map) to an existing `UserEvent` schema. The producer is now sending messages with this field populated for some events, but your consumers (running the old schema version) are failing to deserialize.  \n\nExplain the likely cause of the failure and provide 2-3 concrete steps to resolve it while ensuring backward compatibility for existing consumers. What Avro compatibility rules are relevant here?",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core schema evolution, backward compatibility, and validation in Avro/Schema Registry context matching role (minor -1 for assuming Kafka, not explicit). Clarity: Precise scenario, unambiguous intent, well-scoped. Discriminative: Requires applied knowledge of Avro rules, trade-offs, and fixes; distinguishes deep understanding from superficial recall.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-425",
        "role_title": "Senior Backend Engineer - Graph Analytics",
        "question": "**Question:**  \nYou're optimizing a Neo4j graph database for a social network recommendation engine with 1 billion edges (e.g., user-friend connections). Traversal queries for \"friends-of-friends\" recommendations are taking >10 seconds.  \n\nDescribe 2-3 specific optimization techniques you'd apply in Neo4j (e.g., indexing, query tuning, schema changes), and explain how you'd integrate Apache Spark for any heavy graph computations. What metrics would you monitor to validate improvements?  \n\n*(Expected response: 2-5 min; tests senior-level practical Neo4j optimization, Spark integration, and graph-scale thinking.)*",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets Neo4j optimization and Spark integration for billion-edge graph analytics in social/recommendation contexts, core to role (-1 for not explicitly listing Neo4j/Spark in desc but perfect conceptual match). Clarity: Unambiguous, well-scoped with scenario, specific asks (2-3 techniques), time guide, no bundling. Discriminative: Requires applied knowledge of trade-offs (techniques, integration, metrics), separates seniors via depth vs rote recall.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-427",
        "role_title": "Backend Engineer - Feature Store",
        "question": "**Question:**  \nIn Feast, describe a practical scenario where you'd use an online store like Redis alongside an offline store like PostgreSQL in an ML feature pipeline. What key steps would you take in Python to define and materialize features for both, ensuring low-latency serving for real-time inference? (Feel free to sketch a short code snippet or config example.)\n\n*(Expected answer: Candidate explains online for real-time/low-latency lookups, offline for historical/batch training; steps include defining FeatureView with entities/features, using PushSource for online updates, applying `materialize-incremental` for offline, and `feast apply` for registry. Code might show `@feast_feature_view` decorator with `online=True` for Redis, batch/online sources.)*",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests Feast (core to feature store infrastructure), online/offline stores, versioning, real-time serving\u2014perfect match to role; no red flags. Clarity: Unambiguous scenario and steps requested, well-scoped with code/config prompt; minor vagueness on snippet length (-1). Discriminative: Requires applied Feast knowledge, trade-offs (latency vs historical), and practical Python steps\u2014not rote recall; strong separation of experts from juniors.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-428",
        "role_title": "Senior Backend Engineer - Payment Orchestration",
        "question": "**Question:**\n\nIn our payment orchestration system built with Go, Kafka, and PostgreSQL, imagine you're routing a high-priority transaction (e.g., $10k+) to one of three providers (Stripe, Adyen, PayPal) based on success rates, latency, and cost. The primary provider fails mid-transaction.\n\nDescribe (in 3-5 sentences) the failover logic you'd implement in Go, including how you'd track success rates in real-time (e.g., via Redis/Kafka) and ensure idempotency to avoid double-charging. What key metrics would you monitor post-failover?",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Directly tests core payment orchestration skills (routing, failover, success rates, idempotency) using role's Go stack plus relevant Kafka/PostgreSQL; minor ding for adding Redis (unmentioned) but fits real-time needs. Crystal clear with 3-5 sentence scope, specific scenario, and post-failover metrics. Strong separation via trade-offs in real-time tracking, Go implementation, and metrics without being too broad.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-430",
        "role_title": "Junior Backend Engineer - Search Indexing",
        "question": "**Question:**  \nYou're building a Python script to bulk index 10,000 product records from PostgreSQL into Elasticsearch. The records include fields like `id`, `name`, `description`, and `price`.  \n\n1. Write a short Python code snippet (using the `elasticsearch` library) to connect to ES, fetch records from Postgres (assume a simple query), and perform a bulk index operation.  \n2. What are 2 key things you'd configure in the Elasticsearch mapping for the `description` field to make it searchable?  \n\n*(Expect ~3-5 lines of code + brief explanations; focus on practicality over perfection.)*",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 8,
          "reasoning": "Relevance: Directly tests core skills (bulk indexing, Python, ES, PostgreSQL) for entry-level search indexing role; minor deduction as mapping design is only briefly touched (-1). Clarity: Well-scoped with exact task, libraries, fields, and expectations; no bundling issues. Discriminative: Requires practical code writing + applied mapping knowledge (e.g., analyzer, type), separates those who can implement from theorists.",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-426",
        "role_title": "Junior Backend Engineer - DevOps Scripting",
        "question": "**Question:**\n\nYou're setting up a simple CI/CD pipeline using GitHub Actions for a Python app. The workflow should build a Docker image on every push to the `main` branch, tag it with the commit SHA, and push it to Docker Hub (assume credentials are stored as secrets named `DOCKER_USERNAME` and `DOCKER_PASSWORD`).\n\nWrite a basic `.github/workflows/deploy.yml` file that accomplishes this. Include steps for checkout, login to Docker Hub, build, tag, and push. (No need for testing or deployment steps\u2014just the image build/push.)\n\n*Expected time: 3-5 minutes. Bonus if you handle multi-platform builds or caching.*",
        "scores": {
          "relevance": 9,
          "clarity": 10,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core DevOps automation skills (CI pipelines, Docker, GitHub Actions) for entry-level role; minor deduction as Docker Hub isn't explicitly listed but fits deployment scripting (-1). Clarity: Crystal clear with precise scope, secrets, steps, and time estimate; no ambiguity. Discriminative: Requires writing functional YAML with applied knowledge of GitHub Actions/Docker; separates candidates who can implement from those who can't; bonus adds depth without requiring it.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-429",
        "role_title": "Backend Engineer - Log Aggregation",
        "question": "**Question:**  \nYou're building a log aggregation pipeline in Go that processes millions of events per second using Kafka as the input source and ClickHouse for storage. Vector is used for parsing and enriching logs before they're written to ClickHouse.  \n\nDescribe a practical approach to implement efficient schema-on-read parsing for semi-structured JSON logs (e.g., varying fields like `user_id`, `error_code`) in this stack. What key configurations in Vector and ClickHouse would you use to handle high throughput and ensure query performance, and why?  \n\n*(Expected answer: 2-4 sentences on Vector's `remap` or `parse_json` transforms for dynamic parsing, ClickHouse's dynamic JSON columns or materialized views for schema flexibility, partitioning by timestamp for retention/pruning, and why they scale for high TPS.)*",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's log aggregation focus, explicitly names Go/Kafka/Vector/ClickHouse for millions EPS parsing/enrichment/retention (no red flags). Clarity: Crystal clear, well-scoped to schema-on-read with expected depth via configs/why; minor deduction for lacking explicit time constraint. Discriminative: Tests applied deep knowledge of stack configs, trade-offs for scale/performance, distinguishes strong candidates able to reason about high-throughput choices.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-431",
        "role_title": "Staff Engineer - Real-time Collaboration",
        "question": "**Question:**  \nYou're designing a real-time collaborative text editor using WebSockets and CRDTs (e.g., Yjs). A user applies a deletion that overlaps with an insertion from another user due to network latency. Walk me through how a CRDT like a Yjs Array resolves this conflict, and what strategy you'd use to ensure the final document state is intuitive for users (e.g., cursor positioning or undo behavior). Include a brief TypeScript pseudocode snippet for the client-side merge if relevant.",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 10,
          "reasoning": "Directly tests core role skills in real-time collaboration, conflict resolution, and operational transforms via CRDTs (Yjs), matching 'architect real-time collaboration infrastructure'. Crystal clear, well-scoped with specific scenario and asks for explanation + strategy + code. Strongly differentiates via trade-offs, intuition, and applied CRDT knowledge; minor scope ambiguity on pseudocode prevents perfect clarity score.",
          "composite": 9.666666666666666
        }
      },
      {
        "role_id": "be-432",
        "role_title": "Backend Engineer - Data Validation",
        "question": "**Question:**\n\nIn a Python-based data pipeline using Great Expectations and Airflow, you've noticed intermittent data quality failures where incoming CSV files from S3 have unexpected null values in a critical 'customer_id' column (expecting <1% nulls, but seeing 5-10%). Describe a practical 3-step approach you'd take to diagnose and resolve this using Great Expectations, including one specific Expectation you'd implement and how you'd integrate it into Airflow. (Keep your answer concise, ~200 words max.)",
        "scores": {
          "relevance": 9,
          "clarity": 10,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core data validation, schema checks (nulls), and pipeline integration with exact tech stack (Great Expectations, Airflow, Python, S3) from role; minor -1 for not explicitly mentioning lineage/stats. Clarity: Crystal clear scenario, precise 3-step structure, specific expectation required, word limit scopes perfectly. Discriminative: Forces practical diagnosis (trade-offs in root cause), implementation details, and Airflow integration, separating those with hands-on experience from theorists.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-437",
        "role_title": "Senior Backend Engineer - Secrets Management",
        "question": "**Question:**  \nIn a Go service running on Kubernetes that uses HashiCorp Vault for dynamic secrets (e.g., PostgreSQL credentials), describe a practical approach to automatically rotate those secrets every 24 hours. Include how you'd handle updating the database connection in your service without downtime, and touch on audit logging the rotation events. What challenges might arise with AWS KMS integration for encryption-at-rest?",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (secrets rotation, Vault, access/audit) with Go/K8s specifics (-1 for minor unmentioned tech like AWS KMS). Clarity: Well-scoped, unambiguous, single focused scenario. Discriminative: Requires applied knowledge of integration, zero-downtime, trade-offs, and challenges for strong separation.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-434",
        "role_title": "Principal Engineer - Database Strategy",
        "question": "**Question:**  \nYou're leading the database strategy for a new multi-region application using PostgreSQL as the primary database, with CockroachDB as a potential future option for stronger distribution. Kafka is used for event streaming, and Redis for caching. Briefly walk us through your approach to designing a resilient read path that supports low-latency global reads (e.g., <100ms p99), including key trade-offs in replication, caching, and failover\u2014assuming Kubernetes orchestration across 3 regions. What metrics would you prioritize for ongoing optimization?",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 10,
          "reasoning": "Relevance: Directly tests core role responsibilities (multi-region DB strategy, tech selection like PostgreSQL/CockroachDB) with exact stack mentioned; no red flags (-0). Clarity: Crystal clear, well-scoped with specifics (e.g., <100ms p99, 3 regions, Kubernetes), requests brief approach with trade-offs; no red flags (-0). Discriminative: Excellent at probing deep applied knowledge, trade-offs (replication/caching/failover), and metrics\u2014strong separation of strong vs weak candidates; no red flags (-0).",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-438",
        "role_title": "Staff Engineer - ML Serving Infrastructure",
        "question": "**Question:**  \nYou're designing an ML serving system using Triton Inference Server on Kubernetes for real-time inference with strict p99 latency targets (<50ms). Describe your approach to implementing dynamic batching, including key configuration parameters you'd tune in Triton's model config, how you'd monitor its effectiveness with Prometheus, and one potential pitfall you'd mitigate for variable request rates.",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core role skills (ML serving, batching, latency optimization) with exact tech (Triton on K8s). Clarity: Precise, well-scoped, no ambiguity or bundling issues. Discriminative: Requires applied knowledge of configs, monitoring, trade-offs/pitfalls, strongly separates experts. Minor clarity ding for unspecified exact config fields expected.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-435",
        "role_title": "Junior Backend Engineer - Queue Consumers",
        "question": "**Question:**  \nYou're building a Python RabbitMQ consumer that processes order updates from a queue and saves them to PostgreSQL. The consumer might crash mid-processing, so you need to ensure no data loss or duplicates.  \n\nExplain in 3-5 sentences:  \n1. How would you make the consumer **idempotent** (safe to retry)?  \n2. When would you send a **basic_ack** vs. **basic_nack**?  \n3. What is a **dead letter exchange**, and why use it here?  \n\n*(Expect: Unique constraint or version check for idempotency; ack on success/nack on failure; DLX for retries/poison messages.)*",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's focus on message queue consumers, ack patterns, dead letter handling, and idempotency using exact tech (Python, RabbitMQ, PostgreSQL); no red flags. Clarity: Crystal clear, well-scoped to 3-5 sentences with numbered parts and expected answers; minor -2 for multiple questions bundled. Discriminative: Tests applied knowledge and trade-offs distinguishing strong candidates able to explain RabbitMQ specifics; not pure recall.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-439",
        "role_title": "Backend Engineer - Billing Integration",
        "question": "**Question:**\n\nYou're integrating Stripe subscriptions into a Python-based billing system using PostgreSQL. A customer wants to upgrade from a $10/month plan to a $20/month plan mid-cycle (on day 10 of their billing period), with proration enabled.\n\nWalk me through how you'd implement this upgrade using the Stripe Python SDK, including:\n1. The key Stripe API call and its essential parameters.\n2. How you'd handle proration credits/debits in your database (e.g., updating the `subscriptions` table).\n3. Any Celery/Redis considerations for async invoicing.\n\n(Feel free to sketch pseudocode or key steps.)",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core billing integration skills (Stripe subscriptions, proration) and tech stack (Python SDK, PostgreSQL, Celery/Redis) from role; minor ding for assuming Celery/Redis not explicitly listed (-1). Clarity: Crystal clear, well-scoped with specific scenario and numbered points; allows pseudocode flexibility. Discriminative: Requires applied knowledge of Stripe API, DB handling, and async patterns with trade-offs, strongly separates capable integrators from juniors.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-436",
        "role_title": "Backend Engineer - API Documentation",
        "question": "**Question:**  \nYou're building an OpenAPI spec for a Node.js/Express API endpoint that retrieves a user's order history from PostgreSQL. The endpoint is `GET /v1/users/{userId}/orders` and returns a paginated list of orders with fields like `id`, `status`, `total`, and `createdAt`.\n\nProvide a concise OpenAPI 3.0 YAML snippet for this endpoint, including:  \n- Path parameters  \n- Query parameters for pagination (`limit` max 50, `offset`)  \n- A sample 200 response with 2 example orders  \n- One error response (e.g., 404 user not found)  \n\n(Expected: ~15-20 lines of YAML. Focus on schema structure and best practices like `$ref` reuse.)",
        "scores": {
          "relevance": 9,
          "clarity": 10,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests OpenAPI spec generation (core to role's API documentation tooling), uses Node.js context and PostgreSQL implicitly via fields; minor ding as Express/PostgreSQL are contextual not deeply tested (-1). Clarity: Crystal clear with precise requirements, scope (~15-20 lines), and best practices guidance. Discriminative: Requires applied YAML authoring, schema design, $ref usage, and error handling; distinguishes those who can produce structured specs from trivia knowers.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-444",
        "role_title": "Backend Engineer - Service Templates",
        "question": "**Question:**  \nYou're setting up a Cookiecutter template for a new Go microservice that will deploy to Kubernetes via ArgoCD. Walk me through 3-5 key best practices you'd include in the template for security defaults and observability, and briefly explain how you'd implement one of them using Go code or configuration (e.g., in a `main.go` or YAML file).",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (scaffolding templates, security defaults, observability) with exact tech (Cookiecutter, Go, Kubernetes/ArgoCD); minor ding for not mentioning CI/CD. Clarity: Crystal clear, well-scoped (3-5 practices, one implementation example), specifies formats. Discriminative: Requires applied knowledge of best practices with code/config explanation, tests trade-offs and depth, strong separation.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-441",
        "role_title": "Senior Backend Engineer - Autocomplete Systems",
        "question": "**Question:**  \nYou're building an autocomplete system using Elasticsearch that handles prefix matching for search queries at 100K QPS with sub-50ms latency. A user types \"san\" and expects personalized results (e.g., \"San Francisco\" prioritized if they've searched it recently).  \n\nDescribe a concise architecture using your tech stack (Java, Elasticsearch, Redis, Kafka, PostgreSQL) to support prefix matching + personalization. What key optimizations would you apply in Elasticsearch for low latency, and how would you integrate personalization without exceeding the latency budget? (Focus on 2-3 critical decisions.)",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core autocomplete/prefix matching, personalization, and latency/QPS from role; uses exact tech stack (-1 for generic phrasing but still excellent). Clarity: Crystal clear, well-scoped to 2-3 decisions with precise constraints. Discriminative: Requires applied knowledge of trade-offs (latency optimizations, personalization integration), distinguishes strong architects from weak ones.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-443",
        "role_title": "Senior Backend Engineer - Data Lake Architecture",
        "question": "**Question:**  \nIn Apache Iceberg, describe a practical scenario from your experience where schema evolution was necessary in a production data lake (e.g., adding a new column or changing a data type). How did you handle it using Spark or Trino to ensure zero-downtime queries, and what role did features like partition pruning or metadata tables play?",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Directly tests core role skills (Iceberg schema evolution in data lakes) with relevant tech (Spark/Trino); clear, well-scoped scenario with expected depth; strong separation via practical experience, trade-offs, and feature application (no major red flags). Minor deduct for assuming personal experience but highly discriminative.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-440",
        "role_title": "Junior Backend Engineer - Metrics Collection",
        "question": "**Question:**  \nIn Go, using the Prometheus client library, write a short code snippet (5-10 lines) to create and increment a counter metric named `http_requests_total` that tracks the number of incoming HTTP requests, labeled by HTTP method (e.g., GET, POST). Explain briefly (1-2 sentences) why you'd choose a counter over a gauge for this use case.\n\n*(Expected answer: Import `github.com/prometheus/client_golang/prometheus` and `prometheus/promhttp`. Register a `prometheus.NewCounterVec(prometheus.CounterOpts{Name: \"http_requests_total\"}, []string{\"method\"})`. Increment in handler: `c.WithLabelValues(r.Method).Inc()`. Counter because it only monotonically increases, ideal for counting events like requests, unlike gauges which can go up/down.)*",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's focus on metrics instrumentation (counter pattern) with exact tech stack (Prometheus in Go, core to job). Clarity: Crystal clear with line limit, specific labels, and follow-up explanation; minor deduction as import details slightly underspecified but expected answer clarifies. Discriminative: Requires applied coding + trade-off reasoning on counter vs gauge, strongly separates candidates who understand metrics patterns from those who don't.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-446",
        "role_title": "Staff Engineer - Distributed Tracing",
        "question": "**Question:**  \nYou're designing a distributed tracing system for a high-throughput service mesh using OpenTelemetry and Jaeger as the backend. Traffic volumes mean you can't store 100% of traces without overwhelming storage costs. Walk me through your approach to implementing an effective sampling strategy\u2014what factors would you consider, how would you balance trace completeness with resource constraints, and how might you configure it in OpenTelemetry (e.g., head/tail sampling)?",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 10,
          "reasoning": "Directly targets core role responsibility of designing sampling strategies for distributed tracing at scale, using exact tech (OpenTelemetry/Jaeger). Crystal clear with specific scope, prompts trade-offs and config details for strong candidate separation. Minor clarity ding for not specifying answer format/depth, but well-scoped overall.",
          "composite": 9.666666666666666
        }
      },
      {
        "role_id": "be-445",
        "role_title": "Junior Backend Engineer - Database Migrations",
        "question": "**Question:**  \nYou're using Alembic to manage database migrations with SQLAlchemy and PostgreSQL. A recent migration added a non-nullable `email` column to the `users` table without a default value, and it failed because the table already has rows.\n\nExplain in 2-3 steps how you would fix this with a new Alembic migration revision, ensuring it runs safely on a production database with existing data. (No need to write full code, just the high-level approach.)",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests Alembic migrations (core to role), zero-downtime/rollback safety on PostgreSQL/SQLAlchemy; minor deduction as role is entry-level but question fits learning focus (-1). Clarity: Crystal clear, scoped to 2-3 high-level steps, production-safe constraints explicit. Discriminative: Requires applied knowledge of safe schema changes (add nullable first, backfill, constrain), distinguishes those understanding production pitfalls from rote memorizers.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-442",
        "role_title": "Backend Engineer - Event Streaming",
        "question": "**Question:**  \nIn our event streaming system built with Rust and NATS, we use fan-out patterns to broadcast real-time updates to thousands of connected clients via WebSocket. Describe a practical approach you'd take in Rust to efficiently filter and fan-out high-volume events (e.g., 10k+ events/sec) from a NATS JetStream subject to specific subsets of subscribers based on user preferences (like topic or region). Include key considerations for performance and reliability, such as handling backpressure or replays.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (event streaming, fan-out, filtering, replay) with exact tech stack (Rust, NATS); minor deduction as JetStream/WebSocket not explicitly listed (-1). Clarity: Well-scoped, unambiguous, specifies tech/context/volume; no red flags. Discriminative: Requires applied knowledge of Rust/NATS patterns, trade-offs (backpressure, replays), distinguishes strong performers handling high-volume streaming.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-449",
        "role_title": "Junior Backend Engineer - Auth Integration",
        "question": "**Question:**\n\nIn a Node.js/Express app using TypeScript, you're adding Google OAuth2 login. The user authorizes via Google, and your callback receives an `access_token` and `refresh_token`. \n\nWrite a simple function (5-10 lines) that:\n- Stores the `refresh_token` securely in PostgreSQL (assume a `user_tokens` table with `user_id` and `refresh_token` columns).\n- Returns a short-lived JWT for your app's session.\n\nInclude basic error handling and explain one security risk if the refresh_token is stored in plaintext. \n\n*(Expect code snippet + 1-sentence explanation)*",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Directly tests core OAuth token handling, refresh storage, and JWT issuance for entry-level role with Node.js/TS stack; crystal clear scope (5-10 lines), well-constrained; strong separation via secure storage implementation, error handling, and security trade-off insight without being trivial or overly broad.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-433",
        "role_title": "Senior Backend Engineer - Platform APIs",
        "question": "**Question:**  \nYou're designing a gRPC-based internal platform API in Go for a service catalog that allows developers to query and provision resources (e.g., databases). Walk me through how you'd structure the protobuf schema for a `ListServices` RPC, including key fields for service metadata, and explain how you'd implement server-side pagination using PostgreSQL as the backend. What trade-offs would you consider for performance at scale with Kubernetes deployments?",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 10,
          "reasoning": "Relevance: Directly tests core role skills (API design, service catalog, provisioning) with exact tech stack (gRPC, Go, PostgreSQL implied, Kubernetes); minor deduction as Go is inferred not explicit (-1). Clarity: Crystal clear, well-scoped with specific RPC, pagination, and trade-offs; no bundling or vagueness. Discriminative: Excellent at separating candidates via schema design, SQL pagination implementation, and scale trade-offs (e.g., cursor vs offset, sharding, K8s autoscaling).",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-448",
        "role_title": "Senior Backend Engineer - Webhook Infrastructure",
        "question": "**Question:**  \nIn Go, design a simple retry mechanism for delivering a webhook payload to an endpoint that might fail (e.g., 5xx errors). Include exponential backoff with jitter, a maximum of 5 retries, and a dead letter queue fallback after failure. Provide pseudocode or a concise code snippet (no full implementation needed), and explain one key challenge in ensuring at-least-once delivery guarantees with this setup.\n\n*(Expected answer: ~2-4 min to sketch code + explain idempotency or duplicate handling challenges)*",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests Go implementation of core webhook retry logic (exponential backoff, DLQ), matching role's guaranteed delivery focus (-1 for assuming Go if not explicitly listed). Clarity: Crystal clear scope, constraints specified, expected format/depth guided. Discriminative: Requires applied coding + trade-off explanation (idempotency challenges), strong separation of strong vs weak candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-450",
        "role_title": "Principal Engineer - ML Platform Strategy",
        "question": "**Question:**  \nYou're leading the adoption of an ML platform across our organization, which currently uses a mix of MLflow for experiment tracking, Kubeflow on Kubernetes for pipelines, and Ray for distributed training. Teams are facing challenges with governance, such as inconsistent model versioning, lack of reproducibility in production, and siloed tooling decisions.  \n\nIn 2-5 minutes, walk us through your high-level strategy for a unified ML platform: What key principles would guide your tooling selection and architecture? How would you address governance (e.g., model registry, access controls)? And what steps would you take for team enablement?",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role responsibilities (ML platform strategy, tooling, governance, enablement) with exact tech stack from description; no red flags. Clarity: Crystal clear, well-scoped with time limit and specific subtopics; minor -1 for bundled elements but highly structured. Discriminative: Probes high-level strategy, trade-offs, and practical application, strongly separating experienced leaders from juniors; time-bound for screening.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-453",
        "role_title": "Backend Engineer - Notification Delivery",
        "question": "**Question:**  \nIn our Go-based notification system, we use Redis for queuing notifications and PostgreSQL for tracking delivery status. Describe a simple approach you'd take to implement idempotent delivery for push notifications (e.g., via FCM/APNS), ensuring a retry due to a transient network error doesn't duplicate the delivery. Include key code snippets or pseudocode in Go, and mention any relevant Redis or DB operations. (2-3 sentences + code is fine.)",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Directly tests core role skills (push delivery, idempotency, retry handling) using exact tech stack (Go, Redis, PostgreSQL); crystal clear with scoped response format and no ambiguity; strong separation via applied knowledge of trade-offs in retries/idempotency with code, not mere recall.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-452",
        "role_title": "Senior Backend Engineer - Faceted Search",
        "question": "**Question:**  \nIn Elasticsearch, you're implementing faceted search for an e-commerce catalog with millions of products. Users want to filter by category (e.g., \"electronics > phones\") and brand, while seeing accurate facet counts for other attributes like price range and color *after* the filters are applied.  \n\nExplain how you'd structure the search query using aggregations and filters to ensure facet counts are precise (not inflated by unfiltered docs), and what pitfalls you'd avoid at scale. Include a high-level query sketch in JSON.  \n\n*(Expected answer: Use `bool` filter context for category/brand, nested `terms` or `range` aggs in a filtered `POST_FILTER` or composite aggs; avoid global bucket selectors for accuracy; watch for shard_size on high-cardinality fields.)*",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's faceted search, dynamic filtering, aggregation optimization, and scale requirements in Elasticsearch\u2014no red flags. Clarity: Crystal clear with specific scenario, expected structure, and scope; minor deduction for not specifying time limit. Discriminative: Tests deep applied knowledge of query structure, pitfalls, trade-offs (e.g., POST_FILTER vs composite), and scale issues\u2014strong separation, not mere recall.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-447",
        "role_title": "Backend Engineer - Load Shedding",
        "question": "**Question:**  \nYou're implementing load shedding in a Go service running in Kubernetes, using Envoy as a sidecar proxy and Redis for priority queues. Under high load, you need to gracefully degrade by dropping low-priority requests while preserving critical ones.  \n\nDescribe a simple mechanism you'd use to detect overload (e.g., via Prometheus metrics) and signal Envoy to throttle traffic. Include 2-3 key Go code snippets for:  \n1. Querying a Prometheus metric for overload detection.  \n2. Enqueueing a request to a Redis priority queue.  \n3. Sending a backpressure signal (e.g., via HTTP endpoint).  \n\n*(Expect 2-5 min verbal explanation with pseudocode; probe for adaptive throttling details.)*",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (load shedding, priority queues, throttling, backpressure) with exact tech (Go, Redis, Kubernetes/Envoy, Prometheus); minor ding for assuming Envoy not explicitly listed (-1). Clarity: Precise scope, clear tasks with examples, time-bound, well-formed for screening. Discriminative: Requires applied knowledge across integration points, code snippets, and trade-offs (e.g., adaptive throttling probe), strongly separates candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-454",
        "role_title": "Junior Backend Engineer - ETL Scripts",
        "question": "**Question:**\n\nYou're writing a Python ETL script using pandas to load sales data from a CSV file into a PostgreSQL table. The CSV has 100k rows with a 'sale_date' column in string format '2023-12-01'. \n\nWrite a short code snippet (5-10 lines) that:\n1. Reads the CSV into a pandas DataFrame\n2. Converts 'sale_date' to a proper datetime\n3. Handles any invalid dates by setting them to null\n4. Writes the cleaned data to PostgreSQL table 'sales' (assume connection string `engine = create_engine('postgresql://user:pass@localhost/db')`)\n\n```python\n# Your code here\n```",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core ETL skills (pandas data loading/cleaning, datetime handling, PostgreSQL write) for entry-level ETL role; minor ding for assuming engine creation. Clarity: Precise scope (5-10 lines), clear steps, all constraints provided. Discriminative: Requires applied pandas/SQLAlchemy knowledge with error handling, distinguishes those who can write functional ETL code from trivia knowers.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-455",
        "role_title": "Staff Engineer - Developer Portal",
        "question": "**Question:**  \nIn Backstage, imagine you're designing a plugin architecture for a developer portal where teams can onboard their own services to the service catalog. Walk us through how you would structure a custom plugin (e.g., for service onboarding) using TypeScript and React, including key Backstage APIs you'd use for entity registration, UI integration, and backend proxying to PostgreSQL. What trade-offs would you consider for scalability across multiple teams?  \n\n*(Expected response: 2-5 min verbal or written; tests practical Backstage plugin dev, DX focus, and staff-level architecture thinking.)*",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Directly tests core Backstage plugin architecture, TypeScript/React, service onboarding, and scalability\u2014perfectly matches role's developer portal and plugin focus. Crystal clear with specific APIs, scoped to 2-5 min, prompts trade-offs for deep thinking. Minor ding for assuming Backstage (implied but not explicit in role), but exceptional otherwise.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-456",
        "role_title": "Backend Engineer - Query Optimization",
        "question": "**Question:**  \nYou're analyzing a slow PostgreSQL query using `EXPLAIN ANALYZE` that shows a sequential scan on a large table (`users`) with a `WHERE` clause filtering on `email` (a text column) and `status` (a varchar column). The query processes 1M rows but only returns 100 matches.  \n\n1. What index(es) would you recommend adding, and why?  \n2. How would you verify if it improves performance?  \n\n*(Expect: Composite index on `(status, email)` or partial index; re-run `EXPLAIN ANALYZE` with `BUFFERS` for I/O metrics.)*",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills in slow query detection, index recommendations, and plan analysis using PostgreSQL, perfectly matching the role. No red flags. Clarity: Crystal clear scenario with specific details; minor deduction for bundled sub-questions (-1, but still well-scoped). Discriminative: Requires applied knowledge of index selection (trade-offs like composite vs partial), verification methods, and deep EXPLAIN ANALYZE understanding; expected answer shows strong separation. Minor deduction as it guides toward specifics slightly.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-451",
        "role_title": "Backend Engineer - Subscription Billing",
        "question": "**Question:**  \nIn a subscription billing system using Java/Spring Boot and PostgreSQL, how would you implement usage metering for a feature like API calls, where customers are charged based on monthly overages beyond their plan limit (e.g., $0.01 per extra 1,000 calls)? Walk through the key components, including how you'd track usage, handle plan changes with proration, and ensure accuracy under high load with Kafka and Redis.\n\n*(Expected answer outline: Async Kafka events for usage capture \u2192 Redis for real-time counting/incrementing \u2192 Periodic PostgreSQL aggregation/billing \u2192 Proration calc via (days remaining / total days) * overage cost on plan change.)*",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core subscription billing skills (usage metering, plan changes, proration) with exact tech stack from role; minor ding for Kafka/Redis not explicitly in desc (-1). Clarity: Crystal clear, well-scoped with specific scenario, expected depth implied. Discriminative: Requires applied knowledge of architecture trade-offs (async, real-time vs batch, high load), distinguishes strong candidates who can outline full system.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-457",
        "role_title": "Senior Backend Engineer - SLO Automation",
        "question": "**Question:**  \nIn Go, implement a simple function that calculates the current SLO burn rate for a service over the last 30 days, given a target SLO of 99.9% availability and a Prometheus query result providing the total valid requests and error count over that window. Explain your alerting threshold logic for error budget depletion (e.g., at what burn rate would you trigger an escalation?). Provide code and a brief rationale.\n\n*(Expected: ~10-15 lines of Go code using slices/maps for metrics, basic math for burn rate = (error_rate / target_rate), and threshold like >1.5x for 7-day projection.)*",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests Go (core for infra) and SLO burn rate calculation/error budget tracking, matching role's focus; minor ding for not specifying exact Prometheus format (-1). Clarity: Well-scoped with inputs, expected output, line count, and example formula; no bundling or ambiguity. Discriminative: Requires applied Go coding, math, and threshold trade-offs/projections, strongly separating candidates able to implement vs. theorize.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-458",
        "role_title": "Backend Engineer - API Gateway Plugins",
        "question": "**Question:**  \nIn Kong, you're developing a custom Lua plugin to implement JWT authentication for an API route. The plugin should validate the JWT from the `Authorization` header, extract the `user_id` claim, and add it as a header (`X-User-ID`) to upstream requests if valid (reject with 401 otherwise).  \n\nWrite a concise Lua code snippet for the `access` phase of the plugin schema that accomplishes this. Assume `kong.service.load_jwt` and standard Kong helpers are available, and use Redis (via `kong.client.redis`) as a token blacklist for revoked JWTs. Include basic error handling.  \n\n*(Expected: ~20-40 lines of Lua demonstrating Kong plugin structure, JWT parsing, Redis interaction, and request modification.)*",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Directly tests core Kong Lua plugin development for API gateway auth/transformation per role. Crystal clear scope, constraints, and expectations; no ambiguity or bundling. Strong separation via applied Lua coding with JWT/Redis integration, error handling, and Kong-specific APIs\u2014not mere recall.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-461",
        "role_title": "Senior Backend Engineer - Fraud Detection",
        "question": "**Question:**  \nYou're building a real-time fraud detection pipeline using Kafka for event streaming, Redis for caching, and PostgreSQL for persistent storage. Describe how you'd architect a rule engine that evaluates payment transactions (e.g., velocity checks, IP blacklists) against incoming Kafka events, caches hot rules in Redis for sub-ms lookups, and flags suspicious ones for manual review. What trade-offs would you consider for latency vs. accuracy, and how would you handle rule updates without downtime?",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 10,
          "reasoning": "Relevance: Directly tests core fraud detection pipeline skills (rule engines, real-time scoring) with relevant tech (streaming, caching, storage); minor ding for assuming specific tools not listed (-1). Clarity: Crystal clear, well-scoped architecture with specific components and constraints. Discriminative: Excellent at separating candidates via applied architecture, trade-offs (latency/accuracy), and operational concerns (downtime), requiring deep understanding.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-460",
        "role_title": "Backend Engineer - Experiment Tracking",
        "question": "**Question:**  \nIn MLflow, you've just logged several runs for different hyperparameter combinations in an experiment, including metrics like accuracy and F1-score, plus model artifacts stored to S3. Walk me through the Python code (or steps) you'd use to query these runs from PostgreSQL, compare the top 3 models by F1-score, and generate a basic comparison table or visualization. What key MLflow functions would you rely on?",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests MLflow for experiment tracking, metric comparison, and artifact handling (core to role); minor ding for assuming S3/PostgreSQL not explicitly listed (-1). Clarity: Well-scoped with specific scenario, clear steps expected, no ambiguity. Discriminative: Requires applied MLflow knowledge (querying, filtering, comparing), trade-offs in top-k selection, distinguishes practical users from theorists.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-459",
        "role_title": "Junior Backend Engineer - Container Security",
        "question": "**Question:**\n\nYou're setting up Trivy to scan a Docker image for vulnerabilities in a CI/CD pipeline. The image is `nginx:1.21-alpine`. Walk me through the exact Trivy command you'd use to scan it (including any key flags you'd add for a junior-level setup), and explain what the output tells you about HIGH or CRITICAL vulnerabilities. What would you do next if Trivy reports a CRITICAL vulnerability in the base image? \n\n*(Expected answer time: 2-4 minutes; tests practical Trivy/Docker usage, vulnerability prioritization, and basic remediation thinking.)*",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 8,
          "reasoning": "Relevance: Directly tests core container scanning skills (Trivy/Docker) central to role (-1 for minor focus on specific image/version not broadly required). Clarity: Precise command request, clear output explanation, and next steps; well-scoped with time hint. Discriminative: Tests practical command knowledge, interpretation, and reasoning over rote recall, separating those with hands-on experience.",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-462",
        "role_title": "Backend Engineer - Alert Routing",
        "question": "**Question:**  \nIn Alertmanager, you've received a stream of alerts for a critical service outage across multiple instances (e.g., pod1, pod2, pod3). Describe how you would configure a grouping rule using Go templates to intelligently group these into a single notification. Include the key `group_by`, `group_wait`, `group_interval`, and `repeat_interval` settings you'd use, and explain why they'd work well for this scenario in a production PagerDuty integration.\n\n*(Expected answer: Group by `['alertname', 'cluster', 'service']` to consolidate instances; `group_wait: 30s` to buffer; `group_interval: 5m` for ongoing grouping; `repeat_interval: 1h` to avoid spam. Tests practical Alertmanager config for dedup/routing.)*",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core alert grouping, deduplication, and routing skills for the role (-1 for assuming Alertmanager not explicitly listed). Clarity: Crystal clear, well-scoped with specific parameters and scenario. Discriminative: Requires applied config knowledge, trade-offs in timings, and Go template reasoning, strongly separates practical experts from theorists.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-463",
        "role_title": "Junior Backend Engineer - Full-text Search",
        "question": "**Question:**\n\nYou're building a FastAPI endpoint to search blog posts stored in PostgreSQL using full-text search. The `posts` table has a `content` column (text). \n\nWrite a simple SQL query to:\n1. Create a GIN index on the `content` column for full-text search.\n2. Search for posts containing \"machine learning\" (considering word variations), rank them by relevance, and return the top 3 results with title and a relevance score.\n\nProvide the SQL and a brief explanation of `tsvector` and `ts_rank` used here. (No need for full FastAPI code.)",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's PostgreSQL full-text search focus (tsvector, ranking, optimization); no red flags. Clarity: Crystal clear with precise scope, minor deduction for lacking exact tsquery syntax example. Discriminative: Tests applied SQL knowledge, indexing, ranking trade-offs, and explanation of core concepts, strongly separates candidates familiar with role tech.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-464",
        "role_title": "Staff Engineer - Presence Systems",
        "question": "**Question:**  \nYou're designing a presence system for a chat app using Go and WebSockets, handling 1M+ concurrent users. Walk me through how you'd implement a heartbeat protocol to detect and gracefully handle client disconnections (e.g., due to network issues), including key Go code snippets for the server-side logic, what timeout values you'd choose and why, and how you'd synchronize the user's presence state across connected devices using Redis.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 10,
          "reasoning": "Directly tests core role skills (presence, heartbeats, connection management, state sync) with exact tech (WebSockets, Redis); assumes Go fits scale/architecture focus. Crystal clear with precise scope (heartbeats, timeouts, sync, code snippets). Excellent separation via trade-offs (timeout choices), applied design, and code depth; well-constrained for screening.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-465",
        "role_title": "Backend Engineer - CDC Pipelines",
        "question": "**Question:**  \nIn a CDC pipeline using Debezium to capture changes from PostgreSQL and stream them to Kafka for replication into Snowflake, describe how you would configure Debezium to handle an initial snapshot of existing data (e.g., for a new table) while ensuring exactly-once delivery semantics end-to-end. What key Debezium connector configs or Kafka settings would you use, and why?",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core CDC pipeline skills (Debezium, PostgreSQL, Kafka, Snowflake replication, snapshots, exactly-once), matching role focus; minor deduction as Snowflake config not deeply probed (-1). Clarity: Precise, well-scoped to configs/reasons, no ambiguity or bundling. Discriminative: Requires applied knowledge of Debezium configs (snapshot.mode, etc.), Kafka semantics (transactions), and trade-offs for end-to-end guarantees, strongly separating experts.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-467",
        "role_title": "Backend Engineer - Connection Pooling",
        "question": "**Question:**\n\nYou're setting up PgBouncer as a connection pooler in front of a PostgreSQL cluster running on Kubernetes, using Go services. Your Go app is experiencing high connection latency during traffic spikes. Walk me through how you'd configure PgBouncer's `pool_mode`, `max_client_conn`, and `default_pool_size` to optimize for scaling, and explain one key trade-off you'd consider when choosing between transaction vs. session mode.",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (pool sizing, transaction modes) with PgBouncer/PostgreSQL, highly specific to connection pooling/scaling; minor ding as Kubernetes/Go are contextual but not core (-1). Clarity: Crystal clear, well-scoped parameters, single focused explanation request. Discriminative: Requires applied config knowledge and trade-off reasoning, strongly separates candidates with practical depth.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-468",
        "role_title": "Junior Backend Engineer - CI Pipelines",
        "question": "**Question:**  \nYou're setting up a GitHub Actions workflow in YAML to build and test a Python application using Docker. The workflow runs `pip install -r requirements.txt` on every push, which takes 2 minutes due to dependency downloads.  \n\nWrite a simple YAML job snippet that uses Docker and implements **caching** to speed up the `pip install` step. Explain briefly (1-2 sentences) why your caching strategy works.  \n\n*(Expected: Use `actions/cache` or Docker layer caching with a key based on `requirements.txt` hash.)*",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Directly tests core caching strategies for GitHub Actions CI pipelines with Python/Docker, matching role focus perfectly (-0 red flags). Crystal clear with specific scenario, expected approach hinted, and scoped to a simple snippet (+ explanation). Requires applied YAML knowledge and understanding of cache keys/hash trade-offs, distinguishing those who can implement vs recite basics.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-471",
        "role_title": "Staff Engineer - Zero Trust Architecture",
        "question": "**Question:**  \nIn a microservices architecture running on Kubernetes, walk us through how you would implement automated mTLS between services using SPIFFE and Envoy. What key components would you configure (e.g., SPIRE agent, Envoy filters), and how would you handle workload identity attestation and short-lived certificate rotation?",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 10,
          "reasoning": "Relevance: Directly targets core role requirements (mTLS automation in microservices) with exact tech (Kubernetes, SPIFFE, Envoy); no red flags. Clarity: Precise, well-scoped walkthrough with specific components; minor deduction for no explicit time constraint. Discriminative: Requires deep applied knowledge of integration, trade-offs in attestation/rotation, strongly separates experts from superficial knowers.",
          "composite": 9.666666666666666
        }
      },
      {
        "role_id": "be-470",
        "role_title": "Backend Engineer - GraphQL Federation",
        "question": "**Question:**  \nIn Apollo Federation, explain how entity resolution works across subgraphs during a federated query. Walk through a simple example with two subgraphs (e.g., `User` service providing `@key(fields: \"id\")` and `Order` service resolving the `User` entity), including the key steps in query planning and execution. What happens if entity resolution fails in one subgraph?\n\n*(Expected answer: Covers reference resolution via `@key`, supergraph query planning with parallel subgraph calls, batching via `@requires` if needed, and error handling like partial resolution or fallback.)*",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's core focus on Apollo Federation, schema stitching, query planning, and entity resolution\u2014no red flags. Clarity: Crystal clear with specific example, well-scoped steps, and failure case; minor deduction for lacking explicit time/format constraints. Discriminative: Tests deep applied knowledge of mechanisms, trade-offs (batching, partial resolution), and error handling, strongly separating experts from surface-level knowers.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-473",
        "role_title": "Senior Backend Engineer - Refund Processing",
        "question": "**Question:**  \nIn a refund processing system using Java and Spring Boot, describe how you would implement partial refunds (e.g., refunding $15 out of a $20 charge) while ensuring ledger reconciliation remains balanced. Include key considerations for handling provider callbacks (e.g., success/failure) and maintaining an audit trail, mentioning relevant tech like PostgreSQL, Kafka, or Redis if applicable. (Answer in 3-5 sentences.)",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Directly tests core refund processing skills (partial refunds, ledger reconciliation, provider callbacks, audit trails) matching the role exactly, with specified tech stack (Java/Spring Boot) and optional relevant ones (PostgreSQL/Kafka/Redis); crystal clear with scoped response length, no bundling or ambiguity; strong separation via applied knowledge of trade-offs in balances/callbacks/audits, not mere recall, though slightly verbose for screening.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-469",
        "role_title": "Senior Backend Engineer - Chaos Engineering",
        "question": "**Question:**  \nIn Chaos Mesh on Kubernetes, you're designing a failure injection experiment to test a Go-based microservice's resilience to pod failures. The service uses a leader election pattern with etcd for state. Describe a Chaos Mesh workflow (including specific resources like Schedule and types of chaos actions) you'd create to inject targeted pod kills, control the blast radius to 20% of replicas, and validate automatic recovery within 60 seconds. What key Go code patterns or Kubernetes configurations would you check post-experiment to confirm resilience?",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests Chaos Mesh, Kubernetes, failure injection, blast radius control, and recovery validation\u2014core to role; minor ding for assuming Chaos Mesh despite etcd/Go focus (-1). Clarity: Precise, well-scoped with specific resources, percentages, and timelines; no bundling or ambiguity. Discriminative: Requires applied knowledge of Chaos Mesh workflows, integration with leader election/etcd, and post-experiment analysis of Go/K8s patterns for trade-offs and deep resilience understanding.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-477",
        "role_title": "Senior Backend Engineer - Data Catalog",
        "question": "**Question:**  \nYou've implemented a data pipeline using Apache Atlas for metadata management and Kafka for event streaming. Describe a practical approach to automatically extract and register lineage information (e.g., from Airflow DAGs processing data between PostgreSQL tables) into Atlas, including how you'd handle updates if a downstream transformation changes. What challenges might arise, and how would you address them?",
        "scores": {
          "relevance": 7,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Strongly tests core lineage tracking and metadata skills but assumes unlisted tools (Atlas, Kafka, Airflow) and ignores data profiling/governance (-2 red flag). Clarity: Crystal clear, well-scoped with specific example and update handling. Discriminative: Excellent at probing applied knowledge, trade-offs, and challenges for strong separation.",
          "composite": 8.333333333333334
        }
      },
      {
        "role_id": "be-474",
        "role_title": "Backend Engineer - Dashboards API",
        "question": "**Question:**  \nIn our observability platform's Go-based Dashboards API, we use Grafana dashboards with template variables (e.g., `$instance` or `$namespace`) that get substituted at runtime based on user context or query params. Briefly walk me through how you would implement a handler in Go to safely render and return a dashboard JSON payload with variable substitution, pulling variable values from a Redis cache (e.g., user-specific filters). Mention any key considerations for security, performance, or error handling.\n\n*(Expect 2-5 min verbal response; follow up on Grafana templating, Go json.Unmarshal/Marshal, Redis Get, injection risks.)*",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets Go APIs, Grafana templating, variable substitution, and Redis\u2014core to dashboard management role (-1 for no explicit role tech stack match but perfect conceptual fit). Clarity: Precise scope, unambiguous, well-scoped for 2-5 min response with clear expectations. Discriminative: Requires applied knowledge of Go handlers, JSON handling, Redis integration, and trade-offs in security (injection), performance (caching), error handling\u2014strong separation of strong vs weak candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-475",
        "role_title": "Junior Backend Engineer - Search Analytics",
        "question": "**Question:**  \nYou've been given access to Kibana dashboards showing search query logs from our Elasticsearch cluster. The logs include fields like `query_string`, `user_id`, `timestamp`, and `results_clicked`. A stakeholder notices that a popular query \"wireless headphones\" has high volume but low click-through rate on results.  \n\nIn 3-5 sentences, walk through how you'd use Kibana to investigate this issue. What visualizations or filters would you start with, and what might you check next (e.g., query variations, result rankings)?",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Directly tests core search analytics skills (query logging, click tracking, relevance metrics) using Elasticsearch/Kibana, matching the entry-level role's focus; crystal clear with specific fields, scenario, and scoped response length; strong separation via applied investigation process, filters/visualizations, and next steps requiring practical understanding over recall.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-472",
        "role_title": "Backend Engineer - Vector Search",
        "question": "**Question:**  \nYou're building a semantic search API using FastAPI, Pinecone for vector storage, and a model like Sentence Transformers for embeddings. Walk me through how you'd implement a hybrid search endpoint that combines vector similarity (from Pinecone) with a keyword filter (e.g., from PostgreSQL). Include key code snippets for the embedding generation, upsert/indexing flow, and the FastAPI query handler. What challenges might arise with high query volume, and how would you mitigate them using Redis?\n\n*(Expected answer: Candidate describes embedding text \u2192 Pinecone upsert \u2192 hybrid query with Pinecone's metadata/hybrid filter + Postgres full-text \u2192 Redis for caching embeddings/queries. ~3-5 min to outline with snippets.)*",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's vector search, embeddings, indexing, hybrid search with exact tech stack (FastAPI, Pinecone, embeddings); no red flags. Clarity: Crystal clear, well-scoped with specific components requested, minor deduction for lacking explicit time/format constraints. Discriminative: Tests applied architecture/design with trade-offs (high volume, Redis caching), strong separation via code snippets and reasoning; not trivial recall.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-476",
        "role_title": "Backend Engineer - Live Updates",
        "question": "**Question:**\n\nYou're building a live dashboard using Socket.io in Node.js/TypeScript with Redis for pub/sub. A client joins a \"room\" to receive updates for their specific dashboard (e.g., `room:user123`). \n\nExplain how you'd implement **selective broadcasting** so that when dashboard data for `user123` updates (triggered from a separate service via Redis), only clients in `room:user123` receive it\u2014and not other users' rooms. Include key Socket.io and Redis code snippets (pseudocode OK).\n\n*Follow-up (if time): How would you handle a client reconnecting and rejoining their room without missing updates?*",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (live updates, room management, selective broadcasting, Redis pub/sub) with exact tech stack; minor -1 for no explicit reconnection in role but it's implied. Clarity: Crystal clear, well-scoped with specific scenario, pseudocode OK, single focused question + optional follow-up. Discriminative: Requires applied knowledge of Socket.io rooms + Redis integration, trade-offs in reconnection (e.g. missed messages, state sync), strong separation of strong vs weak candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-484",
        "role_title": "Staff Engineer - Model Registry",
        "question": "**Question:**  \nYou're designing a model registry using MLflow to manage the ML lifecycle across multiple teams. Walk me through how you would implement a versioning strategy for models that supports immutable tags, rollback capabilities, and integration with S3 for storage and PostgreSQL for metadata. What key considerations would you have for governance, such as access controls and audit trails? (Feel free to sketch a high-level architecture or pseudocode if it helps.)",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Directly targets core role skills (model registry, versioning, governance) with MLflow, S3, PostgreSQL. Crystal clear scope for screening, tests applied architecture/design knowledge and trade-offs (immutability, rollback, access controls). Minor ding for no time constraint but well-scoped overall; strong separation of strong ML engineers.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-480",
        "role_title": "Junior Backend Engineer - Deployment Automation",
        "question": "**Question:**\n\nImagine you're deploying a Python Flask web app to an AWS EC2 instance using Ansible. Walk me through the key steps you'd include in an Ansible playbook to automate this deployment, including pulling code from a Git repo, installing dependencies, and restarting the service. What Ansible modules would you use for each major step, and why? (Feel free to sketch a simple playbook YAML snippet if it helps explain.)",
        "scores": {
          "relevance": 4,
          "clarity": 8,
          "discriminative": 7,
          "reasoning": "Relevance: Superficially mentions Ansible (relevant to configuration management) but focuses on generic Python/Flask/AWS deployment, not core entry-level skills like basic scripts, rollbacks, or environment setup; tests wrong domain depth (-3 generic, -2 not-listed AWS focus). Clarity: Clear intent and well-scoped, though optional YAML adds minor flexibility. Discriminative: Good applied knowledge of Ansible modules with 'why' for trade-offs, separates candidates who understand automation from memorizers.",
          "composite": 6.333333333333333
        }
      },
      {
        "role_id": "be-481",
        "role_title": "Backend Engineer - Canary Deployments",
        "question": "**Question:**  \nYou're implementing a canary deployment for a Go microservice using Istio and ArgoCD. Describe the key steps you'd take in Istio to shift 10% of production traffic to the canary version, monitor a custom Prometheus metric (e.g., `app_error_rate`) for comparison against the baseline, and automatically rollback if the canary's error rate exceeds 2x the baseline. Include relevant Istio resources and a high-level Go snippet for metric exposure if needed.\n\n*(Expected answer: Use VirtualService for weighted traffic splitting (e.g., 90/10), DestinationRule for canary subset, Prometheus for metric scraping, and Istio's `RequestAuthentication` or a controller for gates/rollback via ArgoCD Rollouts.)*",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role's canary deployment, traffic shifting, metrics, and rollback using exact tech (Istio/ArgoCD); no red flags. Clarity: Crystal clear with specific scenario and scope, minor deduction for not specifying response format. Discriminative: Tests deep applied knowledge of Istio resources, integration, monitoring, and automation trade-offs, strongly separates experts.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-482",
        "role_title": "Senior Backend Engineer - API Monetization",
        "question": "**Question:**  \nYou're building an API monetization platform in Go using Kong as the gateway, PostgreSQL for persistent storage, and Redis for caching. Describe how you would implement usage quota enforcement for a pricing tier that limits customers to 10,000 API calls per month. Walk through the key components (e.g., Kong plugin, Redis structure, DB schema), how you'd handle high-throughput request rate limiting, and a strategy for accurate monthly resets with minimal downtime. What edge cases like clock skew or overages would you address?",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 10,
          "reasoning": "Relevance: Perfectly matches role's core needs (usage tracking, quotas, pricing tiers) with specific tech stack; no red flags. Clarity: Crystal clear, well-scoped components and edge cases specified; minor deduction only for lacking explicit time constraint. Discriminative: Tests deep applied knowledge, trade-offs (high-throughput, resets, edge cases), strongly separates strong candidates.",
          "composite": 9.666666666666666
        }
      },
      {
        "role_id": "be-485",
        "role_title": "Junior Backend Engineer - Payment Webhooks",
        "question": "**Question:**  \nYou're building a FastAPI endpoint to receive payment webhooks from a provider like Stripe. The webhook payload contains a `payment_id`, `status` (e.g., \"succeeded\" or \"failed\"), and a signature for verification.  \n\n1. Write a simple FastAPI route to handle this POST request.  \n2. Briefly explain (1-2 sentences each):  \n   - How you'd verify the webhook signature (assume a `signature_header` and shared secret).  \n   - How you'd ensure idempotency if the same webhook is retried (e.g., using Redis and PostgreSQL).  \n\n*(Expect ~10-20 lines of code + short explanations; focus on practical steps, not full production code.)*",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Perfectly matches role (payment webhooks, signature verification, idempotency) with exact tech (FastAPI). Clarity: Crystal clear, well-scoped with line expectations, minor -1 for bundled subquestions. Discriminative: Tests practical coding + applied trade-offs in verification/idempotency, strongly separates capable entry-level candidates from weak ones.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-478",
        "role_title": "Backend Engineer - Cost Attribution",
        "question": "**Question:**  \nIn our cost attribution system built with Go and deployed on Kubernetes, we need to allocate cloud resource costs (e.g., from AWS/GCP) to teams based on resource tags like `team:engineering`. Walk me through how you would implement a Go function to parse a list of Kubernetes pod metadata (including tags/labels), aggregate costs by team, and return a simple chargeback report as a map. What key considerations would you have for accuracy and performance at mid-level scale (thousands of pods)? \n\n*(Expected: 2-5 min verbal/whiteboard response covering tag parsing, grouping with maps, error handling, and basics like caching or efficient queries.)*",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests Go implementation for core role skills (cost attribution, resource tagging, K8s pods, chargeback reports); minor deduction as AWS/GCP not explicitly core but highly relevant (-1). Clarity: Crystal clear, well-scoped with tech stack, scale, and expected response time; no bundling or ambiguity. Discriminative: Requires applied Go knowledge (parsing, aggregation, maps), trade-offs (accuracy/performance), distinguishing strong mid-level candidates via error handling/caching discussion.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-483",
        "role_title": "Backend Engineer - WAF Integration",
        "question": "**Question:**  \nYou're integrating ModSecurity with Nginx as a WAF layer in a Go-based backend service. A custom rule needs to detect and block SQL injection attempts in POST request bodies while logging the matched patterns to Redis for analysis. Write a concise ModSecurity rule (in SecRule format) for this, and briefly explain (1-2 sentences) how you'd trigger it from your Go app and retrieve logs from Redis.\n\n*(Expected answer: A valid SecRule using regex like `SecRule ARGS \"@rx (?:select|union|drop|insert).*?(?:from|into|where)` \"id:1000,phase:2,block,log,setvar:tx.sql_injection=1\" or similar; trigger via Nginx config `modsecurity_rules_file` loaded at startup; Go app uses `github.com/go-redis/redis/v8` to fetch logged keys like `HGETALL waf:logs:{txid}` post-request.)*",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Directly tests core WAF rule writing (ModSecurity), integration with Nginx/Go backend, and Redis logging\u2014perfectly matches role's custom rules, attack detection, and analysis focus (no red flags). Crystal clear scope with expected format and brief explanation request. Requires writing valid rules, explaining integration, and trade-offs in detection/logging, strongly separating skilled WAF engineers from juniors.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-487",
        "role_title": "Senior Backend Engineer - Search Ranking",
        "question": "**Question:**  \nYou're working on a learning-to-rank pipeline for search relevance using Python and Elasticsearch. Describe a practical approach to implementing position bias correction during feature engineering for your ranking model. What specific features would you engineer, and how would you integrate them into an Elasticsearch query or LambdaMART training pipeline? (Aim for 2-3 key steps.)",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly targets core role skills (LTR pipelines, feature engineering) with exact tech (Python, Elasticsearch); minor ding for LambdaMART not explicitly listed. Clarity: Crystal clear, well-scoped with 2-3 steps guidance, no ambiguity. Discriminative: Probes applied knowledge of position bias correction, feature engineering, and integration, requiring trade-offs and practical understanding to separate strong candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-466",
        "role_title": "Senior Backend Engineer - GitOps Tooling",
        "question": "**Question:**  \nIn ArgoCD, you've deployed an application via GitOps, but a manual `kubectl edit` on the cluster caused a configuration drift. Walk me through how ArgoCD detects this drift and the steps you'd take to remediate it, including any Go-based custom tooling you might build to automate rollbacks for frequent drifts.",
        "scores": {
          "relevance": 9,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core GitOps, drift detection, and reconciliation skills for the role; ArgoCD is highly relevant tooling, Go matches automation needs (-1 for not explicitly listed but fits perfectly). Clarity: Clear sequence but slightly open-ended on custom tooling scope. Discriminative: Excellent at separating candidates via applied ArgoCD knowledge, remediation steps, and custom Go tooling design showing deep understanding.",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-488",
        "role_title": "Backend Engineer - Gaming Backend",
        "question": "**Question:**  \nIn a multiplayer game backend using Go and WebSockets, you need to synchronize player positions across 100 concurrent players in a room with ~60Hz updates. Redis is available for pub/sub, and PostgreSQL for persistent state.  \n\nOutline a high-level design for the state synchronization flow, including how you'd handle latency differences and ensure consistency. What trade-offs would you consider (e.g., authoritative server vs. client-side prediction)?  \n\n*(Expect 2-5 min verbal/whiteboard response testing practical real-time sync knowledge.)*",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core real-time multiplayer backend skills (state sync) with exact tech stack (Go, WebSockets, Redis, PostgreSQL); minor deduction as role mentions anti-cheat/matchmaking not covered. Clarity: Crystal clear, well-scoped with constraints (100 players, 60Hz), explicit expected format/depth. Discriminative: Probes deep trade-offs (authoritative vs prediction, latency/consistency), separates strong candidates via applied reasoning over trivia.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-490",
        "role_title": "Senior Backend Engineer - Environment Management",
        "question": "**Question:**  \nIn a Kubernetes-based preview deployment system built with Go, how would you implement namespace isolation and resource quotas for user-created preview environments? Describe your approach, including key Kubernetes resources you'd use and any Go libraries or patterns for automation (e.g., via a controller). What challenges might arise with TTL-based cleanup?",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (namespace isolation, resource quotas, TTL cleanup) using exact tech stack (Kubernetes, Go). No red flags. Clarity: Well-scoped with clear intent, specifies key elements; minor deduction for lacking explicit time/format constraints. Discriminative: Probes applied knowledge, trade-offs, challenges, and patterns, strongly separating candidates with practical depth from superficial ones.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-486",
        "role_title": "Backend Engineer - Span Processing",
        "question": "**Question:**  \nIn a Go-based span processing pipeline using OpenTelemetry, you're implementing tail sampling to retain only 1% of traces based on a custom decision (e.g., error rate > 5% or latency > 500ms). Describe the key steps you'd take to implement this sampler, including how you'd access span attributes in the `OnLateArrivingSpans` method and propagate the sampling decision back to earlier spans. What Go concurrency patterns would you use to handle high-throughput span batches efficiently?\n\n*(Expected answer outline: Implement `otel/sdk/trace.SpanProcessor`; use tail-based sampling with `Decision` enum; read attributes via `SpanContext` or `Span.SpanContext()`; mutex or channels for thread-safety in batch processing; sync batching with Kafka consumer groups.)*",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (tail sampling in span processing pipeline) with exact tech stack (Go, OpenTelemetry); minor deduction as role doesn't explicitly list Go/OTel but aligns perfectly (-1). Clarity: Crystal clear, well-scoped with specific method and decision criteria, includes expected depth. Discriminative: Tests deep applied knowledge of OTEL interfaces, attribute access, decision propagation, and Go concurrency trade-offs, strongly separates strong candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-492",
        "role_title": "Backend Engineer - CD Pipelines",
        "question": "**Question:**\n\nYou're setting up an ArgoCD Application for a Go-based microservice that needs to promote from staging to production environments using GitOps. Describe the key steps you'd take in your GitHub Actions workflow and ArgoCD manifests to implement automated promotion with a manual approval gate (e.g., via GitHub environments) and automated rollback on deployment failure. Include one specific Helm value override for the production environment.\n\n*(Expected answer outline: GitHub Actions job to update Git repo on approval \u2192 ArgoCD sync policy (automated/manual) \u2192 Health checks/pre-sync hooks for rollback \u2192 Example Helm values like `replicaCount: 5` or `image.tag: prod-v1.2`.)*",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core GitOps pipeline skills (ArgoCD, GitHub Actions, multi-env promotion, approvals, rollback) matching role; minor ding for assuming Go/Helm not explicit in desc (-1). Clarity: Crystal clear, well-scoped steps with specific ask for Helm override; no bundling or ambiguity. Discriminative: Requires applied knowledge of integration, trade-offs (sync policies, hooks), and specifics, strongly separating skilled candidates.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-491",
        "role_title": "Junior Backend Engineer - Read Replicas",
        "question": "**Question:**\n\nYou're implementing read replica routing in a Python app using SQLAlchemy and PostgreSQL. You have a primary DB for writes and two read replicas. A user reports that some SELECT queries return slightly outdated data (e.g., a new user created 30 seconds ago isn't visible on a replica yet).\n\nIn 2-3 sentences, explain what likely caused this and how you'd handle it in code (pseudocode OK). What SQLAlchemy config or Python logic would you add?",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Directly tests core read replica routing and replication lag handling from role description using exact tech stack (Python, SQLAlchemy, PostgreSQL); crystal clear with scoped response length and specific ask for code/config; probes applied knowledge of trade-offs like lag detection, distinguishing strong candidates who suggest targeted reads or lag checks from weak ones guessing randomly. Minor genericism (-1 relevance) but no major red flags.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-489",
        "role_title": "Backend Engineer - Data Quality",
        "question": "**Question:**  \nYou're using dbt to manage data pipelines in Snowflake and Great Expectations for data quality checks. A key table in your warehouse (`orders`) has started showing unexpected nulls in a non-nullable column after a recent upstream schema change. Walk me through how you'd set up a dbt test combined with Great Expectations to detect this schema drift and alert on it, including the key configurations you'd use. (Feel free to sketch code snippets or commands.)\n\n*(Expected answer: Candidate describes dbt's `not_null` test or schema tests in `schema.yml`, integrating Great Expectations via `dbt-expectations` package with expectations like `expect_column_values_to_not_be_null`, setting up freshness/volume checks, and alerting via Airflow/Slack hooks. Tests mid-level practical integration knowledge.)*",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Directly tests core role skills (schema drift detection) using exact tech stack (dbt, Snowflake, Great Expectations). Crystal clear with specific scenario, well-scoped for screening, invites practical walkthrough with code. Strong separation of mid-level integration knowledge via trade-offs in configs/alerting; minor generic alert mention but no red flags.",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-479",
        "role_title": "Principal Engineer - Data Architecture",
        "question": "**Question:**  \nYou're designing a data architecture for a high-scale e-commerce platform handling 10M+ daily transactions. It needs low-latency OLTP reads/writes (e.g., inventory checks, order processing) alongside real-time analytics (e.g., sales dashboards, fraud detection). Using PostgreSQL, ClickHouse, Kafka, Redis, and Kubernetes from our stack, outline your high-level architecture, key component roles, and 2-3 critical trade-offs you'd discuss with stakeholders. (2-3 min response)",
        "scores": {
          "relevance": 10,
          "clarity": 10,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core data architecture strategy for mixed OLTP/analytics workloads using exact stack from role; no red flags. Clarity: Crystal clear with specific scenario, stack, scope (high-level, 2-3 min), roles, and trade-offs; well-constrained. Discriminative: Excellent at separating candidates via applied architecture design and trade-off reasoning; minor deduct for potential slight overrun risk but strong overall.",
          "composite": 9.666666666666666
        }
      },
      {
        "role_id": "be-494",
        "role_title": "Backend Engineer - API Mocking",
        "question": "**Question:**  \nIn WireMock (using TypeScript/Node.js), how would you configure a stub to match an incoming POST request to `/api/users` with a JSON body where `email` is a required field and `role` is either \"admin\" or \"user\", then respond with a templated 201 Created status containing the matched `email` and a generated `id`? Provide the key stub configuration (e.g., as a JSON mapping or TypeScript code snippet).\n\n*Follow-up (if time allows): How would you run this stub in a Docker container for integration testing with PostgreSQL?*",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests WireMock (core to API mocking), TypeScript/Node.js, request matching, JSON body validation, and response templating - matches role focus perfectly (-0 red flags). Clarity: Crystal clear, specific endpoint/body/response requirements, scoped to key config snippet (9-10). Discriminative: Requires applied WireMock knowledge (matchers, transformers, templates), distinguishes those who can configure vs memorize; follow-up adds Docker/integration depth without overbroadening (7-10).",
          "composite": 9.0
        }
      },
      {
        "role_id": "be-497",
        "role_title": "Backend Engineer - Payout Systems",
        "question": "**Question:**  \nIn our payout system built with Go, PostgreSQL, and Kafka, we process daily settlement batches containing thousands of bank transfers. Each payout record includes fields like `amount`, `bank_account`, `status`, and `reconciled_at`. Walk me through how you would design and implement a batch processing workflow in Go to validate bank accounts (e.g., via an external API), update statuses idempotently, and publish success/failure events to Kafka for downstream reconciliation. Highlight any key considerations for reliability and error handling.",
        "scores": {
          "relevance": 10,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (batch processing, bank validation, reconciliation) using exact tech stack (Go, PostgreSQL, Kafka); no red flags. Clarity: Crystal clear, well-scoped for screening, minor deduction for unspecified API details but intent unambiguous. Discriminative: Excellent at probing applied knowledge, trade-offs in idempotency/reliability/error handling, distinguishes strong Go engineers handling distributed systems.",
          "composite": 9.333333333333334
        }
      },
      {
        "role_id": "be-498",
        "role_title": "Senior Backend Engineer - Profiling Infrastructure",
        "question": "**Question:**  \nIn Pyroscope, you've collected a flame graph for a Go service showing high CPU usage in a specific goroutine. Walk me through your step-by-step process to investigate, optimize, and compare it against a baseline profile using Pyroscope tools. What key commands or UI features would you use, and why?",
        "scores": {
          "relevance": 7,
          "clarity": 9,
          "discriminative": 9,
          "reasoning": "Relevance: Tests Pyroscope profiling (core to role's flame graphs/baseline comparison), but assumes Pyroscope familiarity not explicitly listed and ignores storage optimization (-2 for tech not listed); Clarity: Crystal clear, step-by-step process well-scoped with specific context; Discriminative: Excellent at separating candidates via applied Pyroscope knowledge, trade-offs in optimization, and tool usage reasoning.",
          "composite": 8.333333333333334
        }
      },
      {
        "role_id": "be-495",
        "role_title": "Senior Backend Engineer - Audit Logging",
        "question": "**Question:**  \nIn Go, design a simple tamper-proof audit logging function that appends a log entry (e.g., `{user_id: string, action: string, timestamp: time.Time}`) to a Kafka topic, ensuring immutability and tamper detection. Include key security considerations like signing and sequencing, and explain how you'd integrate it with Kubernetes for deployment. (Sketch the code snippet and rationale in 2-5 minutes.)",
        "scores": {
          "relevance": 7,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Tests core tamper-proof logging and immutability directly relevant to audit infrastructure, uses Go (assuming in stack), Kafka fits event streaming for logs; deduct 2 for Kubernetes deployment tangential to core role focus, and -1 for generic. Clarity: Well-scoped with specifics (struct, Kafka, 2-5 min), clear intent despite minor jargon; deduct 1 for no explicit constraints on signing method. Discriminative: Excellent at testing applied design, trade-offs in signing/sequencing/security, distinguishes deep thinkers; time-bound prevents overkill.",
          "composite": 8.0
        }
      },
      {
        "role_id": "be-499",
        "role_title": "Principal Engineer - Search Platform",
        "question": "**Question:**  \nAs a Principal Engineer leading our search platform, imagine our enterprise is scaling to handle 10x query volume growth while adopting Elasticsearch as the core engine. Walk me through your high-level architecture decisions for integrating Kafka for real-time indexing, Redis for caching, and Kubernetes for orchestration. What key trade-offs would you consider, and how would you ensure operational excellence (e.g., reliability, cost)?",
        "scores": {
          "relevance": 7,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Tests core search platform strategy, scaling, and operational excellence directly matching role, but penalizes -2 for assuming unmentioned tech (Kafka, Redis, Kubernetes). Clarity: Well-scoped with specific scenario and components, clear intent, minor vagueness on depth. Discriminative: Excellent at probing trade-offs, architecture decisions, and deep understanding to separate strong leaders from average engineers.",
          "composite": 8.0
        }
      },
      {
        "role_id": "be-493",
        "role_title": "Staff Engineer - Reliability Standards",
        "question": "**Question:**  \nAs a Staff Engineer defining reliability standards for our org, walk me through how you would design a production readiness review (PRR) process for a new Kubernetes-based service. What key criteria would you include, and how would you ensure it catches reliability risks before launch? (Aim for 3-5 key points with brief rationale.)",
        "scores": {
          "relevance": 10,
          "clarity": 10,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role responsibility (designing PRR) with Kubernetes from role context, no red flags. Clarity: Crystal clear, well-scoped with 3-5 points limit and explicit aim. Discriminative: Requires applied SRE knowledge, trade-offs in criteria/risks, strong separation; minor deduction as very strong candidates might over-elaborate slightly.",
          "composite": 9.666666666666666
        }
      },
      {
        "role_id": "be-500",
        "role_title": "Staff Engineer - Streaming Architecture",
        "question": "**Question:**  \nYou're designing a real-time fan-out system in Rust using Kafka for event ingestion and Redis for caching user-specific state. Events arrive at 10k/sec, and you need to fan out notifications to 1M+ active WebSocket connections with at-least-once delivery guarantees, while minimizing latency (<100ms p99).\n\nWalk me through your high-level architecture: How would you structure the Kafka topics and consumer groups? What role does Redis play? Outline the Rust async processing flow (e.g., using Tokio), including error handling for duplicate delivery, and how you'd scale this on Kubernetes.",
        "scores": {
          "relevance": 9,
          "clarity": 8,
          "discriminative": 9,
          "reasoning": "Relevance: Directly tests core role skills (streaming infra, event schemas implied in fan-out, delivery guarantees, fan-out patterns) with relevant tech (Kafka); minor ding for unmentioned Rust/Redis/K8s (-1). Clarity: Well-scoped with metrics/constraints, clear intent; slightly low for lacking exact response format/depth guidance (-1, -1 for design scope). Discriminative: Excellent at probing trade-offs, async Rust, scaling, error handling; strong separation of deep thinkers.",
          "composite": 8.666666666666666
        }
      },
      {
        "role_id": "be-496",
        "role_title": "Junior Backend Engineer - Model Serving",
        "question": "**Question:**  \nYou're building a FastAPI endpoint to serve a pre-trained scikit-learn model for predicting house prices from a JSON input like `{\"area\": 1500, \"bedrooms\": 3}`. The model is saved as a `.pkl` file. Write a minimal code snippet for the `/predict` POST endpoint that loads the model once (not per request) and returns the prediction as JSON. Include any necessary imports and explain briefly why you'd use `model_server.py` startup event for loading.\n\n*(Expected answer: Use `pickle.load()` in `@app.on_event(\"startup\")`, `FastAPI()`, `APIRouter` or app directly, `from pydantic import BaseModel` for input validation, simple POST func with `model.predict([features])`. Tests Python/FastAPI basics, model loading awareness for junior level.)*",
        "scores": {
          "relevance": 9,
          "clarity": 9,
          "discriminative": 8,
          "reasoning": "Relevance: Directly tests core skills (FastAPI APIs, model loading with pickle/scikit-learn) for entry-level ML deployment role (-1 for minor APIRouter mention not central). Clarity: Crystal clear, well-scoped with example input/output, specific constraints like startup loading. Discriminative: Tests applied knowledge of FastAPI events, model loading, and input handling to separate juniors who can implement from those who can't; not pure recall but requires synthesis.",
          "composite": 8.666666666666666
        }
      }
    ]
  },
  "claude-4-5-haiku": {
    "model": "claude-4-5-haiku",
    "num_samples": 0,
    "avg_relevance": 0,
    "avg_clarity": 0,
    "avg_discriminative": 0,
    "avg_composite": 0,
    "results": []
  },
  "gpt-5-nano": {
    "model": "gpt-5-nano",
    "num_samples": 0,
    "avg_relevance": 0,
    "avg_clarity": 0,
    "avg_discriminative": 0,
    "avg_composite": 0,
    "results": []
  }
}